# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

"""PyTorch í™˜ê²½ í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ.

ì´ ëª¨ë“ˆì€ PyTorchì™€ CUDA í™˜ê²½ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
"""

import os
import platform
import sys
from pathlib import Path

import pytest


class TestTorchEnvironment:
    """PyTorch í™˜ê²½ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤."""

    def test_python_version(self) -> None:
        """Python ë²„ì „ì´ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸."""
        python_version = sys.version_info
        assert python_version >= (3, 10), f"Python 3.10 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬: {python_version}"
        print(f"âœ… Python ë²„ì „: {platform.python_version()}")

    def test_torch_import(self) -> None:
        """PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì •ìƒì ìœ¼ë¡œ importë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸."""
        try:
            import torch
            print(f"âœ… PyTorch ë²„ì „: {torch.__version__}")
            
            # CUDA í˜¸í™˜ì„± ë¯¸ë¦¬ í™•ì¸
            if torch.cuda.is_available():
                try:
                    # ê°„ë‹¨í•œ CUDA í…ì„œ ìƒì„±ìœ¼ë¡œ ì‹¤ì œ CUDA ì‘ë™ í™•ì¸
                    test_tensor = torch.tensor([1.0], device='cuda')
                    _ = test_tensor.cpu()  # GPU->CPU ì „ì†¡ í…ŒìŠ¤íŠ¸
                    print(f"âœ… CUDA ì´ˆê¸°í™” ì„±ê³µ: {torch.version.cuda}")
                except Exception as cuda_err:
                    print(f"âš ï¸  CUDA ì´ˆê¸°í™” ì‹¤íŒ¨: {cuda_err}")
                    print("   â†’ CPU ëª¨ë“œë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ê³„ì†í•©ë‹ˆë‹¤.")
            else:
                print("â„¹ï¸  CUDA ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œë¡œ ì‹¤í–‰")
                
        except ImportError as e:
            pytest.fail(f"PyTorch import ì‹¤íŒ¨: {e}")
        except Exception as e:
            print(f"âš ï¸  PyTorch ë¡œë”© ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            print("   â†’ ê¸°ë³¸ importëŠ” ì„±ê³µí–ˆì§€ë§Œ CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    def test_torch_basic_operations(self) -> None:
        """PyTorch ê¸°ë³¸ ì—°ì‚°ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸."""
        import torch

        # ê¸°ë³¸ í…ì„œ ìƒì„± ë° ì—°ì‚° í…ŒìŠ¤íŠ¸
        x = torch.randn(3, 3)
        y = torch.randn(3, 3)
        z = torch.matmul(x, y)
        
        assert z.shape == (3, 3), f"í–‰ë ¬ ê³±ì…ˆ ê²°ê³¼ shape ì˜¤ë¥˜: {z.shape}"
        assert not torch.isnan(z).any(), "í–‰ë ¬ ê³±ì…ˆ ê²°ê³¼ì— NaN ê°’ ì¡´ì¬"
        print("âœ… PyTorch ê¸°ë³¸ ì—°ì‚° í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_cuda_availability(self) -> None:
        """CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  ì •ë³´ë¥¼ ì¶œë ¥."""
        import torch

        cuda_available = torch.cuda.is_available()
        print(f"ğŸ“Š CUDA ì‚¬ìš© ê°€ëŠ¥: {cuda_available}")
        
        if cuda_available:
            print(f"ğŸ“Š CUDA ë²„ì „: {torch.version.cuda}")
            print(f"ğŸ“Š GPU ê°œìˆ˜: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
                print(f"ğŸ“Š GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
        else:
            print("âš ï¸  CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

    @pytest.mark.gpu
    def test_cuda_operations(self) -> None:
        """CUDA GPU ì—°ì‚°ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸ (GPUê°€ ìˆì„ ë•Œë§Œ)."""
        import torch

        if not torch.cuda.is_available():
            pytest.skip("CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ GPU í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        
        try:
            # CUDA ì´ˆê¸°í™” í™•ì¸ - import ì‹œì ì—ì„œ ì‹¤íŒ¨í•  ìˆ˜ ìˆëŠ” CUDA ì˜¤ë¥˜ë¥¼ ë¨¼ì € í™•ì¸
            torch.cuda.synchronize()
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            torch.cuda.empty_cache()
            
            # GPUì—ì„œ í…ì„œ ìƒì„± ë° ì—°ì‚°
            device = torch.device("cuda:0")
            x = torch.randn(100, 100, device=device)
            y = torch.randn(100, 100, device=device)
            z = torch.matmul(x, y)
            
            assert z.device.type == "cuda", f"ê²°ê³¼ í…ì„œê°€ GPUì— ìˆì§€ ì•ŠìŒ: {z.device}"
            assert z.shape == (100, 100), f"GPU ì—°ì‚° ê²°ê³¼ shape ì˜¤ë¥˜: {z.shape}"
            assert not torch.isnan(z).any(), "GPU ì—°ì‚° ê²°ê³¼ì— NaN ê°’ ì¡´ì¬"
            
            # CPUë¡œ ë°ì´í„° ì´ë™ í…ŒìŠ¤íŠ¸
            z_cpu = z.cpu()
            assert z_cpu.device.type == "cpu", "CPUë¡œ ë°ì´í„° ì´ë™ ì‹¤íŒ¨"
            
            print("âœ… CUDA GPU ì—°ì‚° í…ŒìŠ¤íŠ¸ í†µê³¼")
            
        except RuntimeError as e:
            if "CUDA" in str(e) and ("symbol" in str(e) or "version" in str(e)):
                pytest.skip(f"CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„± ë¬¸ì œë¡œ GPU í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤: {e}")
            else:
                pytest.fail(f"CUDA GPU ì—°ì‚° ì‹¤íŒ¨: {e}")
        except Exception as e:
            pytest.fail(f"CUDA GPU ì—°ì‚° ì‹¤íŒ¨: {e}")

    def test_torchvision_import(self) -> None:
        """torchvision ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì •ìƒì ìœ¼ë¡œ importë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸."""
        try:
            import torchvision
            print(f"âœ… torchvision ë²„ì „: {torchvision.__version__}")
        except ImportError as e:
            pytest.fail(f"torchvision import ì‹¤íŒ¨: {e}")

    def test_system_environment(self) -> None:
        """ì‹œìŠ¤í…œ í™˜ê²½ ì •ë³´ë¥¼ ì¶œë ¥."""
        print(f"ğŸ“Š ìš´ì˜ì²´ì œ: {platform.system()} {platform.release()}")
        print(f"ğŸ“Š ì•„í‚¤í…ì²˜: {platform.machine()}")
        print(f"ğŸ“Š í”„ë¡œì„¸ì„œ: {platform.processor()}")
        
        # ì‹¤í–‰ í™˜ê²½ í™•ì¸
        import subprocess
        try:
            # uvì™€ conda í™˜ê²½ í™•ì¸
            conda_env = os.environ.get("CONDA_DEFAULT_ENV", "ì—†ìŒ")
            virtual_env = os.environ.get("VIRTUAL_ENV", "ì—†ìŒ")
            print(f"ğŸ“Š Conda í™˜ê²½: {conda_env}")
            print(f"ğŸ“Š ê°€ìƒí™˜ê²½: {virtual_env}")
            
            # Python ì‹¤í–‰ ê²½ë¡œ í™•ì¸
            python_path = sys.executable
            print(f"ğŸ“Š Python ì‹¤í–‰ ê²½ë¡œ: {python_path}")
            
        except Exception as e:
            print(f"âš ï¸  í™˜ê²½ ì •ë³´ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # CUDA ê´€ë ¨ í™˜ê²½ë³€ìˆ˜ í™•ì¸
        cuda_home = os.environ.get("CUDA_HOME", "ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        ld_library_path = os.environ.get("LD_LIBRARY_PATH", "ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        
        print(f"ğŸ“Š CUDA_HOME: {cuda_home}")
        print(f"ğŸ“Š LD_LIBRARY_PATH: {ld_library_path}")

    def test_cuda_libraries_accessible(self) -> None:
        """CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸."""
        cuda_paths = [
            "/usr/local/cuda/lib64",
            "/usr/local/cuda-12.4/lib64",
            "/usr/local/cuda-12.4/targets/x86_64-linux/lib",
        ]
        
        accessible_paths = []
        for path in cuda_paths:
            if Path(path).exists():
                accessible_paths.append(path)
                print(f"âœ… CUDA ê²½ë¡œ ì ‘ê·¼ ê°€ëŠ¥: {path}")
        
        if not accessible_paths:
            print("âš ï¸  ì ‘ê·¼ ê°€ëŠ¥í•œ CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def test_torch_cuda_compatibility(self) -> None:
        """PyTorchì™€ ì‹œìŠ¤í…œ CUDAì˜ í˜¸í™˜ì„±ì„ í…ŒìŠ¤íŠ¸."""
        import torch
        
        print(f"ğŸ“Š PyTorch ë¹Œë“œ ì •ë³´:")
        print(f"  - CUDA ì§€ì›: {torch.version.cuda}")
        print(f"  - cuDNN ë²„ì „: {torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else 'N/A'}")
        print(f"  - Debug ëª¨ë“œ: {torch.version.debug}")
        
        # CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì‹œë„
        if torch.cuda.is_available():
            try:
                # ê°„ë‹¨í•œ CUDA ì—°ì‚°ìœ¼ë¡œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„± í™•ì¸
                torch.cuda.synchronize()
                print("âœ… CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„± í™•ì¸ë¨")
            except Exception as e:
                print(f"âŒ CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„± ì˜¤ë¥˜: {e}")
                # ì´ê²ƒì€ fatal errorê°€ ì•„ë‹ˆë¯€ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤íŒ¨ì‹œí‚¤ì§€ ì•ŠìŒ
        else:
            print("â„¹ï¸  CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    pytest.main([__file__, "-v", "-s"])
