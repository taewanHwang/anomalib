"""Test suite for Spatial-Aware features in DRAEM-SevNet.

ìƒˆë¡œ êµ¬í˜„í•œ Spatial-Aware ê¸°ëŠ¥ë“¤ì„ ì „ìš©ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
- SeverityHeadì˜ spatial_aware pooling_type
- ê³µê°„ ì •ë³´ ë³´ì¡´ ë©”ì»¤ë‹ˆì¦˜
- Spatial attention ê¸°ëŠ¥
- DraemSevNetModelì˜ spatial-aware ì˜µì…˜ë“¤
- GAP vs Spatial-Aware ì„±ëŠ¥ ë¹„êµ

Run with: 
pytest tests/unit/models/image/draem_sevnet/test_spatial_aware_features.py -v -s

Author: Taewan Hwang
"""

import pytest
import torch
import time
from typing import Dict, Tuple
from anomalib.models.image.draem_sevnet.severity_head import SeverityHead, SeverityHeadFactory
from anomalib.models.image.draem_sevnet.torch_model import DraemSevNetModel, DraemSevNetOutput

# ìƒì„¸ ì¶œë ¥ì„ ìœ„í•œ helper function
def verbose_print(message: str, level: str = "INFO"):
    """pytest -v ì‹¤í–‰ ì‹œ ìƒì„¸ ì¶œë ¥ì„ ìœ„í•œ í•¨ìˆ˜"""
    symbols = {"INFO": "â„¹ï¸", "SUCCESS": "âœ…", "WARNING": "âš ï¸", "ERROR": "âŒ", "COMPARE": "ğŸ”„"}
    print(f"\n{symbols.get(level, 'â„¹ï¸')} {message}")


class TestSpatialAwareSeverityHead:
    """SeverityHeadì˜ Spatial-Aware ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    def test_spatial_aware_initialization(self):
        """Spatial-Aware ëª¨ë“œ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing Spatial-Aware SeverityHead initialization...")
        
        # Single-scale spatial-aware
        head_single = SeverityHead(
            in_dim=512,
            hidden_dim=128,
            mode="single_scale",
            pooling_type="spatial_aware",
            spatial_size=4,
            use_spatial_attention=True
        )
        
        assert head_single.pooling_type == "spatial_aware"
        assert head_single.spatial_size == 4
        assert head_single.use_spatial_attention == True
        assert hasattr(head_single, 'spatial_attention')
        assert hasattr(head_single, 'spatial_reducer')
        assert hasattr(head_single, 'spatial_severity_mlp')
        
        verbose_print(f"Single-scale spatial-aware - pooling: {head_single.pooling_type}, size: {head_single.spatial_size}")
        
        # Multi-scale spatial-aware
        head_multi = SeverityHead(
            mode="multi_scale",
            base_width=64,
            hidden_dim=256,
            pooling_type="spatial_aware",
            spatial_size=4,
            use_spatial_attention=True
        )
        
        assert head_multi.pooling_type == "spatial_aware"
        assert hasattr(head_multi, 'scale_spatial_processors')
        assert hasattr(head_multi, 'multi_scale_spatial_mlp')
        
        verbose_print(f"Multi-scale spatial-aware - pooling: {head_multi.pooling_type}, processors: {len(head_multi.scale_spatial_processors)}")
        verbose_print("Spatial-Aware initialization test passed!", "SUCCESS")
    
    def test_spatial_aware_vs_gap_single_scale(self):
        """Single-scale: GAP vs Spatial-Aware ë¹„êµ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing Single-scale: GAP vs Spatial-Aware comparison...")
        
        batch_size, channels, height, width = 4, 512, 7, 7
        input_tensor = torch.randn(batch_size, channels, height, width)
        
        # GAP ë°©ì‹
        head_gap = SeverityHead(
            in_dim=channels,
            hidden_dim=128,
            mode="single_scale",
            pooling_type="gap"
        )
        
        # Spatial-Aware ë°©ì‹
        head_spatial = SeverityHead(
            in_dim=channels,
            hidden_dim=128,
            mode="single_scale",
            pooling_type="spatial_aware",
            spatial_size=4,
            use_spatial_attention=True
        )
        
        # Forward pass
        with torch.no_grad():
            score_gap = head_gap(input_tensor)
            score_spatial = head_spatial(input_tensor)
        
        # Shape ê²€ì¦
        assert score_gap.shape == (batch_size,)
        assert score_spatial.shape == (batch_size,)
        
        # ê°’ ë²”ìœ„ ê²€ì¦
        assert torch.all((score_gap >= 0) & (score_gap <= 1))
        assert torch.all((score_spatial >= 0) & (score_spatial <= 1))
        
        verbose_print(f"GAP scores: {score_gap.tolist()}")
        verbose_print(f"Spatial-Aware scores: {score_spatial.tolist()}")
        
        # íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ
        gap_params = sum(p.numel() for p in head_gap.parameters())
        spatial_params = sum(p.numel() for p in head_spatial.parameters())
        
        verbose_print(f"GAP parameters: {gap_params:,}")
        verbose_print(f"Spatial-Aware parameters: {spatial_params:,}")
        verbose_print(f"Parameter increase: {(spatial_params - gap_params) / gap_params * 100:.1f}%")
        
        # Spatial-Awareê°€ ë” ë§ì€ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì ¸ì•¼ í•¨
        assert spatial_params > gap_params
        
        verbose_print("Single-scale GAP vs Spatial-Aware comparison passed!", "SUCCESS")
    
    def test_spatial_aware_vs_gap_multi_scale(self):
        """Multi-scale: GAP vs Spatial-Aware ë¹„êµ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing Multi-scale: GAP vs Spatial-Aware comparison...")
        
        batch_size = 4
        base_width = 64
        
        # Multi-scale features ìƒì„±
        features = {
            'act2': torch.randn(batch_size, base_width * 2, 56, 56),
            'act3': torch.randn(batch_size, base_width * 4, 28, 28),
            'act4': torch.randn(batch_size, base_width * 8, 14, 14),
            'act5': torch.randn(batch_size, base_width * 8, 7, 7),
            'act6': torch.randn(batch_size, base_width * 8, 7, 7),
        }
        
        # GAP ë°©ì‹
        head_gap = SeverityHead(
            mode="multi_scale",
            base_width=base_width,
            hidden_dim=256,
            pooling_type="gap"
        )
        
        # Spatial-Aware ë°©ì‹
        head_spatial = SeverityHead(
            mode="multi_scale",
            base_width=base_width,
            hidden_dim=256,
            pooling_type="spatial_aware",
            spatial_size=4,
            use_spatial_attention=True
        )
        
        # Forward pass
        with torch.no_grad():
            score_gap = head_gap(features)
            score_spatial = head_spatial(features)
        
        # Shape ê²€ì¦
        assert score_gap.shape == (batch_size,)
        assert score_spatial.shape == (batch_size,)
        
        # ê°’ ë²”ìœ„ ê²€ì¦
        assert torch.all((score_gap >= 0) & (score_gap <= 1))
        assert torch.all((score_spatial >= 0) & (score_spatial <= 1))
        
        verbose_print(f"Multi-scale GAP scores: {score_gap.tolist()}")
        verbose_print(f"Multi-scale Spatial-Aware scores: {score_spatial.tolist()}")
        
        verbose_print("Multi-scale GAP vs Spatial-Aware comparison passed!", "SUCCESS")
    
    def test_spatial_size_variations(self):
        """ë‹¤ì–‘í•œ spatial_size í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing various spatial_size configurations...")
        
        batch_size, channels = 4, 512
        input_tensor = torch.randn(batch_size, channels, 7, 7)
        
        spatial_sizes = [2, 4, 8]
        results = {}
        
        for size in spatial_sizes:
            head = SeverityHead(
                in_dim=channels,
                hidden_dim=128,
                mode="single_scale",
                pooling_type="spatial_aware",
                spatial_size=size,
                use_spatial_attention=True
            )
            
            with torch.no_grad():
                scores = head(input_tensor)
            
            # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
            params = sum(p.numel() for p in head.parameters())
            results[size] = {
                'scores': scores,
                'params': params,
                'mean_score': scores.mean().item()
            }
            
            verbose_print(f"Spatial size {size}: params={params:,}, mean_score={scores.mean():.4f}")
        
        # ê²€ì¦: spatial_sizeê°€ í´ìˆ˜ë¡ ë” ë§ì€ íŒŒë¼ë¯¸í„°
        assert results[8]['params'] > results[4]['params'] > results[2]['params']
        
        verbose_print("Spatial size variations test passed!", "SUCCESS")
    
    def test_spatial_attention_effect(self):
        """Spatial attention íš¨ê³¼ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing spatial attention effect...")
        
        batch_size, channels = 4, 512
        input_tensor = torch.randn(batch_size, channels, 7, 7)
        
        # Attention ìˆëŠ” ê²½ìš°
        head_with_attention = SeverityHead(
            in_dim=channels,
            hidden_dim=128,
            mode="single_scale",
            pooling_type="spatial_aware",
            spatial_size=4,
            use_spatial_attention=True
        )
        
        # Attention ì—†ëŠ” ê²½ìš°
        head_without_attention = SeverityHead(
            in_dim=channels,
            hidden_dim=128,
            mode="single_scale",
            pooling_type="spatial_aware",
            spatial_size=4,
            use_spatial_attention=False
        )
        
        with torch.no_grad():
            scores_with = head_with_attention(input_tensor)
            scores_without = head_without_attention(input_tensor)
        
        # Shape ê²€ì¦
        assert scores_with.shape == (batch_size,)
        assert scores_without.shape == (batch_size,)
        
        # ê°’ ë²”ìœ„ ê²€ì¦
        assert torch.all((scores_with >= 0) & (scores_with <= 1))
        assert torch.all((scores_without >= 0) & (scores_without <= 1))
        
        # íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ
        params_with = sum(p.numel() for p in head_with_attention.parameters())
        params_without = sum(p.numel() for p in head_without_attention.parameters())
        
        verbose_print(f"With attention: params={params_with:,}, scores={scores_with.tolist()}")
        verbose_print(f"Without attention: params={params_without:,}, scores={scores_without.tolist()}")
        
        # Attentionì´ ìˆëŠ” ê²½ìš° ë” ë§ì€ íŒŒë¼ë¯¸í„°
        assert params_with > params_without
        
        verbose_print("Spatial attention effect test passed!", "SUCCESS")
    
    def test_information_preservation(self):
        """ê³µê°„ ì •ë³´ ë³´ì¡´ íš¨ê³¼ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing spatial information preservation...")
        
        batch_size, channels = 1, 512
        height, width = 7, 7
        
        # íŠ¹ì • íŒ¨í„´ì„ ê°€ì§„ feature map ìƒì„± (ì¢Œìƒë‹¨ì— ê°•í•œ ì‹ í˜¸)
        feature_map = torch.zeros(batch_size, channels, height, width)
        feature_map[:, :, 0:3, 0:3] = 1.0  # ì¢Œìƒë‹¨ ê°•í•œ ì‹ í˜¸
        feature_map[:, :, 4:7, 4:7] = 0.3  # ìš°í•˜ë‹¨ ì•½í•œ ì‹ í˜¸
        
        verbose_print(f"Original pattern - Top-left: {feature_map[:, :, 0:3, 0:3].mean():.3f}, Bottom-right: {feature_map[:, :, 4:7, 4:7].mean():.3f}")
        
        # GAP ë°©ì‹ (ì •ë³´ ì†ì‹¤)
        head_gap = SeverityHead(
            in_dim=channels,
            hidden_dim=128,
            mode="single_scale",
            pooling_type="gap"
        )
        
        # Spatial-Aware ë°©ì‹ (ì •ë³´ ë³´ì¡´)
        head_spatial = SeverityHead(
            in_dim=channels,
            hidden_dim=128,
            mode="single_scale",
            pooling_type="spatial_aware",
            spatial_size=4,
            use_spatial_attention=False  # attention ì—†ì´ ìˆœìˆ˜ ê³µê°„ ì •ë³´ë§Œ í…ŒìŠ¤íŠ¸
        )
        
        with torch.no_grad():
            # GAP ë‚´ë¶€ ì²˜ë¦¬ í™•ì¸
            gap_features = head_gap._global_average_pooling(feature_map)
            verbose_print(f"GAP result: {gap_features.mean():.3f} (spatial pattern lost)")
            
            # Spatial-Aware ë‚´ë¶€ ì²˜ë¦¬ í™•ì¸
            spatial_features = head_spatial.spatial_reducer(feature_map)  # [B, hidden_dim, 4, 4]
            verbose_print(f"Spatial-Aware result shape: {spatial_features.shape}")
            verbose_print(f"Spatial-Aware top-left: {spatial_features[:, :, 0:2, 0:2].mean():.3f}")
            verbose_print(f"Spatial-Aware bottom-right: {spatial_features[:, :, 2:4, 2:4].mean():.3f}")
            
            # ìµœì¢… ì ìˆ˜ ë¹„êµ
            score_gap = head_gap(feature_map)
            score_spatial = head_spatial(feature_map)
            
            verbose_print(f"Final GAP score: {score_gap.item():.4f}")
            verbose_print(f"Final Spatial-Aware score: {score_spatial.item():.4f}")
        
        # Spatial-Awareê°€ ê³µê°„ íŒ¨í„´ì„ ë³´ì¡´í•´ì•¼ í•¨
        top_left_preserved = spatial_features[:, :, 0:2, 0:2].mean()
        bottom_right_preserved = spatial_features[:, :, 2:4, 2:4].mean()
        
        # ìƒëŒ€ì  íŒ¨í„´ì´ ë³´ì¡´ë˜ì–´ì•¼ í•¨ (ì¢Œìƒë‹¨ > ìš°í•˜ë‹¨)
        assert top_left_preserved > bottom_right_preserved
        
        verbose_print("Spatial information preservation test passed!", "SUCCESS")


class TestSpatialAwareDraemSevNetModel:
    """DraemSevNetModelì˜ Spatial-Aware ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    def test_spatial_aware_model_initialization(self):
        """Spatial-Aware ëª¨ë¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing Spatial-Aware DraemSevNetModel initialization...")
        
        # ê¸°ë³¸ GAP ëª¨ë¸
        model_gap = DraemSevNetModel(
            severity_head_pooling_type="gap"
        )
        
        # Spatial-Aware ëª¨ë¸
        model_spatial = DraemSevNetModel(
            severity_head_pooling_type="spatial_aware",
            severity_head_spatial_size=4,
            severity_head_use_spatial_attention=True
        )
        
        # Multi-scale Spatial-Aware ëª¨ë¸
        model_multi_spatial = DraemSevNetModel(
            severity_head_mode="multi_scale",
            severity_head_pooling_type="spatial_aware",
            severity_head_spatial_size=4,
            severity_head_use_spatial_attention=True
        )
        
        # SeverityHead ì†ì„± í™•ì¸
        assert model_gap.severity_head.pooling_type == "gap"
        assert model_spatial.severity_head.pooling_type == "spatial_aware"
        assert model_spatial.severity_head.spatial_size == 4
        assert model_spatial.severity_head.use_spatial_attention == True
        assert model_multi_spatial.severity_head.pooling_type == "spatial_aware"
        
        verbose_print(f"GAP model pooling: {model_gap.severity_head.pooling_type}")
        verbose_print(f"Spatial-Aware model pooling: {model_spatial.severity_head.pooling_type}, size: {model_spatial.severity_head.spatial_size}")
        verbose_print(f"Multi-scale Spatial-Aware pooling: {model_multi_spatial.severity_head.pooling_type}")
        
        verbose_print("Spatial-Aware model initialization test passed!", "SUCCESS")
    
    def test_spatial_aware_model_forward_training(self):
        """Spatial-Aware ëª¨ë¸ Training ëª¨ë“œ forward í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing Spatial-Aware model training forward...")
        
        batch_size = 4
        input_tensor = torch.randn(batch_size, 3, 224, 224)
        
        models = {
            "GAP": DraemSevNetModel(severity_head_pooling_type="gap"),
            "Spatial-Aware": DraemSevNetModel(
                severity_head_pooling_type="spatial_aware",
                severity_head_spatial_size=4,
                severity_head_use_spatial_attention=True
            ),
            "Multi-Spatial": DraemSevNetModel(
                severity_head_mode="multi_scale",
                severity_head_pooling_type="spatial_aware",
                severity_head_spatial_size=4
            )
        }
        
        for name, model in models.items():
            model.train()
            
            reconstruction, mask_logits, severity_score = model(input_tensor)
            
            # Shape ê²€ì¦
            assert reconstruction.shape == (batch_size, 3, 224, 224)
            assert mask_logits.shape == (batch_size, 2, 224, 224)
            assert severity_score.shape == (batch_size,)
            
            # ê°’ ë²”ìœ„ ê²€ì¦
            assert torch.all((severity_score >= 0) & (severity_score <= 1))
            
            verbose_print(f"{name} training - severity range: [{severity_score.min():.4f}, {severity_score.max():.4f}]")
        
        verbose_print("Spatial-Aware model training forward test passed!", "SUCCESS")
    
    def test_spatial_aware_model_forward_inference(self):
        """Spatial-Aware ëª¨ë¸ Inference ëª¨ë“œ forward í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing Spatial-Aware model inference forward...")
        
        batch_size = 4
        input_tensor = torch.randn(batch_size, 3, 224, 224)
        
        models = {
            "GAP": DraemSevNetModel(severity_head_pooling_type="gap"),
            "Spatial-Aware": DraemSevNetModel(
                severity_head_pooling_type="spatial_aware",
                severity_head_spatial_size=4,
                severity_head_use_spatial_attention=True
            ),
            "Multi-Spatial": DraemSevNetModel(
                severity_head_mode="multi_scale",
                severity_head_pooling_type="spatial_aware",
                severity_head_spatial_size=4
            )
        }
        
        for name, model in models.items():
            model.eval()
            
            with torch.no_grad():
                output = model(input_tensor)
            
            # íƒ€ì… ê²€ì¦
            assert isinstance(output, DraemSevNetOutput)
            
            # Shape ê²€ì¦
            assert output.final_score.shape == (batch_size,)
            assert output.severity_score.shape == (batch_size,)
            assert output.mask_score.shape == (batch_size,)
            assert output.anomaly_map.shape == (batch_size, 224, 224)
            
            # ê°’ ë²”ìœ„ ê²€ì¦
            assert torch.all((output.final_score >= 0) & (output.final_score <= 1))
            assert torch.all((output.severity_score >= 0) & (output.severity_score <= 1))
            assert torch.all((output.mask_score >= 0) & (output.mask_score <= 1))
            
            verbose_print(f"{name} inference - final_score: [{output.final_score.min():.4f}, {output.final_score.max():.4f}]")
            verbose_print(f"{name} inference - severity_score: [{output.severity_score.min():.4f}, {output.severity_score.max():.4f}]")
        
        verbose_print("Spatial-Aware model inference forward test passed!", "SUCCESS")
    
    def test_spatial_aware_model_parameter_comparison(self):
        """Spatial-Aware ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing Spatial-Aware model parameter comparison...")
        
        models = {
            "GAP Single": DraemSevNetModel(
                severity_head_mode="single_scale",
                severity_head_pooling_type="gap"
            ),
            "Spatial Single": DraemSevNetModel(
                severity_head_mode="single_scale",
                severity_head_pooling_type="spatial_aware",
                severity_head_spatial_size=4
            ),
            "GAP Multi": DraemSevNetModel(
                severity_head_mode="multi_scale",
                severity_head_pooling_type="gap"
            ),
            "Spatial Multi": DraemSevNetModel(
                severity_head_mode="multi_scale",
                severity_head_pooling_type="spatial_aware",
                severity_head_spatial_size=4
            )
        }
        
        param_counts = {}
        for name, model in models.items():
            total_params = sum(p.numel() for p in model.parameters())
            severity_params = sum(p.numel() for p in model.severity_head.parameters())
            param_counts[name] = {
                'total': total_params,
                'severity': severity_params
            }
            
            verbose_print(f"{name}: total={total_params:,}, severity_head={severity_params:,}")
        
        # ê²€ì¦: Spatial-Awareê°€ GAPë³´ë‹¤ ë§ì€ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì ¸ì•¼ í•¨
        assert param_counts["Spatial Single"]["severity"] > param_counts["GAP Single"]["severity"]
        assert param_counts["Spatial Multi"]["severity"] > param_counts["GAP Multi"]["severity"]
        
        # Multi-scaleì´ Single-scaleë³´ë‹¤ ë§ì€ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì ¸ì•¼ í•¨
        assert param_counts["Spatial Multi"]["severity"] > param_counts["Spatial Single"]["severity"]
        
        verbose_print("Parameter comparison test passed!", "SUCCESS")
    
    def test_spatial_aware_gradient_flow(self):
        """Spatial-Aware ëª¨ë¸ gradient íë¦„ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing Spatial-Aware model gradient flow...")
        
        model = DraemSevNetModel(
            severity_head_pooling_type="spatial_aware",
            severity_head_spatial_size=4,
            severity_head_use_spatial_attention=True
        )
        model.train()
        
        batch_size = 2
        input_tensor = torch.randn(batch_size, 3, 224, 224, requires_grad=True)
        
        reconstruction, mask_logits, severity_score = model(input_tensor)
        
        # ì†ì‹¤ ê³„ì‚° (ë‹¨ìˆœí™”)
        loss = reconstruction.sum() + mask_logits.sum() + severity_score.sum()
        loss.backward()
        
        # Input gradient í™•ì¸
        assert input_tensor.grad is not None
        assert not torch.all(input_tensor.grad == 0)
        
        # SeverityHeadì˜ spatial-aware ì»´í¬ë„ŒíŠ¸ë“¤ gradient í™•ì¸
        severity_head = model.severity_head
        
        # Spatial attention gradient í™•ì¸
        if hasattr(severity_head, 'spatial_attention'):
            for param in severity_head.spatial_attention.parameters():
                if param.requires_grad:
                    assert param.grad is not None
                    assert not torch.all(param.grad == 0)
        
        # Spatial reducer gradient í™•ì¸
        if hasattr(severity_head, 'spatial_reducer'):
            for param in severity_head.spatial_reducer.parameters():
                if param.requires_grad:
                    assert param.grad is not None
                    assert not torch.all(param.grad == 0)
        
        verbose_print("Spatial-Aware gradient flow test passed!", "SUCCESS")


class TestSpatialAwareFactory:
    """SeverityHeadFactoryì˜ Spatial-Aware ë©”ì„œë“œ í…ŒìŠ¤íŠ¸"""
    
    def test_factory_spatial_aware_methods(self):
        """Factoryì˜ Spatial-Aware ìƒì„± ë©”ì„œë“œ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing SeverityHeadFactory spatial-aware methods...")
        
        # create_spatial_aware_single_scale
        head_single = SeverityHeadFactory.create_spatial_aware_single_scale(
            in_dim=512,
            hidden_dim=128,
            spatial_size=4,
            use_spatial_attention=True
        )
        
        assert isinstance(head_single, SeverityHead)
        assert head_single.mode == "single_scale"
        assert head_single.pooling_type == "spatial_aware"
        assert head_single.spatial_size == 4
        assert head_single.use_spatial_attention == True
        
        # create_spatial_aware_multi_scale
        head_multi = SeverityHeadFactory.create_spatial_aware_multi_scale(
            base_width=64,
            hidden_dim=256,
            spatial_size=4,
            use_spatial_attention=True
        )
        
        assert isinstance(head_multi, SeverityHead)
        assert head_multi.mode == "multi_scale"
        assert head_multi.pooling_type == "spatial_aware"
        assert head_multi.spatial_size == 4
        assert head_multi.use_spatial_attention == True
        
        verbose_print("Factory spatial-aware methods test passed!", "SUCCESS")
    
    def test_factory_backward_compatibility(self):
        """Factoryì˜ í•˜ìœ„ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing Factory backward compatibility...")
        
        # ê¸°ì¡´ ë©”ì„œë“œë“¤ì´ ìƒˆë¡œìš´ ì˜µì…˜ì„ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸
        head_single_gap = SeverityHeadFactory.create_single_scale(
            in_dim=512,
            pooling_type="gap"
        )
        
        head_single_spatial = SeverityHeadFactory.create_single_scale(
            in_dim=512,
            pooling_type="spatial_aware",
            spatial_size=4,
            use_spatial_attention=True
        )
        
        assert head_single_gap.pooling_type == "gap"
        assert head_single_spatial.pooling_type == "spatial_aware"
        
        verbose_print("Factory backward compatibility test passed!", "SUCCESS")


class TestSpatialAwarePerformance:
    """Spatial-Aware ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸"""
    
    def test_inference_speed_comparison(self):
        """ì¶”ë¡  ì†ë„ ë¹„êµ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing inference speed comparison...")
        
        batch_size = 8
        input_tensor = torch.randn(batch_size, 3, 224, 224)
        num_runs = 50
        
        models = {
            "GAP": DraemSevNetModel(severity_head_pooling_type="gap"),
            "Spatial-Aware": DraemSevNetModel(
                severity_head_pooling_type="spatial_aware",
                severity_head_spatial_size=4,
                severity_head_use_spatial_attention=True
            )
        }
        
        results = {}
        
        for name, model in models.items():
            model.eval()
            
            # Warmup
            with torch.no_grad():
                for _ in range(10):
                    model(input_tensor)
            
            # Timing
            start_time = time.time()
            with torch.no_grad():
                for _ in range(num_runs):
                    output = model(input_tensor)
            end_time = time.time()
            
            avg_time = (end_time - start_time) / num_runs
            results[name] = {
                'avg_time': avg_time,
                'final_score': output.final_score.mean().item()
            }
            
            verbose_print(f"{name}: {avg_time*1000:.2f}ms per batch, avg_score: {output.final_score.mean():.4f}")
        
        # ì†ë„ ë¹„êµ (Spatial-Awareê°€ ë” ëŠë¦´ ìˆ˜ ìˆìŒ)
        speed_ratio = results["Spatial-Aware"]["avg_time"] / results["GAP"]["avg_time"]
        verbose_print(f"Speed ratio (Spatial-Aware / GAP): {speed_ratio:.2f}x", "COMPARE")
        
        # í•©ë¦¬ì ì¸ ì†ë„ ì°¨ì´ì¸ì§€ í™•ì¸ (10ë°° ì´ìƒ ëŠë¦¬ë©´ ì•ˆë¨)
        assert speed_ratio < 10.0, f"Spatial-Aware is too slow: {speed_ratio:.2f}x"
        
        verbose_print("Inference speed comparison test passed!", "SUCCESS")
    
    def test_memory_usage_comparison(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing memory usage comparison...")
        
        large_batch = 32
        input_tensor = torch.randn(large_batch, 3, 224, 224)
        
        models = {
            "GAP": DraemSevNetModel(severity_head_pooling_type="gap"),
            "Spatial-Aware": DraemSevNetModel(
                severity_head_pooling_type="spatial_aware",
                severity_head_spatial_size=4,
                severity_head_use_spatial_attention=True
            )
        }
        
        for name, model in models.items():
            model.eval()
            
            with torch.no_grad():
                output = model(input_tensor)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ (í° ë°°ì¹˜ì—ì„œë„ ì •ìƒ ë™ì‘í•´ì•¼ í•¨)
            assert output.final_score.shape == (large_batch,)
            assert torch.all((output.final_score >= 0) & (output.final_score <= 1))
            
            verbose_print(f"{name}: successfully processed batch_size={large_batch}")
        
        verbose_print("Memory usage comparison test passed!", "SUCCESS")


class TestSpatialAwareArchitectureCoverage:
    """ë‹¤ì–‘í•œ Spatial-Aware ì•„í‚¤í…ì²˜ ì¡°í•© ì™„ì „ í…ŒìŠ¤íŠ¸"""
    
    def test_all_architecture_combinations(self):
        """ëª¨ë“  ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ ì¡°í•© ë§¤íŠ¸ë¦­ìŠ¤ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing all possible architecture combinations...")
        
        # í…ŒìŠ¤íŠ¸í•  ëª¨ë“  ì¡°í•© ì •ì˜
        test_combinations = [
            # (mode, pooling_type, spatial_size, use_attention, score_combination)
            ("single_scale", "gap", None, None, "simple_average"),
            ("single_scale", "gap", None, None, "weighted_average"),
            ("single_scale", "gap", None, None, "maximum"),
            
            ("single_scale", "spatial_aware", 2, True, "simple_average"),
            ("single_scale", "spatial_aware", 2, False, "simple_average"),
            ("single_scale", "spatial_aware", 4, True, "simple_average"),
            ("single_scale", "spatial_aware", 4, False, "simple_average"),
            ("single_scale", "spatial_aware", 8, True, "simple_average"),
            ("single_scale", "spatial_aware", 8, False, "simple_average"),
            
            ("single_scale", "spatial_aware", 4, True, "weighted_average"),
            ("single_scale", "spatial_aware", 4, True, "maximum"),
            
            ("multi_scale", "gap", None, None, "simple_average"),
            ("multi_scale", "gap", None, None, "weighted_average"),
            ("multi_scale", "gap", None, None, "maximum"),
            
            ("multi_scale", "spatial_aware", 2, True, "simple_average"),
            ("multi_scale", "spatial_aware", 2, False, "simple_average"),
            ("multi_scale", "spatial_aware", 4, True, "simple_average"),
            ("multi_scale", "spatial_aware", 4, False, "simple_average"),
            ("multi_scale", "spatial_aware", 8, True, "simple_average"),
            ("multi_scale", "spatial_aware", 8, False, "simple_average"),
            
            ("multi_scale", "spatial_aware", 4, True, "weighted_average"),
            ("multi_scale", "spatial_aware", 4, True, "maximum"),
        ]
        
        batch_size = 2
        input_tensor = torch.randn(batch_size, 3, 224, 224)
        
        successful_combinations = 0
        total_combinations = len(test_combinations)
        
        for i, (mode, pooling_type, spatial_size, use_attention, score_combination) in enumerate(test_combinations):
            try:
                # ëª¨ë¸ ìƒì„±
                if pooling_type == "gap":
                    model = DraemSevNetModel(
                        severity_head_mode=mode,
                        severity_head_pooling_type=pooling_type,
                        score_combination=score_combination,
                        severity_weight_for_combination=0.3
                    )
                else:  # spatial_aware
                    model = DraemSevNetModel(
                        severity_head_mode=mode,
                        severity_head_pooling_type=pooling_type,
                        severity_head_spatial_size=spatial_size,
                        severity_head_use_spatial_attention=use_attention,
                        score_combination=score_combination,
                        severity_weight_for_combination=0.3
                    )
                
                # Training mode í…ŒìŠ¤íŠ¸
                model.train()
                reconstruction, mask_logits, severity_score = model(input_tensor)
                
                assert reconstruction.shape == (batch_size, 3, 224, 224)
                assert mask_logits.shape == (batch_size, 2, 224, 224)
                assert severity_score.shape == (batch_size,)
                assert torch.all((severity_score >= 0) & (severity_score <= 1))
                
                # Inference mode í…ŒìŠ¤íŠ¸
                model.eval()
                with torch.no_grad():
                    output = model(input_tensor)
                
                assert isinstance(output, DraemSevNetOutput)
                assert torch.all((output.final_score >= 0) & (output.final_score <= 1))
                assert torch.all((output.severity_score >= 0) & (output.severity_score <= 1))
                
                successful_combinations += 1
                
                if pooling_type == "gap":
                    combo_desc = f"{mode}+{pooling_type}+{score_combination}"
                else:
                    combo_desc = f"{mode}+{pooling_type}(size={spatial_size},att={use_attention})+{score_combination}"
                
                verbose_print(f"âœ… [{i+1:2d}/{total_combinations}] {combo_desc}")
                
            except Exception as e:
                verbose_print(f"âŒ [{i+1:2d}/{total_combinations}] Failed: {e}", "ERROR")
        
        # ëª¨ë“  ì¡°í•©ì´ ì„±ê³µí•´ì•¼ í•¨
        assert successful_combinations == total_combinations, f"Failed combinations: {total_combinations - successful_combinations}/{total_combinations}"
        
        verbose_print(f"ğŸ‰ All {total_combinations} architecture combinations passed!", "SUCCESS")
    
    def test_input_size_spatial_size_combinations(self):
        """ë‹¤ì–‘í•œ ì…ë ¥ í¬ê¸°ì™€ spatial_size ì¡°í•© í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing input size and spatial size combinations...")
        
        # (input_height, input_width, spatial_size) ì¡°í•©
        size_combinations = [
            (224, 224, 2),
            (224, 224, 4),
            (224, 224, 8),
            (256, 256, 2),
            (256, 256, 4),
            (256, 256, 8),
            (512, 512, 4),
            (512, 512, 8),
            (128, 128, 2),
            (128, 128, 4),
        ]
        
        successful_tests = 0
        
        for height, width, spatial_size in size_combinations:
            try:
                model = DraemSevNetModel(
                    severity_head_mode="single_scale",
                    severity_head_pooling_type="spatial_aware",
                    severity_head_spatial_size=spatial_size,
                    severity_head_use_spatial_attention=True
                )
                
                batch_size = 2
                input_tensor = torch.randn(batch_size, 3, height, width)
                
                # Training mode
                model.train()
                reconstruction, mask_logits, severity_score = model(input_tensor)
                
                assert reconstruction.shape == (batch_size, 3, height, width)
                assert mask_logits.shape == (batch_size, 2, height, width)
                assert severity_score.shape == (batch_size,)
                
                # Inference mode
                model.eval()
                with torch.no_grad():
                    output = model(input_tensor)
                
                assert output.anomaly_map.shape == (batch_size, height, width)
                
                successful_tests += 1
                verbose_print(f"âœ… Input({height}x{width}) + Spatial({spatial_size}x{spatial_size})")
                
            except Exception as e:
                verbose_print(f"âŒ Input({height}x{width}) + Spatial({spatial_size}x{spatial_size}): {e}", "ERROR")
        
        assert successful_tests == len(size_combinations), f"Failed size combinations: {len(size_combinations) - successful_tests}"
        verbose_print("Input size and spatial size combinations test passed!", "SUCCESS")
    
    def test_extreme_spatial_sizes(self):
        """ê·¹í•œ spatial_size ê°’ë“¤ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing extreme spatial sizes...")
        
        batch_size = 2
        input_tensor = torch.randn(batch_size, 3, 224, 224)
        
        # ê·¹í•œ ê°’ë“¤ í…ŒìŠ¤íŠ¸
        extreme_sizes = [1, 16, 32]  # ë§¤ìš° ì‘ì€ ê°’ê³¼ í° ê°’ë“¤
        
        for spatial_size in extreme_sizes:
            try:
                model = DraemSevNetModel(
                    severity_head_mode="single_scale",
                    severity_head_pooling_type="spatial_aware",
                    severity_head_spatial_size=spatial_size,
                    severity_head_use_spatial_attention=True
                )
                
                model.train()
                reconstruction, mask_logits, severity_score = model(input_tensor)
                
                # ê¸°ë³¸ ê²€ì¦
                assert severity_score.shape == (batch_size,)
                assert torch.all((severity_score >= 0) & (severity_score <= 1))
                
                # íŒŒë¼ë¯¸í„° ìˆ˜ í™•ì¸
                total_params = sum(p.numel() for p in model.parameters())
                severity_params = sum(p.numel() for p in model.severity_head.parameters())
                
                verbose_print(f"âœ… Spatial size {spatial_size:2d}: total_params={total_params:,}, severity_params={severity_params:,}")
                
            except Exception as e:
                verbose_print(f"âŒ Spatial size {spatial_size}: {e}", "ERROR")
                # ê·¹í•œ ê°’ì—ì„œëŠ” ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ (ë©”ëª¨ë¦¬ ë¶€ì¡± ë“±)
                continue
        
        verbose_print("Extreme spatial sizes test completed!", "SUCCESS")
    
    def test_sspcab_with_spatial_aware(self):
        """SSPCAB ì˜µì…˜ê³¼ Spatial-Aware ì¡°í•© í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing SSPCAB with Spatial-Aware combinations...")
        
        batch_size = 2
        input_tensor = torch.randn(batch_size, 3, 224, 224)
        
        # SSPCAB + Spatial-Aware ì¡°í•©ë“¤
        combinations = [
            (False, "gap"),
            (True, "gap"),
            (False, "spatial_aware"),
            (True, "spatial_aware"),
        ]
        
        for sspcab, pooling_type in combinations:
            try:
                if pooling_type == "gap":
                    model = DraemSevNetModel(
                        sspcab=sspcab,
                        severity_head_pooling_type=pooling_type
                    )
                else:
                    model = DraemSevNetModel(
                        sspcab=sspcab,
                        severity_head_pooling_type=pooling_type,
                        severity_head_spatial_size=4,
                        severity_head_use_spatial_attention=True
                    )
                
                model.train()
                reconstruction, mask_logits, severity_score = model(input_tensor)
                
                # ê¸°ë³¸ ê²€ì¦
                assert reconstruction.shape == (batch_size, 3, 224, 224)
                assert severity_score.shape == (batch_size,)
                assert torch.all((severity_score >= 0) & (severity_score <= 1))
                
                verbose_print(f"âœ… SSPCAB={sspcab} + {pooling_type}")
                
            except Exception as e:
                verbose_print(f"âŒ SSPCAB={sspcab} + {pooling_type}: {e}", "ERROR")
                assert False, f"SSPCAB combination failed: {e}"
        
        verbose_print("SSPCAB with Spatial-Aware combinations test passed!", "SUCCESS")
    
    def test_parameter_scaling_analysis(self):
        """íŒŒë¼ë¯¸í„° ìŠ¤ì¼€ì¼ë§ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing parameter scaling analysis...")
        
        # ë‹¤ì–‘í•œ hidden_dim ê°’ë“¤ë¡œ íŒŒë¼ë¯¸í„° ìŠ¤ì¼€ì¼ë§ í™•ì¸
        hidden_dims = [64, 128, 256, 512]
        spatial_sizes = [2, 4, 8]
        
        scaling_results = {}
        
        for hidden_dim in hidden_dims:
            scaling_results[hidden_dim] = {}
            for spatial_size in spatial_sizes:
                try:
                    model = DraemSevNetModel(
                        severity_head_mode="single_scale",
                        severity_head_hidden_dim=hidden_dim,
                        severity_head_pooling_type="spatial_aware",
                        severity_head_spatial_size=spatial_size,
                        severity_head_use_spatial_attention=True
                    )
                    
                    severity_params = sum(p.numel() for p in model.severity_head.parameters())
                    scaling_results[hidden_dim][spatial_size] = severity_params
                    
                    verbose_print(f"Hidden={hidden_dim:3d}, Spatial={spatial_size}: {severity_params:,} params")
                    
                except Exception as e:
                    verbose_print(f"âŒ Hidden={hidden_dim}, Spatial={spatial_size}: {e}", "ERROR")
                    continue
        
        # ìŠ¤ì¼€ì¼ë§ íŒ¨í„´ ê²€ì¦
        for hidden_dim in hidden_dims:
            if len(scaling_results[hidden_dim]) >= 2:
                sizes = sorted(scaling_results[hidden_dim].keys())
                for i in range(len(sizes)-1):
                    smaller_size = sizes[i]
                    larger_size = sizes[i+1]
                    assert scaling_results[hidden_dim][larger_size] > scaling_results[hidden_dim][smaller_size], \
                        f"Parameter scaling error: larger spatial_size should have more parameters"
        
        verbose_print("Parameter scaling analysis test passed!", "SUCCESS")
    
    def test_backward_compatibility_comprehensive(self):
        """í¬ê´„ì ì¸ í•˜ìœ„ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
        verbose_print("Testing comprehensive backward compatibility...")
        
        batch_size = 2
        input_tensor = torch.randn(batch_size, 3, 224, 224)
        
        # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ ìƒì„± (ìƒˆë¡œìš´ ì˜µì…˜ ì—†ì´)
        legacy_models = [
            DraemSevNetModel(),  # ëª¨ë“  ê¸°ë³¸ê°’
            DraemSevNetModel(severity_head_mode="multi_scale"),
            DraemSevNetModel(score_combination="weighted_average"),
            DraemSevNetModel(severity_weight_for_combination=0.7),
            DraemSevNetModel(sspcab=True),
        ]
        
        for i, model in enumerate(legacy_models):
            try:
                # ëª¨ë“  ë ˆê±°ì‹œ ëª¨ë¸ì€ ê¸°ë³¸ì ìœ¼ë¡œ GAPì„ ì‚¬ìš©í•´ì•¼ í•¨
                assert model.severity_head.pooling_type == "gap"
                
                # Training mode
                model.train()
                reconstruction, mask_logits, severity_score = model(input_tensor)
                
                assert reconstruction.shape == (batch_size, 3, 224, 224)
                assert severity_score.shape == (batch_size,)
                
                # Inference mode
                model.eval()
                with torch.no_grad():
                    output = model(input_tensor)
                
                assert isinstance(output, DraemSevNetOutput)
                assert torch.all((output.final_score >= 0) & (output.final_score <= 1))
                
                verbose_print(f"âœ… Legacy model {i+1}: OK")
                
            except Exception as e:
                verbose_print(f"âŒ Legacy model {i+1}: {e}", "ERROR")
                assert False, f"Backward compatibility broken: {e}"
        
        verbose_print("Comprehensive backward compatibility test passed!", "SUCCESS")


# pytestë¡œ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” í†µí•© í…ŒìŠ¤íŠ¸
def test_spatial_aware_integration_summary():
    """ì „ì²´ Spatial-Aware ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìš”ì•½"""
    verbose_print("ğŸ§ª Spatial-Aware Features Test Suite Integration Summary", "INFO")
    verbose_print("=" * 70)
    
    # í…ŒìŠ¤íŠ¸ êµ¬ì„± ìš”ì†Œ í™•ì¸
    test_components = [
        "SeverityHead Spatial-Aware initialization",
        "GAP vs Spatial-Aware comparison (single & multi-scale)",
        "Spatial size variations (2, 4, 8)",
        "Spatial attention effect testing",
        "Spatial information preservation verification",
        "DraemSevNetModel Spatial-Aware integration",
        "Training & inference mode forward passes",
        "Parameter count comparison",
        "Gradient flow validation",
        "SeverityHeadFactory spatial-aware methods",
        "Factory backward compatibility",
        "Inference speed comparison",
        "Memory usage comparison"
    ]
    
    verbose_print("Test components covered:")
    for i, component in enumerate(test_components, 1):
        verbose_print(f"  {i:2d}. {component}")
    
    verbose_print(f"\nğŸ¯ Total {len(test_components)} test categories covered!", "SUCCESS")
    verbose_print("\nğŸ“‹ Key Features Tested:")
    verbose_print("  âœ… Spatial information preservation (vs GAP information loss)")
    verbose_print("  âœ… Spatial attention mechanism")
    verbose_print("  âœ… Configurable spatial_size (2x2, 4x4, 8x8)")
    verbose_print("  âœ… Single-scale & Multi-scale support")
    verbose_print("  âœ… Backward compatibility with existing GAP mode")
    verbose_print("  âœ… Performance characteristics")
    
    verbose_print("\nRun individual tests with:")
    verbose_print("pytest tests/unit/models/image/draem_sevnet/test_spatial_aware_features.py::TestSpatialAwareSeverityHead::test_<method_name> -v -s")


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œì—ëŠ” pytest ì‹¤í–‰ì„ ê¶Œì¥
    print("\nğŸ§ª DRAEM-SevNet Spatial-Aware Features Test Suite")
    print("=" * 60)
    print("To run tests with verbose output:")
    print("pytest tests/unit/models/image/draem_sevnet/test_spatial_aware_features.py -v -s")
    print("\nTo run specific test class:")
    print("pytest tests/unit/models/image/draem_sevnet/test_spatial_aware_features.py::TestSpatialAwareSeverityHead -v -s")
    print("\nTo run specific test method:")
    print("pytest tests/unit/models/image/draem_sevnet/test_spatial_aware_features.py::TestSpatialAwareSeverityHead::test_spatial_aware_initialization -v -s")
    print("\n" + "=" * 60)
