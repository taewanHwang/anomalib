#!/usr/bin/env python3
"""
CutPaste Synthetic Generator v2 ë¶„ì„ í…ŒìŠ¤íŠ¸

synthetic_generator_v2.pyì˜ CutPasteSyntheticGeneratorë¥¼ ì‚¬ìš©í•˜ì—¬
ë‹¤ì–‘í•œ ì •ê·œí™” ì¡°ê±´ì—ì„œ augmentation ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
cd /mnt/ex-disk/taewan.hwang/study/anomalib
python tests/unit/models/image/draem_cutpaste_clf/test_synthetic_generator_analysis.py
"""

import os
import sys
import random
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import torch
from PIL import Image
from typing import Dict, List, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parents[5]
sys.path.insert(0, str(project_root))

# í•„ìš”í•œ ëª¨ë“ˆ import
from src.anomalib.models.image.draem_cutpaste_clf.synthetic_generator_v2 import CutPasteSyntheticGenerator

# =============================================================================
# ğŸ”§ í…ŒìŠ¤íŠ¸ ì„¤ì • (ì‚¬ìš©ìê°€ ì§ì ‘ ìˆ˜ì • ê°€ëŠ¥)
# =============================================================================
class TestConfig:
    """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
    # CutPaste íŒŒë¼ë¯¸í„°
    CUT_W_RANGE = (10, 80)        # íŒ¨ì¹˜ ë„ˆë¹„ ë²”ìœ„
    CUT_H_RANGE = (1, 2)          # íŒ¨ì¹˜ ë†’ì´ ë²”ìœ„
    A_FAULT_START = 1.0           # ì¦í­ ì‹œì‘ê°’
    A_FAULT_RANGE_END = 2.0      # ì¦í­ ëê°’
    PROBABILITY = 0.5             # Anomaly ìƒì„± í™•ë¥ 

    # í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°
    NUM_SAMPLES = 30              # ê° ì •ê·œí™” íƒ€ì…ë³„ ìƒì„±í•  ìƒ˜í”Œ ìˆ˜
    DOMAIN = 'A'                  # í…ŒìŠ¤íŠ¸í•  ë„ë©”ì¸
    RANDOM_SEED = 42              # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œê°’
    IMAGE_SIZE = (31, 95)         # ë¦¬ì‚¬ì´ì¦ˆ í¬ê¸° (H, W)

    # ì¶œë ¥ ì„¤ì •
    OUTPUT_DIR = project_root / "tests" / "unit" / "models" / "image" / "draem_cutpaste_clf" / "outputs_synthetic_v2"
    SAVE_INDIVIDUAL_SAMPLES = True  # ê°œë³„ ìƒ˜í”Œ ì €ì¥ ì—¬ë¶€


class SyntheticGeneratorAnalyzer:
    """CutPasteSyntheticGenerator ë¶„ì„ê¸°"""

    def __init__(self, config: TestConfig):
        self.config = config
        self.project_root = project_root
        self.data_root = self.project_root / "datasets" / "HDMAP"
        self.output_dir = config.OUTPUT_DIR
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ì •ê·œí™” íƒ€ì…ë³„ ë°ì´í„° ê²½ë¡œ
        self.normalization_types = {
            'zscore': '10000_tiff_zscore',
            'minmax': '10000_tiff_minmax',
            'original': '10000_tiff_original'
        }

        # Generator ì´ˆê¸°í™”
        self.generator = CutPasteSyntheticGenerator(
            cut_w_range=config.CUT_W_RANGE,
            cut_h_range=config.CUT_H_RANGE,
            a_fault_start=config.A_FAULT_START,
            a_fault_range_end=config.A_FAULT_RANGE_END,
            probability=config.PROBABILITY,
            validation_enabled=True
        )

        print(f"âœ… Generator ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ì„¤ì •: {self.generator.get_config_info()}")

    def load_sample_image(self, normalization_type: str, domain: str = None) -> Tuple[torch.Tensor, str]:
        """ìƒ˜í”Œ ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        domain = domain or self.config.DOMAIN
        data_path = self.data_root / self.normalization_types[normalization_type]
        train_good_path = data_path / f"domain_{domain}" / "train" / "good"

        # TIFF íŒŒì¼ ëª©ë¡
        tiff_files = list(train_good_path.glob("*.tiff")) + list(train_good_path.glob("*.tif"))
        if not tiff_files:
            raise FileNotFoundError(f"No TIFF files found in {train_good_path}")

        # ëœë¤ íŒŒì¼ ì„ íƒ
        random_file = random.choice(tiff_files)

        # ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ
        img = Image.open(random_file)
        if self.config.IMAGE_SIZE:
            img = img.resize((self.config.IMAGE_SIZE[1], self.config.IMAGE_SIZE[0]))  # (W, H) for PIL

        # numpy arrayë¡œ ë³€í™˜ í›„ tensorë¡œ
        img_array = np.array(img).astype(np.float32)
        img_tensor = torch.from_numpy(img_array).unsqueeze(0)  # (1, H, W)

        return img_tensor, str(random_file)

    def generate_samples(self, img_tensor: torch.Tensor, num_samples: int) -> List[Dict]:
        """ì—¬ëŸ¬ augmentation ìƒ˜í”Œ ìƒì„±"""
        results = []

        for i in range(num_samples):
            # Generator í˜¸ì¶œ (patch_info í¬í•¨)
            synthetic, mask, severity_label, patch_info = self.generator(
                img_tensor,
                return_patch_info=True
            )

            # ê²°ê³¼ ì €ì¥
            result = {
                'idx': i,
                'original': img_tensor.clone(),
                'synthetic': synthetic,
                'mask': mask,
                'severity_label': severity_label.item(),
                'patch_info': patch_info,
                'has_anomaly': patch_info['has_anomaly']
            }

            # íŒ¨ì¹˜ í”½ì…€ ì¶”ì¶œ
            if result['has_anomaly']:
                mask_bool = mask[0, 0] > 0
                result['patch_pixels'] = synthetic[0, 0][mask_bool].cpu().numpy()
                result['original_patch_pixels'] = img_tensor[0][mask_bool].cpu().numpy()
            else:
                result['patch_pixels'] = np.array([])
                result['original_patch_pixels'] = np.array([])

            results.append(result)

        return results

    def analyze_statistics(self, results: List[Dict]) -> Dict:
        """í†µê³„ ë¶„ì„"""
        stats = {
            'total_samples': len(results),
            'anomaly_count': sum(1 for r in results if r['has_anomaly']),
            'normal_count': sum(1 for r in results if not r['has_anomaly'])
        }

        # ì›ë³¸ ì´ë¯¸ì§€ í†µê³„
        all_original = np.concatenate([r['original'].numpy().flatten() for r in results])
        stats['original'] = {
            'mean': float(np.mean(all_original)),
            'std': float(np.std(all_original)),
            'min': float(np.min(all_original)),
            'max': float(np.max(all_original))
        }

        # Synthetic ì´ë¯¸ì§€ í†µê³„
        all_synthetic = np.concatenate([r['synthetic'].numpy().flatten() for r in results])
        stats['synthetic'] = {
            'mean': float(np.mean(all_synthetic)),
            'std': float(np.std(all_synthetic)),
            'min': float(np.min(all_synthetic)),
            'max': float(np.max(all_synthetic))
        }

        # íŒ¨ì¹˜ ì˜ì—­ í†µê³„ (anomalyê°€ ìˆëŠ” ê²½ìš°ë§Œ)
        all_patches = []
        all_original_patches = []
        severity_values = []

        for r in results:
            if r['has_anomaly'] and len(r['patch_pixels']) > 0:
                all_patches.extend(r['patch_pixels'])
                all_original_patches.extend(r['original_patch_pixels'])
                severity_values.append(r['severity_label'])

        if all_patches:
            stats['patches'] = {
                'mean': float(np.mean(all_patches)),
                'std': float(np.std(all_patches)),
                'min': float(np.min(all_patches)),
                'max': float(np.max(all_patches)),
                'count': len(all_patches)
            }
            stats['original_patches'] = {
                'mean': float(np.mean(all_original_patches)),
                'std': float(np.std(all_original_patches)),
                'min': float(np.min(all_original_patches)),
                'max': float(np.max(all_original_patches))
            }
            stats['severity'] = {
                'mean': float(np.mean(severity_values)),
                'std': float(np.std(severity_values)),
                'min': float(np.min(severity_values)),
                'max': float(np.max(severity_values))
            }

            # ì¦í­ ë¹„ìœ¨ ê³„ì‚°
            stats['amplification_ratio'] = stats['patches']['mean'] / stats['original_patches']['mean'] if stats['original_patches']['mean'] != 0 else 0

        stats['anomaly_ratio'] = stats['anomaly_count'] / stats['total_samples']

        return stats

    def plot_analysis(self, all_results: Dict[str, List[Dict]], save_path: Path):
        """ì¢…í•© ë¶„ì„ í”Œë¡¯ ìƒì„±"""
        fig = plt.figure(figsize=(20, 16))
        gs = fig.add_gridspec(4, 3, hspace=0.3, wspace=0.25)

        fig.suptitle('CutPaste Synthetic Generator v2 Analysis', fontsize=16, fontweight='bold')

        norm_types = list(all_results.keys())
        colors = {'zscore': 'blue', 'minmax': 'green', 'original': 'red'}

        # 1. íˆìŠ¤í† ê·¸ë¨ ë¹„êµ (ê° ì •ê·œí™” íƒ€ì…ë³„)
        for idx, norm_type in enumerate(norm_types):
            results = all_results[norm_type]
            color = colors[norm_type]

            # Original vs Synthetic íˆìŠ¤í† ê·¸ë¨
            ax = fig.add_subplot(gs[idx, 0])

            all_original = np.concatenate([r['original'].numpy().flatten() for r in results])
            all_synthetic = np.concatenate([r['synthetic'].numpy().flatten() for r in results])

            ax.hist(all_original, bins=50, alpha=0.5, label='Original', color='gray', density=True)
            ax.hist(all_synthetic, bins=50, alpha=0.5, label='Synthetic', color=color, density=True)
            ax.set_title(f'{norm_type.upper()}: Original vs Synthetic')
            ax.set_xlabel('Pixel Value')
            ax.set_ylabel('Density')
            ax.legend()
            ax.grid(True, alpha=0.3)

            # íŒ¨ì¹˜ ì˜ì—­ íˆìŠ¤í† ê·¸ë¨
            ax = fig.add_subplot(gs[idx, 1])

            patch_pixels = []
            original_patch_pixels = []
            for r in results:
                if r['has_anomaly'] and len(r['patch_pixels']) > 0:
                    patch_pixels.extend(r['patch_pixels'])
                    original_patch_pixels.extend(r['original_patch_pixels'])

            if patch_pixels:
                ax.hist(original_patch_pixels, bins=30, alpha=0.5, label='Original Patch', color='gray', density=True)
                ax.hist(patch_pixels, bins=30, alpha=0.5, label='Augmented Patch', color=color, density=True)
                ax.set_title(f'{norm_type.upper()}: Patch Comparison')
                ax.set_xlabel('Pixel Value')
                ax.set_ylabel('Density')
                ax.legend()
                ax.grid(True, alpha=0.3)
            else:
                ax.text(0.5, 0.5, 'No Anomaly Patches', ha='center', va='center', transform=ax.transAxes)
                ax.set_title(f'{norm_type.upper()}: Patch Comparison')

            # Severity ë¶„í¬
            ax = fig.add_subplot(gs[idx, 2])

            severity_values = [r['severity_label'] for r in results if r['has_anomaly']]
            if severity_values:
                ax.hist(severity_values, bins=20, color=color, alpha=0.7)
                ax.set_title(f'{norm_type.upper()}: Severity Distribution')
                ax.set_xlabel('Severity (Amplitude)')
                ax.set_ylabel('Count')
                ax.grid(True, alpha=0.3)

                # í†µê³„ ì •ë³´ ì¶”ê°€
                stats_text = f"Mean: {np.mean(severity_values):.2f}\nStd: {np.std(severity_values):.2f}"
                ax.text(0.7, 0.9, stats_text, transform=ax.transAxes,
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

        # 4. ìƒ˜í”Œ ì´ë¯¸ì§€ ë¹„êµ (ë§ˆì§€ë§‰ í–‰)
        for idx, norm_type in enumerate(norm_types):
            results = all_results[norm_type]

            # Anomaly ìƒ˜í”Œ ì°¾ê¸°
            anomaly_sample = None
            for r in results:
                if r['has_anomaly']:
                    anomaly_sample = r
                    break

            if anomaly_sample:
                ax = fig.add_subplot(gs[3, idx])

                # Originalê³¼ Syntheticì„ ë‚˜ë€íˆ í‘œì‹œ
                original_img = anomaly_sample['original'][0].numpy().squeeze()  # Remove channel dimension
                synthetic_img = anomaly_sample['synthetic'][0, 0].numpy()
                mask = anomaly_sample['mask'][0, 0].numpy()

                # 3ê°œ ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (2D arrays)
                separator = np.ones((original_img.shape[0], 2)) * np.max(original_img)
                combined = np.hstack([
                    original_img,
                    separator,
                    synthetic_img,
                    separator,
                    mask * np.max(original_img)
                ])

                ax.imshow(combined, cmap='viridis')
                ax.set_title(f'{norm_type.upper()}: Original | Synthetic | Mask')
                ax.axis('off')

                # íŒ¨ì¹˜ ì •ë³´ ì¶”ê°€
                patch_info = anomaly_sample['patch_info']
                info_text = f"Size: {patch_info['cut_w']}Ã—{patch_info['cut_h']}\n"
                info_text += f"Amplitude: {patch_info['a_fault']:.2f}\n"
                info_text += f"Coverage: {patch_info['coverage_percentage']:.1f}%"
                ax.text(0.02, 0.98, info_text, transform=ax.transAxes,
                       verticalalignment='top', fontsize=8,
                       bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))

        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š ë¶„ì„ í”Œë¡¯ ì €ì¥ë¨: {save_path}")

    def save_individual_samples(self, results: List[Dict], norm_type: str, output_dir: Path):
        """ê°œë³„ ìƒ˜í”Œ ì €ì¥"""
        sample_dir = output_dir / f"samples_{norm_type}"
        sample_dir.mkdir(exist_ok=True)

        # Anomaly ìƒ˜í”Œë§Œ ì €ì¥ (ìµœëŒ€ 5ê°œ)
        anomaly_samples = [r for r in results if r['has_anomaly']][:5]

        for i, sample in enumerate(anomaly_samples):
            try:
                fig, axes = plt.subplots(1, 3, figsize=(12, 4))

                # Original
                axes[0].imshow(sample['original'][0].numpy().squeeze(), cmap='viridis')
                axes[0].set_title('Original')
                axes[0].axis('off')

                # Synthetic
                axes[1].imshow(sample['synthetic'][0, 0].numpy(), cmap='viridis')
                axes[1].set_title('Synthetic')
                axes[1].axis('off')

                # Mask
                axes[2].imshow(sample['mask'][0, 0].numpy(), cmap='hot')
                axes[2].set_title('Mask')
                axes[2].axis('off')

                # íŒ¨ì¹˜ ì •ë³´ ì¶”ê°€
                patch_info = sample['patch_info']
                info_text = f"Patch: {patch_info['cut_w']}Ã—{patch_info['cut_h']}\n"
                info_text += f"From: ({patch_info['from_location_w']}, {patch_info['from_location_h']})\n"
                info_text += f"To: ({patch_info['to_location_w']}, {patch_info['to_location_h']})\n"
                info_text += f"Amplitude: {patch_info['a_fault']:.2f}"

                fig.text(0.02, 0.5, info_text, fontsize=10,
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

                plt.tight_layout()
                save_path = sample_dir / f"sample_{i:02d}.png"
                plt.savefig(save_path, dpi=100, bbox_inches='tight')
                plt.close()
            except Exception as e:
                print(f"      Warning: Could not save sample {i}: {e}")
                plt.close()
                continue

        if len(anomaly_samples) > 0:
            print(f"   ğŸ’¾ ìƒ˜í”Œ ì €ì¥ë¨: {sample_dir}")

    def generate_report(self, all_stats: Dict[str, Dict], save_path: Path):
        """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("CutPaste Synthetic Generator v2 Analysis Report\n")
            f.write("=" * 80 + "\n\n")

            # Generator ì„¤ì •
            f.write("Generator Configuration:\n")
            f.write("-" * 40 + "\n")
            config_info = self.generator.get_config_info()
            for key, value in config_info.items():
                f.write(f"  {key}: {value}\n")
            f.write("\n")

            # í…ŒìŠ¤íŠ¸ ì„¤ì •
            f.write("Test Configuration:\n")
            f.write("-" * 40 + "\n")
            f.write(f"  NUM_SAMPLES: {self.config.NUM_SAMPLES}\n")
            f.write(f"  DOMAIN: {self.config.DOMAIN}\n")
            f.write(f"  IMAGE_SIZE: {self.config.IMAGE_SIZE}\n")
            f.write(f"  RANDOM_SEED: {self.config.RANDOM_SEED}\n\n")

            # ê° ì •ê·œí™” íƒ€ì…ë³„ í†µê³„
            for norm_type, stats in all_stats.items():
                f.write(f"\n{norm_type.upper()} Normalization Analysis:\n")
                f.write("=" * 60 + "\n")

                f.write(f"Sample Distribution:\n")
                f.write(f"  Total: {stats['total_samples']}\n")
                f.write(f"  Anomaly: {stats['anomaly_count']} ({stats['anomaly_ratio']*100:.1f}%)\n")
                f.write(f"  Normal: {stats['normal_count']} ({(1-stats['anomaly_ratio'])*100:.1f}%)\n\n")

                f.write(f"Original Image Statistics:\n")
                f.write(f"  Mean: {stats['original']['mean']:.6f}\n")
                f.write(f"  Std: {stats['original']['std']:.6f}\n")
                f.write(f"  Range: [{stats['original']['min']:.6f}, {stats['original']['max']:.6f}]\n\n")

                f.write(f"Synthetic Image Statistics:\n")
                f.write(f"  Mean: {stats['synthetic']['mean']:.6f}\n")
                f.write(f"  Std: {stats['synthetic']['std']:.6f}\n")
                f.write(f"  Range: [{stats['synthetic']['min']:.6f}, {stats['synthetic']['max']:.6f}]\n\n")

                if 'patches' in stats:
                    f.write(f"Patch Region Statistics:\n")
                    f.write(f"  Original Patch Mean: {stats['original_patches']['mean']:.6f}\n")
                    f.write(f"  Augmented Patch Mean: {stats['patches']['mean']:.6f}\n")
                    f.write(f"  Amplification Ratio: {stats['amplification_ratio']:.3f}x\n")
                    f.write(f"  Patch Std: {stats['patches']['std']:.6f}\n")
                    f.write(f"  Patch Range: [{stats['patches']['min']:.6f}, {stats['patches']['max']:.6f}]\n\n")

                    f.write(f"Severity Statistics:\n")
                    f.write(f"  Mean: {stats['severity']['mean']:.3f}\n")
                    f.write(f"  Std: {stats['severity']['std']:.3f}\n")
                    f.write(f"  Range: [{stats['severity']['min']:.3f}, {stats['severity']['max']:.3f}]\n")
                else:
                    f.write(f"Patch Region Statistics: No anomaly patches generated\n")

                f.write("\n" + "-" * 60 + "\n")

            f.write("\n" + "=" * 80 + "\n")
            f.write("End of Report\n")
            f.write("=" * 80 + "\n")

        print(f"ğŸ“„ ë¦¬í¬íŠ¸ ì €ì¥ë¨: {save_path}")

    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("\n" + "=" * 80)
        print("ğŸš€ CutPaste Synthetic Generator v2 Analysis Started")
        print("=" * 80 + "\n")

        all_results = {}
        all_stats = {}

        # ê° ì •ê·œí™” íƒ€ì…ë³„ë¡œ ë¶„ì„
        for norm_type in self.normalization_types.keys():
            print(f"\nğŸ“Š Analyzing {norm_type.upper()} normalization...")

            try:
                # ì´ë¯¸ì§€ ë¡œë“œ
                img_tensor, filename = self.load_sample_image(norm_type)
                print(f"   âœ“ Image loaded: {Path(filename).name}")
                print(f"   âœ“ Shape: {img_tensor.shape}")
                print(f"   âœ“ Range: [{img_tensor.min():.4f}, {img_tensor.max():.4f}]")

                # ìƒ˜í”Œ ìƒì„±
                results = self.generate_samples(img_tensor, self.config.NUM_SAMPLES)
                all_results[norm_type] = results

                # í†µê³„ ë¶„ì„
                stats = self.analyze_statistics(results)
                all_stats[norm_type] = stats

                print(f"   âœ“ Generated {len(results)} samples")
                print(f"   âœ“ Anomaly ratio: {stats['anomaly_ratio']*100:.1f}%")

                # ê°œë³„ ìƒ˜í”Œ ì €ì¥
                if self.config.SAVE_INDIVIDUAL_SAMPLES:
                    self.save_individual_samples(results, norm_type, self.output_dir)

            except Exception as e:
                print(f"   âŒ Error processing {norm_type}: {e}")
                continue

        # ì¢…í•© ë¶„ì„ í”Œë¡¯
        print(f"\nğŸ“Š Generating analysis plots...")
        plot_path = self.output_dir / "synthetic_v2_analysis.png"
        self.plot_analysis(all_results, plot_path)

        # ë¦¬í¬íŠ¸ ìƒì„±
        report_path = self.output_dir / "synthetic_v2_report.txt"
        self.generate_report(all_stats, report_path)

        print("\n" + "=" * 80)
        print("âœ… Analysis Complete!")
        print(f"ğŸ“ Results saved to: {self.output_dir}")
        print("=" * 80)

        return all_results, all_stats


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì • ì´ˆê¸°í™”
    config = TestConfig()

    # ëœë¤ ì‹œë“œ ì„¤ì •
    random.seed(config.RANDOM_SEED)
    np.random.seed(config.RANDOM_SEED)
    torch.manual_seed(config.RANDOM_SEED)

    # ë¶„ì„ê¸° ìƒì„± ë° ì‹¤í–‰
    analyzer = SyntheticGeneratorAnalyzer(config)
    results, stats = analyzer.run_analysis()

    # ì„ íƒì : ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì—¬ ì¶”ê°€ ë¶„ì„ ê°€ëŠ¥
    return results, stats


if __name__ == "__main__":
    main()