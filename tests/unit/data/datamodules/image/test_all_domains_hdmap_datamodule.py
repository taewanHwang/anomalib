#!/usr/bin/env python3
"""AllDomains HDMAP DataModule í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸.

ìƒˆë¡œ êµ¬í˜„ëœ AllDomainsHDMAPDataModuleì˜ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
Multi-class Unified Model Anomaly Detectionì„ ìœ„í•œ í†µí•© ë°ì´í„° ì²˜ë¦¬ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
"""

from pathlib import Path
import torch

from anomalib.data.datamodules.image.all_domains_hdmap import AllDomainsHDMAPDataModule


def test_all_domains_hdmap_datamodule():
    """AllDomainsHDMAPDataModule ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸."""
    print("="*80)
    print("AllDomains HDMAP DataModule í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*80)
    
    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    root_path = "./datasets/HDMAP/1000_8bit_resize_224x224"
    
    try:
        # AllDomainsHDMAPDataModule ìƒì„±
        print("\n1. AllDomainsHDMAPDataModule ìƒì„± ì¤‘...")
        datamodule = AllDomainsHDMAPDataModule(
            root=root_path,
            domains=None,  # ëª¨ë“  ë„ë©”ì¸ ì‚¬ìš© (A, B, C, D)
            train_batch_size=16,
            eval_batch_size=8,
            num_workers=2,
            val_split_ratio=0.2,  # trainì—ì„œ 20% validation ë¶„í• 
        )
        
        print(f"âœ… DataModule ì´ë¦„: {datamodule.name}")
        print(f"âœ… ì¹´í…Œê³ ë¦¬: {datamodule.category}")
        print(f"âœ… ë£¨íŠ¸ ê²½ë¡œ: {datamodule.root}")
        print(f"âœ… í¬í•¨ ë„ë©”ì¸: {datamodule.domains}")
        print(f"âœ… í›ˆë ¨ ë°°ì¹˜ í¬ê¸°: {datamodule.train_batch_size}")
        print(f"âœ… í‰ê°€ ë°°ì¹˜ í¬ê¸°: {datamodule.eval_batch_size}")
        print(f"âœ… Validation ë¶„í•  ë¹„ìœ¨: {datamodule.val_split_ratio}")
        
        # ë°ì´í„° ì¤€ë¹„ ë° ì„¤ì •
        print("\n2. ë°ì´í„° ì¤€ë¹„ ë° ì„¤ì • ì¤‘...")
        datamodule.prepare_data()
        datamodule.setup()
        
        print(f"âœ… í›ˆë ¨ ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {len(datamodule.train_data)}")
        print(f"âœ… ê²€ì¦ ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {len(datamodule.val_data) if datamodule.val_data else 0}")  
        print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {len(datamodule.test_data)}")
        
        # ì˜ˆìƒ ìƒ˜í”Œ ìˆ˜ ê³„ì‚° ë° ê²€ì¦
        expected_train_total = 4000  # 1000 * 4 domains
        expected_test_total = 6400   # 1600 * 4 domains (ì¶”ì •)
        expected_val_samples = int(expected_train_total * datamodule.val_split_ratio)
        expected_train_samples = expected_train_total - expected_val_samples
        
        print(f"\nğŸ“Š ë°ì´í„° ë¶„í•  ê²€ì¦:")
        print(f"   ì˜ˆìƒ Train: {expected_train_samples}, ì‹¤ì œ: {len(datamodule.train_data)}")
        print(f"   ì˜ˆìƒ Val: {expected_val_samples}, ì‹¤ì œ: {len(datamodule.val_data) if datamodule.val_data else 0}")
        print(f"   ì˜ˆìƒ Test: {expected_test_total}, ì‹¤ì œ: {len(datamodule.test_data)}")
        
        # ë°ì´í„° ë¶„í• ì˜ ë¼ë²¨ ë¶„í¬ ìƒì„¸ ë¶„ì„
        print(f"\nğŸ” ë°ì´í„°ì…‹ë³„ ë¼ë²¨ ë¶„í¬ ìƒì„¸ ë¶„ì„:")
        
        # Train ë°ì´í„° ë¼ë²¨ ë¶„í¬ (ì •ìƒë§Œ ìˆì–´ì•¼ í•¨)
        train_samples_df = datamodule.train_data.samples
        train_label_counts = train_samples_df['label_index'].value_counts().sort_index()
        print(f"   ğŸ“Š Train ë°ì´í„° ë¼ë²¨ ë¶„í¬:")
        for label_idx, count in train_label_counts.items():
            label_name = "ì •ìƒ(good)" if label_idx == 0 else "ê²°í•¨(fault)"
            print(f"      {label_name}: {count}ê°œ")
        
        if len(train_label_counts) == 1 and 0 in train_label_counts:
            print("   âœ… í™•ì¸: Train ë°ì´í„°ëŠ” ì •ìƒ ë°ì´í„°ë§Œ í¬í•¨")
        else:
            print("   âš ï¸  ê²½ê³ : Train ë°ì´í„°ì— ê²°í•¨ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
        
        # Validation ë°ì´í„° ë¼ë²¨ ë¶„í¬ (ì •ìƒë§Œ ìˆì–´ì•¼ í•¨ - trainì—ì„œ ë¶„í• )
        if datamodule.val_data:
            val_samples_df = datamodule.val_data.samples
            val_label_counts = val_samples_df['label_index'].value_counts().sort_index()
            print(f"   ğŸ“Š Validation ë°ì´í„° ë¼ë²¨ ë¶„í¬:")
            for label_idx, count in val_label_counts.items():
                label_name = "ì •ìƒ(good)" if label_idx == 0 else "ê²°í•¨(fault)"
                print(f"      {label_name}: {count}ê°œ")
            
            if len(val_label_counts) == 1 and 0 in val_label_counts:
                print("   âœ… í™•ì¸: Validation ë°ì´í„°ëŠ” ì •ìƒ ë°ì´í„°ë§Œ í¬í•¨ (trainì—ì„œ ë¶„í• )")
            else:
                print("   âš ï¸  ê²½ê³ : Validation ë°ì´í„°ì— ê²°í•¨ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
        
        # Test ë°ì´í„° ë¼ë²¨ ë¶„í¬ (ì •ìƒ+ê²°í•¨ ëª¨ë‘ ìˆì–´ì•¼ í•¨)
        test_samples_df = datamodule.test_data.samples
        test_label_counts = test_samples_df['label_index'].value_counts().sort_index()
        print(f"   ğŸ“Š Test ë°ì´í„° ë¼ë²¨ ë¶„í¬:")
        for label_idx, count in test_label_counts.items():
            label_name = "ì •ìƒ(good)" if label_idx == 0 else "ê²°í•¨(fault)"
            print(f"      {label_name}: {count}ê°œ")
        
        if len(test_label_counts) == 2 and 0 in test_label_counts and 1 in test_label_counts:
            print("   âœ… í™•ì¸: Test ë°ì´í„°ëŠ” ì •ìƒ+ê²°í•¨ ë°ì´í„° ëª¨ë‘ í¬í•¨")
            normal_ratio = test_label_counts[0] / len(test_samples_df) * 100
            fault_ratio = test_label_counts[1] / len(test_samples_df) * 100
            print(f"   ğŸ“ˆ Test ë°ì´í„° ë¹„ìœ¨: ì •ìƒ {normal_ratio:.1f}%, ê²°í•¨ {fault_ratio:.1f}%")
        else:
            print("   âš ï¸  ê²½ê³ : Test ë°ì´í„°ì— ì •ìƒ ë˜ëŠ” ê²°í•¨ ë°ì´í„°ê°€ ëˆ„ë½ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
        
        # DataLoader ìƒì„± ë° í…ŒìŠ¤íŠ¸
        print("\n3. DataLoader ìƒì„± ë° ë°°ì¹˜ í…ŒìŠ¤íŠ¸...")
        train_loader = datamodule.train_dataloader()
        val_loader = datamodule.val_dataloader()
        test_loader = datamodule.test_dataloader()
        
        print(f"âœ… í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
        print(f"âœ… ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader) if val_loader else 0}")
        print(f"âœ… í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: {len(test_loader)}")
        
        # ìƒ˜í”Œ ë°°ì¹˜ í™•ì¸
        print("\n4. ìƒ˜í”Œ ë°°ì¹˜ ë°ì´í„° í™•ì¸...")
        train_batch = next(iter(train_loader))
        print(f"âœ… í›ˆë ¨ ë°°ì¹˜ ì´ë¯¸ì§€ í˜•íƒœ: {train_batch.image.shape}")
        print(f"âœ… í›ˆë ¨ ì´ë¯¸ì§€ ì±„ë„ ìˆ˜: {train_batch.image.shape[1]} (C, H, W ìˆœì„œ)")
        print(f"âœ… í›ˆë ¨ ì´ë¯¸ì§€ ë°ì´í„° íƒ€ì…: {train_batch.image.dtype}")
        print(f"âœ… í›ˆë ¨ ì´ë¯¸ì§€ ê°’ ë²”ìœ„: {train_batch.image.min().item():.4f} ~ {train_batch.image.max().item():.4f}")
        print(f"âœ… í›ˆë ¨ ë°°ì¹˜ ë¼ë²¨ í˜•íƒœ: {train_batch.gt_label.shape}")
        print(f"âœ… í›ˆë ¨ ë¼ë²¨ ê°’ ë²”ìœ„: {train_batch.gt_label.min().item()} ~ {train_batch.gt_label.max().item()}")
        
        # Train ë°°ì¹˜ëŠ” ì •ìƒ ë°ì´í„°ë§Œ ìˆì–´ì•¼ í•¨
        normal_count = (train_batch.gt_label == 0).sum().item()
        fault_count = (train_batch.gt_label == 1).sum().item()
        print(f"âœ… í›ˆë ¨ ë°°ì¹˜ - ì •ìƒ: {normal_count}ê°œ, ê²°í•¨: {fault_count}ê°œ")
        if fault_count == 0:
            print("   ğŸ” í™•ì¸: í›ˆë ¨ ë°ì´í„°ëŠ” ì •ìƒ ë°ì´í„°ë§Œ í¬í•¨ (Anomaly Detection íŠ¹ì„±)")
        else:
            print("   âš ï¸  ê²½ê³ : í›ˆë ¨ ë°ì´í„°ì— ê²°í•¨ ë°ì´í„° í¬í•¨ë¨!")
        
        if test_loader:
            test_batch = next(iter(test_loader))
            print(f"âœ… í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì´ë¯¸ì§€ í˜•íƒœ: {test_batch.image.shape}")
            print(f"âœ… í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì±„ë„ ìˆ˜: {test_batch.image.shape[1]} (C, H, W ìˆœì„œ)")
            print(f"âœ… í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë°ì´í„° íƒ€ì…: {test_batch.image.dtype}")
            print(f"âœ… í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê°’ ë²”ìœ„: {test_batch.image.min().item():.4f} ~ {test_batch.image.max().item():.4f}")
            
            # RGB ì±„ë„ë³„ ë™ì¼ì„± í™•ì¸ (grayscale â†’ RGB ë³€í™˜ í™•ì¸)
            if test_batch.image.shape[1] == 3:
                r_channel = test_batch.image[:, 0, :, :]
                g_channel = test_batch.image[:, 1, :, :] 
                b_channel = test_batch.image[:, 2, :, :]
                
                channels_identical = torch.allclose(r_channel, g_channel) and torch.allclose(g_channel, b_channel)
                print(f"âœ… RGB ì±„ë„ ë™ì¼ì„± (grayscale â†’ RGB ë³€í™˜): {'Yes' if channels_identical else 'No'}")
                
                if channels_identical:
                    print("   ğŸ” í™•ì¸: Grayscale ì´ë¯¸ì§€ê°€ RGBë¡œ ë³€í™˜ë¨ (R=G=B)")
                else:
                    print("   ğŸ” ì‹¤ì œ RGB ì»¬ëŸ¬ ì´ë¯¸ì§€")
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¼ë²¨ ë¶„í¬ í™•ì¸ (ì •ìƒ+ê²°í•¨ ëª¨ë‘ ìˆì–´ì•¼ í•¨)
            test_normal_count = (test_batch.gt_label == 0).sum().item()
            test_fault_count = (test_batch.gt_label == 1).sum().item()
            print(f"âœ… í…ŒìŠ¤íŠ¸ ë°°ì¹˜ - ì •ìƒ: {test_normal_count}ê°œ, ê²°í•¨: {test_fault_count}ê°œ")
            
            # Validation ë°°ì¹˜ ë¼ë²¨ ë¶„í¬ë„ í™•ì¸
            if val_loader:
                val_batch = next(iter(val_loader))
                val_normal_count = (val_batch.gt_label == 0).sum().item()
                val_fault_count = (val_batch.gt_label == 1).sum().item()
                print(f"âœ… ê²€ì¦ ë°°ì¹˜ - ì •ìƒ: {val_normal_count}ê°œ, ê²°í•¨: {val_fault_count}ê°œ")
                if val_fault_count == 0:
                    print("   ğŸ” í™•ì¸: ê²€ì¦ ë°ì´í„°ë„ ì •ìƒ ë°ì´í„°ë§Œ í¬í•¨ (trainì—ì„œ ë¶„í• )")
                else:
                    print("   âš ï¸  ê²½ê³ : ê²€ì¦ ë°ì´í„°ì— ê²°í•¨ ë°ì´í„° í¬í•¨ë¨!")
        
        # ë„ë©”ì¸ í†µí•© ê²€ì¦
        print(f"\n5. ë„ë©”ì¸ í†µí•© ê²€ì¦...")
        
        # ë„ë©”ì¸ë³„ ìƒ˜í”Œ ë¶„í¬ ë° ë¼ë²¨ ë¶„í¬ êµì°¨ í™•ì¸
        print(f"âœ… ë„ë©”ì¸ë³„ ìƒì„¸ ë¶„í¬ ë¶„ì„:")
        
        # Train ë°ì´í„°: ë„ë©”ì¸ë³„ + ë¼ë²¨ë³„ ë¶„í¬
        train_samples_df = datamodule.train_data.samples
        print(f"   ğŸ“Š í›ˆë ¨ ë°ì´í„° ë„ë©”ì¸ë³„ ë¶„í¬:")
        for domain in datamodule.domains:
            domain_data = train_samples_df[train_samples_df['domain'] == domain]
            domain_label_counts = domain_data['label_index'].value_counts().sort_index()
            normal_count = domain_label_counts.get(0, 0)
            fault_count = domain_label_counts.get(1, 0)
            print(f"      {domain}: ì´ {len(domain_data)}ê°œ (ì •ìƒ: {normal_count}, ê²°í•¨: {fault_count})")
        
        # Test ë°ì´í„°: ë„ë©”ì¸ë³„ + ë¼ë²¨ë³„ ë¶„í¬  
        test_samples_df = datamodule.test_data.samples
        print(f"   ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ë„ë©”ì¸ë³„ ë¶„í¬:")
        for domain in datamodule.domains:
            domain_data = test_samples_df[test_samples_df['domain'] == domain]
            domain_label_counts = domain_data['label_index'].value_counts().sort_index()
            normal_count = domain_label_counts.get(0, 0)
            fault_count = domain_label_counts.get(1, 0)
            print(f"      {domain}: ì´ {len(domain_data)}ê°œ (ì •ìƒ: {normal_count}, ê²°í•¨: {fault_count})")
        
        # Anomaly Detection ë°ì´í„° íŠ¹ì„± ìš”ì•½
        print(f"\nğŸ¯ Anomaly Detection ë°ì´í„° íŠ¹ì„± ìš”ì•½:")
        print(f"   âœ… Train/Validation: ì •ìƒ ë°ì´í„°ë§Œ ì‚¬ìš© (ë¹„ì§€ë„ í•™ìŠµ)")
        print(f"   âœ… Test: ì •ìƒ+ê²°í•¨ ë°ì´í„° ëª¨ë‘ ì‚¬ìš© (ì„±ëŠ¥ í‰ê°€)")
        print(f"   âœ… ë„ë©”ì¸ í†µí•©: {len(datamodule.domains)}ê°œ ë„ë©”ì¸ ë°ì´í„° í†µí•©")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_specific_domains():
    """íŠ¹ì • ë„ë©”ì¸ë§Œ ì„ íƒí•˜ì—¬ í…ŒìŠ¤íŠ¸."""
    print("\n" + "="*80)
    print("íŠ¹ì • ë„ë©”ì¸ ì„ íƒ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    root_path = "./datasets/HDMAP/1000_8bit_resize_224x224"
    
    try:
        # A, B ë„ë©”ì¸ë§Œ ì‚¬ìš©
        print("\n1. íŠ¹ì • ë„ë©”ì¸ (A, B) ì„¤ì •...")
        datamodule = AllDomainsHDMAPDataModule(
            root=root_path,
            domains=["domain_A", "domain_B"],  # A, Bë§Œ ì‚¬ìš©
            train_batch_size=16,
            eval_batch_size=8,
            num_workers=2,
            val_split_ratio=0.25,  # 25% validation
        )
        
        datamodule.prepare_data()
        datamodule.setup()
        
        print(f"âœ… ì„ íƒëœ ë„ë©”ì¸: {datamodule.domains}")
        print(f"âœ… í›ˆë ¨ ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {len(datamodule.train_data)}")
        print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {len(datamodule.test_data)}")
        
        # ì˜ˆìƒ ê°’ê³¼ ë¹„êµ
        expected_total_train = 2000  # 1000 * 2 domains  
        expected_val = int(expected_total_train * 0.25)  # 500
        expected_train = expected_total_train - expected_val  # 1500
        expected_test = 3200  # 1600 * 2 domains
        
        print(f"\nğŸ“Š íŠ¹ì • ë„ë©”ì¸ ë°ì´í„° ê²€ì¦:")
        print(f"   ì˜ˆìƒ Train: {expected_train}, ì‹¤ì œ: {len(datamodule.train_data)}")
        print(f"   ì˜ˆìƒ Val: {expected_val}, ì‹¤ì œ: {len(datamodule.val_data) if datamodule.val_data else 0}")
        print(f"   ì˜ˆìƒ Test: {expected_test}, ì‹¤ì œ: {len(datamodule.test_data)}")
        
        # íŠ¹ì • ë„ë©”ì¸ì˜ ë¼ë²¨ ë¶„í¬ ìƒì„¸ í™•ì¸
        print(f"âœ… íŠ¹ì • ë„ë©”ì¸ ì„ íƒ ì‹œ ë¼ë²¨ ë¶„í¬ í™•ì¸:")
        
        # Train ë°ì´í„° ë¼ë²¨ ë¶„í¬
        train_samples_df = datamodule.train_data.samples
        train_label_counts = train_samples_df['label_index'].value_counts().sort_index()
        print(f"   ğŸ“Š Train ë¼ë²¨ ë¶„í¬:")
        for label_idx, count in train_label_counts.items():
            label_name = "ì •ìƒ(good)" if label_idx == 0 else "ê²°í•¨(fault)"
            print(f"      {label_name}: {count}ê°œ")
        
        # Test ë°ì´í„° ë¼ë²¨ ë¶„í¬
        test_samples_df = datamodule.test_data.samples  
        test_label_counts = test_samples_df['label_index'].value_counts().sort_index()
        print(f"   ğŸ“Š Test ë¼ë²¨ ë¶„í¬:")
        for label_idx, count in test_label_counts.items():
            label_name = "ì •ìƒ(good)" if label_idx == 0 else "ê²°í•¨(fault)"
            print(f"      {label_name}: {count}ê°œ")
        
        # ë„ë©”ì¸ë³„ ë¶„í¬
        train_domain_counts = train_samples_df['domain'].value_counts()
        print(f"   ğŸ“Š í›ˆë ¨ ë°ì´í„° ë„ë©”ì¸ë³„ ë¶„í¬:")
        for domain, count in train_domain_counts.items():
            print(f"      {domain}: {count}ê°œ")
        
        return True
        
    except Exception as e:
        print(f"âŒ íŠ¹ì • ë„ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


def compare_with_existing_datamodules():
    """ê¸°ì¡´ DataModuleë“¤ê³¼ ë¹„êµ í…ŒìŠ¤íŠ¸."""
    print("\n" + "="*80)
    print("ê¸°ì¡´ DataModuleë“¤ê³¼ ë¹„êµ")
    print("="*80)
    
    root_path = "./datasets/HDMAP/1000_8bit_resize_224x224"
    
    try:
        from anomalib.data.datamodules.image.hdmap import HDMAPDataModule
        from anomalib.data.datamodules.image.multi_domain_hdmap import MultiDomainHDMAPDataModule
        
        print("\nğŸ“Š DataModuleë³„ ë°ì´í„° êµ¬ì„± ë¹„êµ:")
        
        # 1. HDMAPDataModule (ë‹¨ì¼ ë„ë©”ì¸)
        single_dm = HDMAPDataModule(
            root=root_path,
            domain="domain_A",
            train_batch_size=16,
            eval_batch_size=8,
            num_workers=2,
        )
        single_dm.setup()
        
        print(f"\n1. HDMAPDataModule (domain_A):")
        print(f"   Train: {len(single_dm.train_data)}ê°œ")
        print(f"   Val: {len(single_dm.val_data) if single_dm.val_data else 0}ê°œ")
        print(f"   Test: {len(single_dm.test_data)}ê°œ")
        
        # 2. MultiDomainHDMAPDataModule (ë„ë©”ì¸ ì „ì´)
        multi_dm = MultiDomainHDMAPDataModule(
            root=root_path,
            source_domain="domain_A",
            target_domains=["domain_B", "domain_C"],
            train_batch_size=16,
            eval_batch_size=8,
            num_workers=2,
        )
        multi_dm.setup()
        
        print(f"\n2. MultiDomainHDMAPDataModule (Aâ†’B,C):")
        print(f"   Train: {len(multi_dm.train_data)}ê°œ (ì†ŒìŠ¤ ë„ë©”ì¸ë§Œ)")
        print(f"   Val: {len(multi_dm.val_data) if multi_dm.val_data else 0}ê°œ (ì†ŒìŠ¤ test)")
        print(f"   Test: {sum(len(test_data) for test_data in multi_dm.test_data)}ê°œ (íƒ€ê²Ÿ ë„ë©”ì¸ë“¤)")
        
        # 3. AllDomainsHDMAPDataModule (ëª¨ë“  ë„ë©”ì¸ í†µí•©)
        all_dm = AllDomainsHDMAPDataModule(
            root=root_path,
            domains=None,  # ëª¨ë“  ë„ë©”ì¸
            train_batch_size=16,
            eval_batch_size=8,
            num_workers=2,
            val_split_ratio=0.2,
        )
        all_dm.setup()
        
        print(f"\n3. AllDomainsHDMAPDataModule (ëª¨ë“  ë„ë©”ì¸):")
        print(f"   Train: {len(all_dm.train_data)}ê°œ (ëª¨ë“  ë„ë©”ì¸ í†µí•©)")
        print(f"   Val: {len(all_dm.val_data) if all_dm.val_data else 0}ê°œ (trainì—ì„œ ë¶„í• )")
        print(f"   Test: {len(all_dm.test_data)}ê°œ (ëª¨ë“  ë„ë©”ì¸ í†µí•©)")
        
        print(f"\nğŸ¯ ì‚¬ìš© ìš©ë„ë³„ ì¶”ì²œ:")
        print(f"   - ë‹¨ì¼ ë„ë©”ì¸ í•™ìŠµ: HDMAPDataModule")
        print(f"   - ë„ë©”ì¸ ì „ì´ í•™ìŠµ: MultiDomainHDMAPDataModule")
        print(f"   - ë©€í‹°í´ë˜ìŠ¤ í†µí•© í•™ìŠµ: AllDomainsHDMAPDataModule â­")
        
        # ê° DataModuleì˜ ë¼ë²¨ ë¶„í¬ íŠ¹ì„± ìš”ì•½
        print(f"\nğŸ“Š DataModuleë³„ ë¼ë²¨ ë¶„í¬ íŠ¹ì„±:")
        print(f"   ğŸ”¹ HDMAPDataModule:")
        print(f"      - Train: ì •ìƒë§Œ (ë‹¨ì¼ ë„ë©”ì¸)")
        print(f"      - Test: ì •ìƒ+ê²°í•¨ (ë‹¨ì¼ ë„ë©”ì¸)")
        print(f"   ğŸ”¹ MultiDomainHDMAPDataModule:")
        print(f"      - Train: ì •ìƒë§Œ (ì†ŒìŠ¤ ë„ë©”ì¸)")
        print(f"      - Val: ì •ìƒ+ê²°í•¨ (ì†ŒìŠ¤ ë„ë©”ì¸ test)")
        print(f"      - Test: ì •ìƒ+ê²°í•¨ (íƒ€ê²Ÿ ë„ë©”ì¸ë“¤)")
        print(f"   ğŸ”¹ AllDomainsHDMAPDataModule â­:")
        print(f"      - Train: ì •ìƒë§Œ (ëª¨ë“  ë„ë©”ì¸ í†µí•©)")
        print(f"      - Val: ì •ìƒë§Œ (trainì—ì„œ ë¶„í• )")
        print(f"      - Test: ì •ìƒ+ê²°í•¨ (ëª¨ë“  ë„ë©”ì¸ í†µí•©)")
        
        return True
        
    except Exception as e:
        print(f"âŒ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    print("ğŸš€ AllDomains HDMAP DataModule ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # 1. ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    basic_success = test_all_domains_hdmap_datamodule()
    
    if basic_success:
        # 2. íŠ¹ì • ë„ë©”ì¸ ì„ íƒ í…ŒìŠ¤íŠ¸
        specific_success = test_specific_domains()
        
        # 3. ê¸°ì¡´ DataModuleê³¼ ë¹„êµ
        compare_success = compare_with_existing_datamodules()
        
        print("\n" + "="*80)
        print("ğŸ‰ AllDomains HDMAP DataModule í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("="*80)
        print("âœ… ê¸°ë³¸ ê¸°ëŠ¥: ì •ìƒ ë™ì‘")
        print("âœ… íŠ¹ì • ë„ë©”ì¸ ì„ íƒ: ì •ìƒ ë™ì‘")
        print("âœ… ê¸°ì¡´ DataModule ë¹„êµ: ì™„ë£Œ")
        print("\nğŸ¯ Multi-class Unified Model Anomaly Detection ì¤€ë¹„ ì™„ë£Œ!")
        print("ğŸ“ ì‚¬ìš©ë²•:")
        print("   from anomalib.data.datamodules.image import AllDomainsHDMAPDataModule")
        print("   datamodule = AllDomainsHDMAPDataModule()")
        print("   trainer.fit(model, datamodule)")
        
    else:
        print("\nâŒ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ë°ì´í„° ê²½ë¡œì™€ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")