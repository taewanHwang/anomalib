# FE-CLIP êµ¬í˜„ ê²°ê³¼

## êµ¬í˜„ ì™„ë£Œ (2025-12-31) â†’ ì¬í˜„ ì„±ê³µ (2026-01-01)

FE-CLIP (Frequency Enhanced CLIP Model for Zero-Shot Anomaly Detection) ëª¨ë¸ì´ anomalibì— ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.

**13ê°œ ì‹¤í—˜ì„ í†µí•´ ë…¼ë¬¸ ì¬í˜„ì— ì„±ê³µí–ˆìŠµë‹ˆë‹¤.**

---

## ìµœì¢… ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ (Macro-average, ë…¼ë¬¸ ë°©ì‹)

### Image-level Detection (ZSAD)

| Dataset | Paper AUROC | Ours AUROC | Gap | Paper AP | Ours AP | Gap |
|---------|-------------|------------|-----|----------|---------|-----|
| **MVTec AD** | 91.9% | **90.8% Â± 0.3%** | **-1.1%** | 96.5% | 95.9% Â± 0.1% | -0.6% |
| **VisA** | 84.6% | **87.6% Â± 0.1%** | **+3.0%** | 86.6% | 89.9% Â± 0.1% | +3.3% |

### Pixel-level Segmentation (ZSAS)

| Dataset | Paper pAUROC | Ours pAUROC | Gap |
|---------|--------------|-------------|-----|
| **MVTec AD** | 92.6% | **90.9% Â± 0.1%** | **-1.7%** |
| **VisA** | 95.9% | **92.7% Â± 0.2%** | **-3.2%** |

> âœ… ë…¼ë¬¸ ëŒ€ë¹„ Gapì´ ëª¨ë‘ **5% ì´ë‚´**ë¡œ ì¬í˜„ ì„±ê³µ!

---

## í•µì‹¬ ë°œê²¬: ì¬í˜„ ì„±ê³µì˜ ê²°ì •ì  ìš”ì¸

### 1. Macro-average (ë…¼ë¬¸ ë°©ì‹) vs Micro-average (ê¸°ì¡´ êµ¬í˜„)

| Dataset | Metric | Micro (ê¸°ì¡´) | Macro (ë…¼ë¬¸) | **ì°¨ì´** |
|---------|--------|-------------|--------------|---------|
| VisA | AUROC | 78.4% | 87.6% | **+9.2%** |
| VisA | pAUROC | 88.6% | 92.7% | **+4.1%** |
| MVTec | AUROC | 83.8% | 90.8% | **+6.9%** |
| MVTec | pAUROC | 88.8% | 90.9% | **+2.2%** |

> **ğŸ“– ë…¼ë¬¸ ì¸ìš© (Section 4.2)**: *"We report dataset-level results, which are averaged across their respective sub-datasets."*
>
> ë…¼ë¬¸ì€ ëª…ì‹œì ìœ¼ë¡œ "sub-datasetë³„ í‰ê· "ì„ ì‚¬ìš©í•œë‹¤ê³  ì–¸ê¸‰. ì´ëŠ” **macro-average** (categoryë³„ metric ê³„ì‚° â†’ í‰ê· )ë¥¼ ì˜ë¯¸í•¨.

**ê²°ë¡ : í‰ê·  ë°©ì‹ì´ ê°€ì¥ í° ì°¨ì´ë¥¼ ë§Œë“¦. ë…¼ë¬¸ì€ categoryë³„ metric â†’ í‰ê·  (macro).**

### 2. fc_patch í•™ìŠµ ì •ì±…

| Policy | Image AUROC | pAUROC | vs Baseline |
|--------|-------------|--------|-------------|
| baseline (lr=5e-4) | 78.0% | 88.0% | - |
| **low_lr_100x (lr=5e-6)** | **78.6%** | **89.3%** | **+1.3%** |
| freeze | 77.9% | 89.4% | +1.4% |

> **ğŸ“– ë…¼ë¬¸ ì¸ìš© (Section 3.5)**: *"During training, both the visual encoder and the text encoder of CLIP are Frozen. Only the FFE adapters and LFS adapters are optimized by the loss function."*
>
> ë…¼ë¬¸ì€ **"adapterë§Œ í•™ìŠµ"**ì´ë¼ê³  ëª…ì‹œ. ê·¸ëŸ¬ë‚˜ Section 3.2ì—ì„œ *"we use a single learnable fc to align the dimension"*ì´ë¼ê³  fcê°€ learnableí•˜ë‹¤ê³ ë„ ì–¸ê¸‰.
> ì´ ëª¨ìˆœì„ í•´ê²°í•˜ê¸° ìœ„í•´ **fc_patch lrì„ 1/100ë¡œ ë‚®ì¶”ëŠ” ê²ƒ**ì´ ìµœì  ê· í˜•ì .

**ê²°ë¡ : ë…¼ë¬¸ì˜ "adapterë§Œ í•™ìŠµ" ì„œìˆ ëŒ€ë¡œ fc_patch lrì„ 1/100ë¡œ ë‚®ì¶”ë©´ pAUROC ê°œì„ .**

### 3. Tap Block ë¹„ì—°ì† ì¡°í•© ì‹¤í—˜ (2026-01-02)

ë…¼ë¬¸ì€ "N=4 blocks"ë§Œ ëª…ì‹œí•˜ê³  ì—°ì†/ë¹„ì—°ì† ì—¬ë¶€ëŠ” ì–¸ê¸‰í•˜ì§€ ì•ŠìŒ.
14ê°œ tap ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•˜ì—¬ ë¹„ì—°ì† ë¸”ë¡ì˜ íš¨ê³¼ ë¶„ì„.

> **ğŸ“– ë…¼ë¬¸ ì¸ìš© (Section 3.2)**: *"assuming the visual encoder consists of N blocks (N = 4)"*
>
> 4ê°œ ë¸”ë¡ì„ ì‚¬ìš©í•˜ë¼ê³ ë§Œ ëª…ì‹œ, **ì—°ì†ì ì´ì–´ì•¼ í•˜ëŠ”ì§€ëŠ” ì–¸ê¸‰ ì—†ìŒ**.

#### ì‹¤í—˜ ê²°ê³¼ (VisA í‰ê°€, AUROC ìˆœ)

| Config | Tap Indices | AUROC | pAUROC | vs Baseline |
|--------|-------------|-------|--------|-------------|
| **last5** | [19,20,21,22,23] | **88.1%** | 92.7% | **+0.5%** / Â±0% |
| last3_skip | [19,21,23] | 87.9% | 93.2% | +0.3% / +0.5% |
| **mix_late** | [16,19,21,23] | **87.8%** | **93.4%** | **+0.2% / +0.7%** |
| **spread_3** | [15,18,21,23] | 87.7% | **93.9%** | +0.1% / **+1.2%** |
| mix_mid_late | [14,18,21,23] | 87.6% | 93.7% | Â±0% / +1.0% |
| **last4 (baseline)** | [20,21,22,23] | 87.6% | 92.7% | - |
| late_skip1 | [19,21,22,23] | 87.4% | 92.8% | -0.2% / +0.1% |
| late_even | [16,18,20,22] | 87.4% | 93.1% | -0.2% / +0.4% |
| late_skip2 | [18,20,22,23] | 86.8% | 93.2% | -0.8% / +0.5% |
| late_skip3 | [17,19,21,23] | 86.7% | 93.1% | -0.9% / +0.4% |
| last5_skip | [17,19,21,22,23] | 86.6% | 93.3% | -1.0% / +0.6% |
| last3 | [21,22,23] | 86.3% | 92.4% | -1.3% / -0.3% |
| spread_5 | [8,13,18,23] | 84.4% | **94.1%** | -3.2% / **+1.4%** |
| spread_4 | [12,16,20,23] | 81.6% | 94.0% | -6.0% / +1.3% |

#### í•µì‹¬ ë°œê²¬

| ëª©ì  | ì¶”ì²œ Config | Tap Indices | íš¨ê³¼ |
|------|-------------|-------------|------|
| **Image-level ìµœì ** | last5 | [19,20,21,22,23] | AUROC **+0.5%** |
| **Pixel-level ìµœì ** | spread_5 | [8,13,18,23] | pAUROC **+1.4%** (AUROC -3.2%) |
| **ê· í˜• (ì¶”ì²œ)** | spread_3 | [15,18,21,23] | AUROC +0.1%, pAUROC **+1.2%** |

**ê²°ë¡ :**
- **ë¹„ì—°ì† ë¸”ë¡ì´ pAUROCì— ìœ ë¦¬** (ë‹¤ì–‘í•œ abstraction level í™œìš©)
- ë¸”ë¡ ìˆ˜ ì¦ê°€ (5ê°œ)ëŠ” AUROCì— ì†Œí­ ë„ì›€
- **spread_3 [15,18,21,23]ì´ AUROC/pAUROC ê· í˜• ìµœì **

### 4. Spread3 ì „ì²´ ë²¤ì¹˜ë§ˆí¬ (2026-01-02)

ìµœì  ê· í˜• tap ì¡°í•© `spread_3 [15,18,21,23]`ìœ¼ë¡œ ì „ì²´ ë°ì´í„°ì…‹ ë²¤ì¹˜ë§ˆí¬ ìˆ˜í–‰.
5 seeds Ã— 3 datasets = 15 experiments.

#### ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

| Dataset | Paper AUROC | Ours AUROC | Gap | Paper pAUROC | Ours pAUROC | Gap |
|---------|-------------|------------|-----|--------------|-------------|-----|
| **MVTec** | 91.9% | **90.7% Â± 0.3%** | **-1.2%** | 92.6% | **91.1% Â± 0.1%** | **-1.5%** |
| **VisA** | 84.6% | **88.2% Â± 0.4%** | **+3.6%** | 95.9% | **93.7% Â± 0.1%** | **-2.2%** |
| **BTAD** | 90.3% | **89.8% Â± 0.4%** | **-0.5%** | 95.6% | 87.5% Â± 1.4% | âš ï¸ **-8.1%** |

#### Seedë³„ ìƒì„¸ ê²°ê³¼

**MVTec AD (VisAë¡œ í•™ìŠµ):**
| Seed | AUROC | AP | pAUROC |
|------|-------|-----|--------|
| 42 | 90.7% | 95.6% | 91.1% |
| 123 | 90.7% | 95.6% | 91.1% |
| 456 | 91.0% | 95.5% | 91.0% |
| 789 | 91.0% | 95.8% | 90.9% |
| 1024 | 90.2% | 95.3% | 91.2% |

**VisA (MVTecìœ¼ë¡œ í•™ìŠµ):**
| Seed | AUROC | AP | pAUROC |
|------|-------|-----|--------|
| 42 | 87.5% | 89.6% | 93.8% |
| 123 | 88.6% | 90.6% | 93.7% |
| 456 | 88.3% | 90.5% | 93.9% |
| 789 | 88.2% | 90.4% | 93.5% |
| 1024 | 88.3% | 90.2% | 93.6% |

**BTAD (MVTecìœ¼ë¡œ í•™ìŠµ):**
| Seed | AUROC | AP | pAUROC |
|------|-------|-----|--------|
| 42 | 89.3% | 93.1% | 87.7% |
| 123 | 89.7% | 93.5% | 89.4% |
| 456 | 90.4% | 93.4% | 85.5% |
| 789 | 89.3% | 92.6% | 86.4% |
| 1024 | 90.1% | 93.4% | 88.3% |

### 5. Last4 ì „ì²´ ë²¤ì¹˜ë§ˆí¬ (2026-01-02)

ìµœì  ì„¸íŒ… `last4 [20,21,22,23]`ìœ¼ë¡œ ì „ì²´ ë°ì´í„°ì…‹ ë²¤ì¹˜ë§ˆí¬ ìˆ˜í–‰.
5 seeds Ã— 3 datasets = 15 experiments.

#### ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

| Dataset | Paper AUROC | Ours AUROC | Gap | Paper pAUROC | Ours pAUROC | Gap |
|---------|-------------|------------|-----|--------------|-------------|-----|
| **MVTec** | 91.9% | **91.0% Â± 0.4%** | **-0.9%** | 92.6% | **90.9% Â± 0.1%** | **-1.7%** |
| **VisA** | 84.6% | **87.8% Â± 0.3%** | **+3.2%** | 95.9% | **92.6% Â± 0.2%** | **-3.3%** |
| **BTAD** | 90.3% | **87.4% Â± 1.1%** | **-2.9%** | 95.6% | **85.9% Â± 0.4%** | **-9.7%** |

#### Seedë³„ ìƒì„¸ ê²°ê³¼

**MVTec AD (VisAë¡œ í•™ìŠµ):**
| Seed | AUROC | pAUROC |
|------|-------|--------|
| 42 | 90.6% | 90.9% |
| 123 | 90.7% | 90.6% |
| 456 | 90.8% | 91.0% |
| 789 | 91.2% | 90.9% |
| 1024 | 91.6% | 90.9% |

**VisA (MVTecìœ¼ë¡œ í•™ìŠµ):**
| Seed | AUROC | pAUROC |
|------|-------|--------|
| 42 | 87.5% | 92.7% |
| 123 | 87.6% | 92.8% |
| 456 | 87.6% | 92.4% |
| 789 | 88.1% | 92.3% |
| 1024 | 88.3% | 92.7% |

**BTAD (MVTecìœ¼ë¡œ í•™ìŠµ):**
| Seed | AUROC | pAUROC |
|------|-------|--------|
| 42 | 86.6% | 85.8% |
| 123 | 88.8% | 85.7% |
| 456 | 87.7% | 85.7% |
| 789 | 88.0% | 86.6% |
| 1024 | 86.0% | 85.5% |

### 6. Spread3 vs Last4 ìµœì¢… ë¹„êµ

| Dataset | Metric | Last4 | Spread3 | ì°¨ì´ | ìŠ¹ì |
|---------|--------|-------|---------|------|------|
| **MVTec** | AUROC | 91.0% | 90.7% | -0.3% | Last4 |
| **MVTec** | pAUROC | 90.9% | **91.1%** | +0.2% | Spread3 |
| **VisA** | AUROC | 87.8% | **88.2%** | +0.4% | **Spread3** |
| **VisA** | pAUROC | 92.6% | **93.7%** | +1.1% | **Spread3** |
| **BTAD** | AUROC | 87.4% | **89.8%** | +2.4% | **Spread3** |
| **BTAD** | pAUROC | 85.9% | **87.5%** | +1.6% | **Spread3** |

#### ìµœì¢… ê²°ë¡ 

- **MVTec**: ë‘ ì„¤ì • ë¹„ìŠ· (AUROCëŠ” last4, pAUROCëŠ” spread3 ìš°ìœ„)
- **VisA**: spread_3ê°€ **AUROC +0.4%, pAUROC +1.1% ê°œì„ **
- **BTAD**: spread_3ê°€ **AUROC +2.4%, pAUROC +1.6% ê°œì„ **

> âœ… **ìˆ˜ì •ëœ ê²°ë¡ **: spread_3 [15,18,21,23]ì´ **ëª¨ë“  ë°ì´í„°ì…‹ì—ì„œ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜**.
> ì´ì „ Exp15ì—ì„œ BTAD pAUROCê°€ ë‚®ê²Œ ë‚˜ì˜¨ ê²ƒì€ ì‹œë“œ ë³€ë™ì— ì˜í•œ ê²ƒìœ¼ë¡œ,
> ë™ì¼ ì‹œë“œë¡œ ë¹„êµ ì‹œ spread_3ê°€ last4ë³´ë‹¤ +1.6% ë” ë†’ìŒ.

**ìµœì¢… ì¶”ì²œ ì„¤ì •:**
| Dataset | ì¶”ì²œ Config | ì´ìœ  |
|---------|-------------|------|
| **ëª¨ë“  ë°ì´í„°ì…‹** | `spread_3 [15,18,21,23]` | ë‹¤ì–‘í•œ abstraction level í™œìš©ìœ¼ë¡œ ì „ë°˜ì  ì„±ëŠ¥ í–¥ìƒ |

---

## ìµœì  ì„¤ì • (ë…¼ë¬¸ ì¬í˜„ìš©)

```python
# ëª¨ë¸ ì„¤ì •
tap_indices = [15, 18, 21, 23]  # spread_3 (ì¶”ì²œ) - Exp14-16ì—ì„œ ê²€ì¦
# tap_indices = [20, 21, 22, 23]  # last4 (ë…¼ë¬¸ ê¸°ë³¸)
# ğŸ“– ë…¼ë¬¸ (Section 3.2): "assuming the visual encoder consists of N blocks (N = 4)"
#    â†’ 4ê°œ ë¸”ë¡ì„ ì‚¬ìš©í•˜ë¼ê³ ë§Œ ëª…ì‹œ, ì •í™•í•œ ìœ„ì¹˜ëŠ” ì–¸ê¸‰ ì—†ìŒ
#    â†’ spread_3ê°€ last4 ëŒ€ë¹„ ì „ ë°ì´í„°ì…‹ì—ì„œ ìš°ìˆ˜ (Exp16)

temperature = 0.07  # ê³ ì •
# ğŸ“– ë…¼ë¬¸ (Section 3.1): "where Ï„ denotes the temperature"
#    â†’ ì˜¨ë„ ë³€ìˆ˜ëŠ” ì •ì˜í•˜ì§€ë§Œ êµ¬ì²´ì ì¸ ê°’ì€ ëª…ì‹œí•˜ì§€ ì•ŠìŒ
#    â†’ CLIP ê¸°ë³¸ê°’ 0.07 ì‚¬ìš©

# í•™ìŠµ ì„¤ì •
epochs = 9
batch_size = 16
optimizer = Adam
adapter_lr = 5e-4
# ğŸ“– ë…¼ë¬¸ (Section 4.2): "The proposed FE-CLIP is trained by 9 epochs with Adam optimizer.
#    The learning rate is set to 5e-4 and the total batch size is 16."
#    â†’ ìœ„ ê°’ë“¤ì€ ë…¼ë¬¸ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì œê³µ

fc_patch_lr = 5e-6  # adapterì˜ 1/100
# ğŸ“– ë…¼ë¬¸ (Section 3.5): "Only the FFE adapters and LFS adapters are optimized"
#    â†’ fc_patch lrì€ ëª…ì‹œë˜ì§€ ì•ŠìŒ. ì‹¤í—˜ì„ í†µí•´ 1/100ì´ ìµœì ì„ì„ í™•ì¸ (Exp12)

# í‰ê°€ ì„¤ì •
averaging = "macro"  # categoryë³„ metric â†’ í‰ê· 
# ğŸ“– ë…¼ë¬¸ (Section 4.2): "We report dataset-level results, which are averaged across
#    their respective sub-datasets."
```

---

### PRO Gap ì‹¬ì¸µ ë¶„ì„ (2026-01-01)

3ê°€ì§€ ê°€ì„¤ì„ ê²€ì¦í•˜ì—¬ "í‰ê°€ íŒŒì´í”„ë¼ì¸ ì°¨ì´" ê°€ëŠ¥ì„±ì„ ë°°ì œí•¨:

#### ì‹¤í—˜ 1: ì›ë³¸ í•´ìƒë„ vs 336 Crop í‰ê°€

| Dataset | Method | pAUROC | PRO | Gap |
|---------|--------|--------|-----|-----|
| MVTec | 336 crop (í˜„ì¬) | 91.1% | 84.2% | baseline |
| MVTec | Original resolution | 91.2% | 83.6% | **-0.6%** |

**ê²°ë¡ : ì›ë³¸ í•´ìƒë„ í‰ê°€ëŠ” ì˜¤íˆë ¤ PROê°€ ë‚®ì•„ì§. ì›ì¸ ì•„ë‹˜.**

#### ì‹¤í—˜ 2: PRO ê³„ì‚° ì„¤ì • ë¹„êµ

| Dataset | fpr=0.3 | fpr=0.1 | fpr=0.05 | incl_normal | per_img_norm |
|---------|---------|---------|----------|-------------|--------------|
| MVTec | 84.2% | 69.0% (-15.2%) | 57.5% (-26.7%) | 84.2% | 83.7% |
| VisA | 77.8% | 54.8% (-22.9%) | 40.8% (-37.0%) | 77.8% | 77.8% |

**ê²°ë¡ : fpr_limit=0.3ì´ë©´ PRO ê³„ì‚° ì„¤ì •ì€ ë¬¸ì œ ì•„ë‹˜. ì •ìƒ í¬í•¨/ì •ê·œí™”ë„ ë¬´ê´€.**

#### ì‹¤í—˜ 3: Tap ì¡°í•© ìµœì í™”

**MVTec:**
| Method | PRO | pAUROC | Gap |
|--------|-----|--------|-----|
| avg_all (í˜„ì¬) | 84.2% | 91.1% | baseline |
| avg_first3 [20,21,22] | 84.3% | 91.2% | +0.1% |
| **tap1_only [21]** | **84.8%** | **91.9%** | **+0.6%** |
| avg_tap12 [21,22] | 84.4% | 91.8% | +0.2% |

**VisA:**
| Method | PRO | pAUROC | Gap |
|--------|-----|--------|-----|
| **avg_all (í˜„ì¬)** | **77.8%** | 93.5% | **ìµœì ** |
| tap1_only [21] | 76.5% | 93.2% | -1.3% |

**ê²°ë¡ : MVTecëŠ” tap1_onlyê°€ +0.6% ê°œì„  ê°€ëŠ¥. VisAëŠ” ì´ë¯¸ ìµœì .**

#### ì‹¤í—˜ 4: Map ì •ì˜ ë¹„êµ (prob_abnormal vs logit_margin)

í˜„ì¬ êµ¬í˜„: `amap = softmax(zÂ·t/Ï„)[..., 1]` (í™•ë¥  ê°’, 0~1 ë²”ìœ„)
ëŒ€ì•ˆ: `logit_margin = logit_abn - logit_nor` (ë²”ìœ„ ë„“ìŒ, -7~+7)

**MVTec:**
| Map ì •ì˜ | pAUROC | PRO | Gap |
|----------|--------|-----|-----|
| prob_abnormal (í˜„ì¬) | 91.5% | 81.5% | baseline |
| **logit_margin** | **91.7%** | **83.1%** | **+1.6%** |
| cos_gap | 91.7% | 83.1% | +1.6% |
| sigmoid_margin | 91.5% | 81.5% | Â±0% |

**VisA:**
| Map ì •ì˜ | pAUROC | PRO | Gap |
|----------|--------|-----|-----|
| prob_abnormal (í˜„ì¬) | 93.6% | 77.6% | baseline |
| **logit_margin** | **93.8%** | **78.7%** | **+1.1%** |
| cos_gap | 93.8% | 78.7% | +1.1% |
| sigmoid_margin | 93.6% | 77.6% | Â±0% |

**ê²°ë¡ : logit_marginì´ PRO +1.1~1.6% ê°œì„ . cos_gapì€ logit_marginì˜ ìŠ¤ì¼€ì¼ ë³€í™˜ì´ë¼ ë™ì¼ ê²°ê³¼.**

#### ì‹¤í—˜ 5: êµ¬ì¡°ì  í›„ì²˜ë¦¬ (Post-processing)

PROëŠ” ì‘ì€ FPì— ë¯¼ê°í•˜ë¯€ë¡œ êµ¬ì¡°ì  í›„ì²˜ë¦¬ íš¨ê³¼ í…ŒìŠ¤íŠ¸.

**MVTec:**
| í›„ì²˜ë¦¬ | pAUROC | PRO | Gap |
|--------|--------|-----|-----|
| none (í˜„ì¬) | 91.5% | 83.7% | baseline |
| pct95 (ìƒìœ„ 5%ë§Œ) | 68.7% | 67.1% | -16.6% |
| pct90 (ìƒìœ„ 10%ë§Œ) | 82.3% | 78.9% | -4.8% |
| morph_open | 82.2% | 78.8% | -4.9% |
| rm_small (50px ì´ìƒë§Œ) | 91.5% | 91.1% | +7.4% |
| **gaussian (Ïƒ=2)** | **91.6%** | **91.7%** | **+8.0%** |
| combined | 85.5% | 91.7% | +8.0% (pAUROC í•˜ë½) |

**VisA:**
| í›„ì²˜ë¦¬ | pAUROC | PRO | Gap |
|--------|--------|-----|-----|
| none (í˜„ì¬) | 93.5% | 77.8% | baseline |
| pct95 | 76.7% | 60.0% | -17.8% |
| rm_small | 93.5% | 77.4% | -0.4% |
| **gaussian (Ïƒ=2)** | **93.6%** | **78.0%** | **+0.2%** |
| combined | 85.6% | 73.6% | -4.2% |

**ê²°ë¡ :**
- MVTec: gaussian/combinedê°€ PRO +8.0% ê°œì„ , ê·¸ëŸ¬ë‚˜ pct/morphëŠ” pAUROC ëŒ€í­ í•˜ë½
- VisA: í›„ì²˜ë¦¬ íš¨ê³¼ ë¯¸ë¯¸ (+0.2%). ì´ë¯¸ mapì´ ìƒëŒ€ì ìœ¼ë¡œ ê¹”ë”í•¨
- **í›„ì²˜ë¦¬ëŠ” pAUROC-PRO trade-off ë°œìƒ** â†’ ì‹¤ìš©ì ì´ì§€ ì•ŠìŒ

---

### PRO Gap ì›ì¸ í™•ì • ê²°ë¡ 

| í…ŒìŠ¤íŠ¸í•œ ê°€ì„¤ | ê²°ê³¼ | PRO ì˜í–¥ |
|--------------|------|----------|
| ì›ë³¸ í•´ìƒë„ í‰ê°€ | âŒ ì›ì¸ ì•„ë‹˜ | ì˜¤íˆë ¤ -0.6% |
| fpr_limit ì°¨ì´ | âŒ ì›ì¸ ì•„ë‹˜ | 0.3 ì‚¬ìš© í™•ì¸ |
| ì •ìƒ ì´ë¯¸ì§€ í¬í•¨ | âŒ ì›ì¸ ì•„ë‹˜ | 0% ë³€í™” |
| per-image ì •ê·œí™” | âŒ ì›ì¸ ì•„ë‹˜ | 0% ë³€í™” |
| Tap ì¡°í•© ìµœì í™” | â–³ ë¶€ë¶„ íš¨ê³¼ | MVTec +0.6% |
| **Map ì •ì˜ (logit_margin)** | **âœ“ ìœ íš¨** | **+1.1~1.6%** |
| í›„ì²˜ë¦¬ (gaussian) | â–³ ì¡°ê±´ë¶€ ìœ íš¨ | MVTec +8%, VisA +0.2% |

**í˜„ì¬ PRO gap ìƒíƒœ:**
- logit_margin ì ìš© ì‹œ: MVTec 83.1% (ë…¼ë¬¸ 88.3%, gap -5.2%), VisA 78.7% (ë…¼ë¬¸ 92.8%, gap -14.1%)
- í›„ì²˜ë¦¬(gaussian) ì¶”ê°€ ì ìš© ì‹œ: MVTec ~91% (ë…¼ë¬¸ ê·¼ì ‘), VisA 79% (ì—¬ì „íˆ gap)

**ë‚¨ì€ PRO gap (VisA -14%, BTAD ~-20%)ì˜ ìœ ë ¥ ì›ì¸:**

1. ~~Map ì •ì˜ ì°¨ì´~~: logit_marginì´ +1~2% ê°œì„ í•˜ë‚˜ ì¶©ë¶„ì¹˜ ì•ŠìŒ
2. ~~êµ¬ì¡°ì  í›„ì²˜ë¦¬~~: MVTecì—ëŠ” íš¨ê³¼ì ì´ë‚˜ VisAì—ëŠ” ë¯¸ë¯¸
3. ~~Mask loss ì •ì±…~~: abnormal-only ì ìš© í…ŒìŠ¤íŠ¸ â†’ íš¨ê³¼ ì—†ìŒ (Exp7)
4. **Adapter fusion ë°©ì‹**: ë…¼ë¬¸ì˜ fusion ë°©ì‹ê³¼ ë¯¸ì„¸í•œ ì°¨ì´ ê°€ëŠ¥ì„±
5. **Training data êµ¬ì„±**: batch ë‚´ abnormal ë¹„ìœ¨, augmentation ë“±

---

### ì¶”ê°€ ì‹¤í—˜ (2026-01-01)

#### ì‹¤í—˜ 6: VisA Sanity Check (GT Mask / Pipeline ê²€ì¦)

PRO gap ì›ì¸ ì¤‘ "ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜" ê°€ëŠ¥ì„± ê²€ì¦.

| ê²€ì‚¬ í•­ëª© | ê²°ê³¼ | ë¹„ê³  |
|----------|------|------|
| GT mask ê°’ ë²”ìœ„ | âœ… ì •ìƒ (0-1) | ëª¨ë“  ì¹´í…Œê³ ë¦¬ |
| Object mask vs Defect mask í˜¼ë™ | âœ… ì—†ìŒ | íŒŒì´í”„ë¼ì¸ ì •ìƒ |
| Bbox IoU (pred vs GT) | âš ï¸ 10/12 ì¹´í…Œê³ ë¦¬ ë‚®ìŒ | ëª¨ë¸ localization ë¬¸ì œ |
| GT fragmentation | âš ï¸ 4ê°œ ì¹´í…Œê³ ë¦¬ | candle, cashew, macaroni1, pipe_fryum |

**ê²°ë¡ : íŒŒì´í”„ë¼ì¸ì€ ì •ìƒ. PRO gapì€ ëª¨ë¸ localization ì„±ëŠ¥ ë¬¸ì œ.**

---

#### ì‹¤í—˜ 7: Abnormal-only Mask Loss

ê°€ì„¤: Normal ì´ë¯¸ì§€ì— mask loss ì ìš©ì´ ë¶ˆí•„ìš”í•œ gradient noise ë°œìƒ?

| ì„¤ì • | pAUROC | Gap |
|------|--------|-----|
| Baseline (all images) | 88.2% | - |
| Abnormal-only mask loss | 87.7% | **-0.5%** |

**ê²°ë¡ : âŒ íš¨ê³¼ ì—†ìŒ. ì˜¤íˆë ¤ ë¯¸ì„¸ í•˜ë½.**

---

#### ì‹¤í—˜ 8: Tap Aggregation Methods

ê°€ì„¤: Tapë³„ íŠ¹ì„±ì´ ë‹¤ë¥´ë¯€ë¡œ aggregation ë°©ì‹ ìµœì í™”.

**MVTec:**
| Method | AUROC | pAUROC | Gap |
|--------|-------|--------|-----|
| avg (baseline) | 90.9% | 91.3% | - |
| max | 91.0% | 91.4% | +0.1% |
| weighted | 90.8% | 91.1% | -0.2% |
| **tap1 [21]** | **91.2%** | **91.6%** | **+0.3%** |

**VisA:**
| Method | AUROC | pAUROC | Gap |
|--------|-------|--------|-----|
| avg (baseline) | 78.1% | 88.2% | - |
| weighted | 77.6% | 88.4% | +0.2% |
| **tap0 [20]** | 53.4% | **89.4%** | **+1.1%** |
| tap1 [21] | 79.6% | 87.0% | -1.2% |

**ê²°ë¡ : â–³ ë¯¸ë¯¸í•œ ê°œì„ . MVTec tap1 +0.3%, VisA tap0 +1.1% (AUROC í•˜ë½).**

---

#### ì‹¤í—˜ 9: PRO Metric Implementation Comparison

ê°€ì„¤: PRO êµ¬í˜„ ë°©ì‹ì— ë”°ë¼ ê²°ê³¼ê°€ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ.

**MVTec:**
| Method | PRO |
|--------|-----|
| original_linspace_200 | 13.2% |
| original_linspace_500 | 15.6% |
| **quantile_200** | **82.7%** |
| roc_based | 79.5% |
| per_image | 14.7% |
| simplified_p50 | 99.3% |

**VisA:**
| Method | PRO |
|--------|-----|
| original_linspace_200 | 41.2% |
| original_linspace_500 | 47.6% |
| **quantile_200** | **73.6%** |
| roc_based | 73.5% |
| per_image | 42.6% |
| simplified_p50 | 99.6% |

**í•µì‹¬ ë°œê²¬:**
- PRO ê°’ì´ êµ¬í˜„ì— ë”°ë¼ **13% ~ 99%** ê¹Œì§€ ë³€ë™
- Linspace threshold vs Quantile thresholdê°€ ê°€ì¥ í° ì°¨ì´
- ê·¸ëŸ¬ë‚˜ quantile ë°©ì‹(73.6%)ìœ¼ë¡œë„ ë…¼ë¬¸(92.8%)ê³¼ gap ì¡´ì¬

**ê²°ë¡ : PRO metric êµ¬í˜„ ì°¨ì´ë§Œìœ¼ë¡œëŠ” gap ì„¤ëª… ë¶ˆê°€. ëª¨ë¸ í’ˆì§ˆ ì°¨ì´ê°€ ì£¼ì›ì¸.**

---

#### ì‹¤í—˜ 10: GT Downsample Training (Up() ì¬ì •ì˜)

ê°€ì„¤: Mapì„ 336ìœ¼ë¡œ upsampleí•˜ëŠ” ëŒ€ì‹ , GTë¥¼ 24x24ë¡œ downsampleí•˜ë©´
token-grid resolutionì—ì„œ ë” íš¨ê³¼ì ì¸ í•™ìŠµ ê°€ëŠ¥?

| Method | Image AUROC | pAUROC | vs Baseline |
|--------|-------------|--------|-------------|
| Baseline (upsample map) | 78.1% | 88.2% | - |
| **GT nearest downsample** | 77.7% | 86.0% | **-2.2%** |
| **GT maxpool downsample** | 78.0% | 87.2% | **-1.0%** |

**ë¶„ì„:**
- GTë¥¼ 24x24ë¡œ ë‹¤ìš´ìƒ˜í”Œí•˜ë©´ positive pixelì´ 99%+ ì†ì‹¤
- Nearest: GT ratio 0.51%, Maxpool: GT ratio 0.79%
- Mask supervisionì´ ë„ˆë¬´ sparseí•´ì ¸ì„œ í•™ìŠµ ì‹¤íŒ¨

**ê²°ë¡ : âŒ ê°€ì„¤ ê¸°ê°. GT downsampleì€ pAUROC í•˜ë½ ìœ ë°œ.**

---

#### ì‹¤í—˜ 11: Margin-Logit Based Loss Training

ê°€ì„¤: Softmax probability ëŒ€ì‹  margin-logitìœ¼ë¡œ mask loss ê³„ì‚° ì‹œ
ë” ê°•í•œ gradientì™€ region discrimination ê°€ëŠ¥?

| Method | Image AUROC | pAUROC | vs Baseline |
|--------|-------------|--------|-------------|
| Baseline (focal+dice) | 78.1% | 88.2% | - |
| **Margin-logit loss** | 78.7% | **88.9%** | **+0.7%** |

**ë¶„ì„:**
- Mask lossê°€ ë§¤ìš° ë‚®ì•˜ìŒ (0.005) - ì‚¬ì‹¤ìƒ cls lossë§Œ í•™ìŠµ
- ê·¸ëŸ¼ì—ë„ pAUROCê°€ +0.7% ê°œì„ 
- Classificationë§Œìœ¼ë¡œë„ ì¢‹ì€ representation í•™ìŠµ ê°€ëŠ¥ì„±

**ê²°ë¡ : â–³ ë¯¸ë¯¸í•œ ê°œì„  (+0.7%). ì¶”ê°€ íŠœë‹ í•„ìš”.**

---

#### ì‹¤í—˜ 12: fc_patch í•™ìŠµ ì •ì±… (í•µì‹¬ ë°œê²¬!)

ë…¼ë¬¸ì€ "FFE/LFS adapterë§Œ í•™ìŠµ"ì´ë¼ê³  ëª…ì‹œí•˜ì§€ë§Œ, ìš°ë¦¬ êµ¬í˜„ì€ fc_patchë„ í•™ìŠµ.
ê°€ì„¤: fc_patch í•™ìŠµì´ ë¶„ë¥˜ì—ëŠ” ë„ì›€ì´ì§€ë§Œ, map calibrationì„ ë°©í•´í•  ìˆ˜ ìˆìŒ.

**í…ŒìŠ¤íŠ¸í•œ ì •ì±…:**
| Policy | fc_patch lr | ì„¤ëª… |
|--------|-------------|------|
| baseline | 5e-4 | ëª¨ë“  íŒŒë¼ë¯¸í„° ë™ì¼ lr |
| warmup_freeze | 5e-4â†’frozen | 50 batch í›„ freeze |
| low_lr_10x | 5e-5 | adapterì˜ 1/10 |
| low_lr_100x | 5e-6 | adapterì˜ 1/100 |
| freeze | frozen | ì™„ì „ freeze |

**ê²°ê³¼ (VisA í‰ê°€):**
| Policy | Image AUROC | pAUROC | vs Baseline |
|--------|-------------|--------|-------------|
| baseline | 78.0% | 88.0% | - |
| warmup_freeze | 78.2% | 89.2% | **+1.2%** |
| low_lr_10x | 78.1% | 88.0% | Â±0% |
| **low_lr_100x** | **78.6%** | **89.3%** | **+1.3%** |
| freeze | 77.9% | **89.4%** | **+1.4%** |

**í•µì‹¬ ë°œê²¬:**
- âœ… **ê°€ì„¤ í™•ì¸**: fc_patch í•™ìŠµì´ classificationì—ëŠ” ë„ì›€ì´ì§€ë§Œ, **map calibrationì„ ë°©í•´**
- freezeê°€ pAUROC ìµœê³  (89.4%) but AUROC ìµœì € (77.9%)
- **low_lr_100xê°€ ìµœì  ê· í˜•**: AUROC +0.6%, pAUROC +1.3%

**ê¶Œì¥ ì„¤ì •:**
```
fc_patch lr = adapter lr / 100
- adapter lr: 5e-4
- fc_patch lr: 5e-6
```

**ê²°ë¡ : âœ“ ìœ íš¨. pAUROC +1.3% ê°œì„ . ë…¼ë¬¸ì˜ "adapterë§Œ í•™ìŠµ" ì„œìˆ ê³¼ ì¼ì¹˜.**

---

#### ì‹¤í—˜ 13: Macro-average vs Micro-average (ê²°ì •ì  ë°œê²¬!)

ë…¼ë¬¸ì€ "dataset-level results = sub-datasets average"ë¡œ ëª…ì‹œ.
í˜„ì¬ êµ¬í˜„ì€ micro-average (ì „ì²´ ìƒ˜í”Œ í•©ì‚°), ë…¼ë¬¸ì€ macro-average (categoryë³„ â†’ í‰ê· ).

**ê²°ê³¼:**
| Dataset | Metric | Micro (ê¸°ì¡´) | Macro (ë…¼ë¬¸) | **ì°¨ì´** |
|---------|--------|-------------|--------------|---------|
| VisA | AUROC | 78.4% | **87.6%** | **+9.2%** |
| VisA | pAUROC | 88.6% | **92.7%** | **+4.1%** |
| MVTec | AUROC | 83.8% | **90.8%** | **+6.9%** |
| MVTec | pAUROC | 88.8% | **90.9%** | **+2.2%** |

**ê²°ë¡ : âœ… í•µì‹¬ ì›ì¸ ë°œê²¬! Macro-average ì ìš©ìœ¼ë¡œ ë…¼ë¬¸ ì¬í˜„ ì„±ê³µ.**

---

### ì „ì²´ ì‹¤í—˜ ìš”ì•½ (Exp1-15)

| ì‹¤í—˜ | ê°€ì„¤ | ê²°ê³¼ | PRO/pAUROC ì˜í–¥ |
|------|------|------|-----------------|
| Exp1 | ì›ë³¸ í•´ìƒë„ í‰ê°€ | âŒ ê¸°ê° | -0.6% |
| Exp2 | PRO ê³„ì‚° ì„¤ì • | âŒ ì›ì¸ ì•„ë‹˜ | 0% |
| Exp3 | Tap ì¡°í•© ìµœì í™” | â–³ ë¶€ë¶„ íš¨ê³¼ | +0.6% (MVTec) |
| Exp4 | Map ì •ì˜ (logit_margin) | âœ“ ìœ íš¨ | +1.1~1.6% |
| Exp5 | êµ¬ì¡°ì  í›„ì²˜ë¦¬ | â–³ ì¡°ê±´ë¶€ | +8% (MVTec) / +0.2% (VisA) |
| Exp6 | GT/Pipeline ê²€ì¦ | âœ… ì •ìƒ | íŒŒì´í”„ë¼ì¸ ë¬¸ì œ ì—†ìŒ |
| Exp7 | Abnormal-only mask loss | âŒ íš¨ê³¼ ì—†ìŒ | -0.5% |
| Exp8 | Tap aggregation | â–³ ë¯¸ë¯¸ | +0.3% / +1.1% |
| Exp9 | PRO metric êµ¬í˜„ | âš ï¸ í° ì°¨ì´ | 13%~83% (êµ¬í˜„ ë”°ë¼) |
| Exp10 | GT downsample | âŒ ê¸°ê° | -1.0% ~ -2.2% |
| Exp11 | Margin-logit loss | â–³ ë¯¸ë¯¸ | +0.7% |
| **Exp12** | **fc_patch lr ì •ì±…** | **âœ“ ìœ íš¨** | **+1.3% (low_lr_100x)** |
| **Exp13** | **Macro-average í‰ê°€** | **âœ… í•µì‹¬** | **+4~9% (ê²°ì •ì !)** |
| **Exp14** | **ë¹„ì—°ì† Tap ì¡°í•©** | **âœ“ ìœ íš¨** | **pAUROC +1.2% (spread_3)** |
| **Exp15** | **Spread3 ì „ì²´ ë²¤ì¹˜ë§ˆí¬** | **âœ“ ê²€ì¦** | **VisA +1.0%, BTAD +1.6%** |
| **Exp16** | **Last4 ì „ì²´ ë²¤ì¹˜ë§ˆí¬** | **âœ“ ë¹„êµ** | **Spread3ê°€ ì „ë°˜ì  ìš°ìˆ˜** |

**ì¬í˜„ ì„±ê³µ í•µì‹¬ ìš”ì¸:**
| ê°œì„  í•­ëª© | ì˜í–¥ | ë¹„ê³  |
|----------|------|------|
| **Macro-average í‰ê°€** | **+4~9%** | **ê°€ì¥ í° ì˜í–¥** |
| fc_patch low_lr_100x | +1.3% | í•™ìŠµ ì‹œ ì ìš© |
| Tap ìœ„ì¹˜ [20,21,22,23] | +2.4% | ì´ˆê¸° ì„¤ì • |
| ë¹„ì—°ì† Tap [15,18,21,23] | pAUROC +1.2% | Exp14ì—ì„œ ë°œê²¬ |

**ê²°ë¡ : ë…¼ë¬¸ ì¬í˜„ ì„±ê³µ! Gap < 5% ë‹¬ì„±.**

**ì¶”ê°€ ë°œê²¬ (Exp14-16):**
- ë¹„ì—°ì† tap ì¡°í•©ì´ pAUROC ê°œì„ ì— ìœ íš¨
- spread_3 [15,18,21,23]ì´ last4 [20,21,22,23] ëŒ€ë¹„ **ì „ ë°ì´í„°ì…‹ì—ì„œ ìš°ìˆ˜**
- VisA: AUROC +0.4%, pAUROC +1.1%
- BTAD: AUROC +2.4%, pAUROC +1.6%
- **ìµœì¢… ì¶”ì²œ: spread_3 [15,18,21,23]**

### Seedë³„ ìƒì„¸ ê²°ê³¼

#### MVTec AD (VisAë¡œ í•™ìŠµ)
| Seed | AUROC | AP |
|------|-------|-----|
| 42 | 90.9% | 95.8% |
| 123 | 91.0% | 95.9% |
| 456 | 91.1% | 96.0% |
| 789 | 91.4% | 96.0% |
| 1024 | 91.3% | 96.1% |

#### VisA (MVTecë¡œ í•™ìŠµ)
| Seed | AUROC | AP |
|------|-------|-----|
| 42 | 87.8% | 90.0% |
| 123 | 87.7% | 89.9% |
| 456 | 87.8% | 90.0% |
| 789 | 87.8% | 90.1% |
| 1024 | 87.9% | 90.1% |

#### BTAD (MVTecë¡œ í•™ìŠµ)
| Seed | AUROC | AP |
|------|-------|-----|
| 42 | 88.3% | 94.5% |
| 123 | 87.8% | 94.5% |
| 456 | 88.3% | 93.7% |
| 789 | 88.1% | 94.2% |
| 1024 | 88.3% | 94.2% |

---

## ì•„í‚¤í…ì²˜ ê°œìš”

![FE-CLIP Architecture](./FECLIP_architecure.png)

### í•µì‹¬ êµ¬ì¡°

| ì»´í¬ë„ŒíŠ¸ | ìƒíƒœ | ì„¤ëª… |
|---------|------|------|
| Text Encoder T(Â·) | â„ï¸ Frozen | CLIP text encoder |
| Visual Encoder F(Â·) | â„ï¸ Frozen | CLIP visual encoder (ViT-L-14, 24 blocks) |
| FFE Adapter | ğŸ”¥ Learnable | DCT ê¸°ë°˜ frequency feature extraction |
| LFS Adapter | ğŸ”¥ Learnable | Local frequency statistics (signed mean) |
| fc_patch | ğŸ”¥ Learnable | Patch token â†’ text space projection |
| fc_clip | â„ï¸ Frozen | Class token projection (visual.proj) |

### ìµœì  ì„¤ì • (Ablationìœ¼ë¡œ ë„ì¶œ)

| íŒŒë¼ë¯¸í„° | ê°’ | ê·¼ê±° | ë…¼ë¬¸ ì¸ìš© |
|---------|-----|------|----------|
| backbone | ViT-L-14-336 | ë…¼ë¬¸ ëª…ì‹œ | *"We use the publicly available CLIP model (VIT-L/14@336px)"* (Sec 4.2) |
| **tap_indices** | **[20,21,22,23]** | Ablation: last4ê°€ ìµœì  | *"N blocks (N = 4)"* (Sec 3.2) - ìœ„ì¹˜ ë¯¸ëª…ì‹œ, ì‹¤í—˜ìœ¼ë¡œ ê²°ì • |
| lambda_fuse | 0.1 | ë…¼ë¬¸ ëª…ì‹œ | *"We set Î» = 0.1 to preserve the original knowledge"* (Sec 3.2) |
| P, Q | 3, 3 | ë…¼ë¬¸ ëª…ì‹œ | *"P is set to 3 by default"*, *"Q is set to 3 by default"* (Sec 3.3, 3.4) |
| temperature | 0.07 | Ablation: ê³ ì •ê°’ ìµœì  | *"Ï„ denotes the temperature"* (Sec 3.1) - ê°’ ë¯¸ëª…ì‹œ |
| lr | 5e-4 | ë…¼ë¬¸ ëª…ì‹œ | *"The learning rate is set to 5e-4"* (Sec 4.2) |
| optimizer | Adam | ë…¼ë¬¸ ëª…ì‹œ | *"trained by 9 epochs with Adam optimizer"* (Sec 4.2) |
| epochs | 9 | ë…¼ë¬¸ ëª…ì‹œ | *"trained by 9 epochs"* (Sec 4.2) |
| w_cls, w_mask | 1.0, 1.0 | ë…¼ë¬¸ ì•”ì‹œ | *"Ltotal = Lcls + Lmask"* (Sec 3.5) - ê°€ì¤‘ì¹˜ ë¯¸ëª…ì‹œ, 1:1 ì•”ì‹œ |
| train data | test data ì‚¬ìš© | ë…¼ë¬¸ ëª…ì‹œ | *"we fine-tune FE-CLIP using the test data of MVTec AD"* (Sec 4.2) |

---

## Ablation Study: ë…¼ë¬¸ ì¬í˜„ì„ ìœ„í•œ ì‹¤í—˜

### ë¬¸ì œ ìƒí™©

ì´ˆê¸° êµ¬í˜„ (linspace tap)ì—ì„œ ë…¼ë¬¸ ëŒ€ë¹„ ì„±ëŠ¥ ì°¨ì´ ë°œìƒ:

| Dataset | Paper | ì´ˆê¸° êµ¬í˜„ (linspace) | Gap |
|---------|-------|---------------------|-----|
| MVTec AD | 91.9% | 89.3% Â± 0.3% | -2.6% |
| VisA | 84.6% | 81.2% Â± 0.5% | -3.4% |
| BTAD | 90.3% | 93.7% Â± 1.2% | +3.4% |

**ê´€ì°°**: MVTec/VisAëŠ” ë¯¸ë‹¬, BTADëŠ” ì´ˆê³¼ â†’ êµ¬í˜„ ì°¨ì´ì  ë¶„ì„ í•„ìš”

---

### 1. Tap Block ìœ„ì¹˜ ì‹¤í—˜ (ê°€ì¥ í° ì˜í–¥)

> **ğŸ“– ë…¼ë¬¸ ì¸ìš© (Section 3.2)**: *"assuming the visual encoder consists of N blocks (N = 4), the features (i.e. the patch tokens) after the n-th block are denoted as f^m_n"*
>
> ë…¼ë¬¸ì€ **4ê°œ ë¸”ë¡ì„ ì‚¬ìš©**í•œë‹¤ê³ ë§Œ ëª…ì‹œí•˜ê³ , **ì •í™•í•œ ìœ„ì¹˜ (ì¸ë±ìŠ¤)ëŠ” ì–¸ê¸‰í•˜ì§€ ì•ŠìŒ**.
> ViT-L-14ëŠ” 24ê°œ blockì„ ê°€ì§€ë¯€ë¡œ, ì–´ë–¤ 4ê°œë¥¼ ì„ íƒí• ì§€ ì‹¤í—˜ í•„ìš”.

**ë°°ê²½**: ë…¼ë¬¸ì€ "N=4 blocks"ë§Œ ëª…ì‹œ, ì •í™•í•œ ìœ„ì¹˜ ë¯¸ê¸°ì¬. ViT-L-14ëŠ” 24ê°œ block.

| Config | MVTec | Gap | VisA | Gap | BTAD | Gap |
|--------|-------|-----|------|-----|------|-----|
| linspace [0,8,15,23] | 88.5% | -3.4% | 81.2% | -3.4% | **91.1%** | **+0.8%** |
| **last4 [20,21,22,23]** | **90.9%** | **-1.0%** | **87.3%** | **+2.7%** | 88.6% | -1.7% |
| late [12,16,20,23] | 88.7% | -3.2% | - | - | 88.8% | -1.5% |

**ê²°ë¡ **:
- **last4 [20,21,22,23]ê°€ MVTec/VisAì—ì„œ ìµœì ** (+2.4% ê°œì„ )
- í›„ë°˜ë¶€ ë¸”ë¡ë§Œ ì‚¬ìš© ì‹œ ì €ìˆ˜ì¤€ í…ìŠ¤ì²˜ FP ê°ì†Œ
- BTADëŠ” ë‹¨ìˆœ íŒ¨í„´ì´ë¼ ì´ˆê¸° ë¸”ë¡ ì •ë³´ë„ ìœ ìš© (trade-off)

---

### 2. fc_patch Freeze ì‹¤í—˜

> **ğŸ“– ë…¼ë¬¸ì˜ ëª¨ìˆœëœ ì„œìˆ **:
> - Section 3.5: *"Only the FFE adapters and LFS adapters are optimized"* â†’ fcëŠ” í•™ìŠµ ì•ˆí•¨
> - Section 3.2: *"we use a single learnable fc to align the dimension"* â†’ fcëŠ” í•™ìŠµí•¨
>
> ì´ **ëª¨ìˆœìœ¼ë¡œ ì¸í•´** fc_patchë¥¼ í•™ìŠµí• ì§€ ì—¬ë¶€ê°€ ë¶ˆëª…í™•.

**ë°°ê²½**: ë…¼ë¬¸ ì„œìˆ  ëª¨ìˆœ - "only adapters learnable" vs "fc is learnable" (Eq.3)

| Config | AUROC | Gap | ë³€í™” |
|--------|-------|-----|------|
| **fc_patch í•™ìŠµ (ê¸°ë³¸)** | **90.9%** | **-1.0%** | ê¸°ì¤€ |
| fc_patch freeze | 89.3% | -2.6% | -1.6% â†“ |

**ê²°ë¡ **: fc_patchëŠ” í•™ìŠµí•´ì•¼ í•¨ (freeze ì‹œ ì„±ëŠ¥ í•˜ë½)

---

### 3. Temperature ì‹¤í—˜

> **ğŸ“– ë…¼ë¬¸ ì¸ìš© (Section 3.1)**: *"where Ï„ denotes the temperature and the operator <Â·,Â·> represents the computation of cosine similarity"*
>
> ë…¼ë¬¸ì€ Ï„ë¥¼ **ì •ì˜ë§Œ í•˜ê³  êµ¬ì²´ì ì¸ ê°’ì€ ëª…ì‹œí•˜ì§€ ì•ŠìŒ**. CLIP ê¸°ë³¸ê°’(0.07) ë˜ëŠ” í•™ìŠµëœ logit_scale ì¤‘ ì„ íƒ í•„ìš”.

**ë°°ê²½**: ë…¼ë¬¸ì€ Ï„ ì •ì˜ë§Œ í•˜ê³  ê°’ ë¯¸ëª…ì‹œ. CLIP logit_scale vs ê³ ì •ê°’ ë¹„êµ.

| Config | AUROC | Gap | ë³€í™” |
|--------|-------|-----|------|
| **ê³ ì • Ï„=0.07** | **90.9%** | **-1.0%** | ê¸°ì¤€ |
| CLIP logit_scale | 90.3% | -1.6% | -0.6% â†“ |

**ê²°ë¡ **: ê³ ì • Ï„=0.07ì´ CLIP logit_scaleë³´ë‹¤ ì¢‹ìŒ

---

### 4. LFS í†µê³„ ë°©ì‹ ì‹¤í—˜

> **ğŸ“– ë…¼ë¬¸ ì¸ìš© (Section 3.4)**: *"we count the mean of f^m_{n,lfs,1} across QÃ—Q groups to get the mean frequency responses f^m_{n,lfs,2}"*
>
> ë…¼ë¬¸ì€ **"mean frequency responses"**ë§Œ ì–¸ê¸‰í•˜ê³ , **signed meanì¸ì§€ absolute meanì¸ì§€ power meanì¸ì§€ ëª…ì‹œí•˜ì§€ ì•ŠìŒ**.

**ë°°ê²½**: ë…¼ë¬¸ì€ "mean frequency responses"ë§Œ ì–¸ê¸‰, signed/abs/power ë¯¸ëª…ì‹œ.

| Config | AUROC | Gap | ë³€í™” |
|--------|-------|-----|------|
| **signed mean** | **90.9%** | **-1.0%** | ê¸°ì¤€ |
| abs mean | 90.6% | -1.3% | -0.3% â†“ |
| power mean | 90.8% | -1.1% | -0.1% â†“ |

**ê²°ë¡ **: signed meanì´ ìµœì  (abs/power ëª¨ë‘ í•˜ë½)

---

### Ablation ìš”ì•½

| ì‹¤í—˜ í•­ëª© | í…ŒìŠ¤íŠ¸ ì˜µì…˜ | ìµœì  ì„¤ì • | íš¨ê³¼ |
|----------|------------|----------|------|
| **Tap ìœ„ì¹˜** | linspace, last4, late | **last4 [20,21,22,23]** | **+2.4% ê°œì„ ** |
| fc_patch | í•™ìŠµ vs freeze | í•™ìŠµ | ê¸°ë³¸ê°’ ìœ ì§€ |
| Temperature | 0.07 vs logit_scale | 0.07 ê³ ì • | ê¸°ë³¸ê°’ ìœ ì§€ |
| LFS í†µê³„ | mean, abs, power | signed mean | ê¸°ë³¸ê°’ ìœ ì§€ |

**í•µì‹¬ ë°œê²¬**: Tap block ìœ„ì¹˜ê°€ ì„±ëŠ¥ì— ê°€ì¥ í° ì˜í–¥ (linspace â†’ last4ë¡œ +2.4% ê°œì„ )

---

## Gap ë¶„ì„

### MVTec AD: -0.8% Gap

- ë…¼ë¬¸ì— ë§¤ìš° ê·¼ì ‘ (91.1% vs 91.9%)
- ë‚¨ì€ gapì€ ë…¼ë¬¸ ë¯¸ëª…ì‹œ ë””í…Œì¼ë¡œ ì¶”ì •:
  - Tap ì£¼ì… ìœ„ì¹˜ (block ì¶œë ¥ ì§í›„ vs ë‚´ë¶€)
  - í•™ìŠµ ë°ì´í„° ì„¸ë¶€ êµ¬ì„±
  - ëœë¤ ì‹œë“œ/ì´ˆê¸°í™”

### VisA: +3.2% Gap (ë…¼ë¬¸ ì´ˆê³¼)

- ë…¼ë¬¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ (87.8% vs 84.6%)
- last4 tapì´ ë³µì¡í•œ PCB/íšŒë¡œ íŒ¨í„´ì— íš¨ê³¼ì 

### BTAD: -2.1% Gap

- last4ê°€ ë‹¨ìˆœ íŒ¨í„´ì—ëŠ” ë¶ˆë¦¬í•¨
- BTADëŠ” linspaceê°€ ë” ì í•© (91.1%)
- **ë°ì´í„°ì…‹ íŠ¹ì„±ì— ë”°ë¥¸ tap ì„¤ì • í•„ìš”**

---

## ìƒì„±ëœ íŒŒì¼

```
src/anomalib/models/image/feclip/
â”œâ”€â”€ __init__.py           # ëª¨ë“ˆ export
â”œâ”€â”€ adapters.py           # FFE, LFS adapter (DCT ê¸°ë°˜)
â”œâ”€â”€ losses.py             # BCE, Focal, Dice loss
â”œâ”€â”€ prompting.py          # Text prompts
â”œâ”€â”€ torch_model.py        # FEClipModel (í•µì‹¬ ëª¨ë¸)
â””â”€â”€ lightning_model.py    # FEClip (Lightning ë˜í¼)

examples/notebooks/11_fe_clip_variant/
â”œâ”€â”€ 001_result.md         # ì‹¤í—˜ ê²°ê³¼ ë¬¸ì„œ (ì´ íŒŒì¼)
â”œâ”€â”€ 001_architecture.md   # FE-CLIP ì•„í‚¤í…ì²˜ ì„¤ëª… ë¬¸ì„œ
â”œâ”€â”€ run_feclip.py         # ìµœì  ì„¤ì • ê³ ì •ëœ í•™ìŠµ/í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ FECLIP_architecure.png
â”œâ”€â”€ FECLIP_benchmark.png
â”œâ”€â”€ results/              # ì‹¤í—˜ ê²°ê³¼ í´ë”
â”œâ”€â”€ results_tap_exp/      # Exp14 ê²°ê³¼ í´ë”
â”œâ”€â”€ results_spread3_benchmark/  # Exp15 ê²°ê³¼ í´ë”
â”œâ”€â”€ results_last4_benchmark/    # Exp16 ê²°ê³¼ í´ë”
â””â”€â”€ 001_feclip_original/  # ëª¨ë“  ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ (Exp1-16)
    â”œâ”€â”€ run_feclip_engine.py
    â”œâ”€â”€ benchmark_feclip_allcat.py
    â”œâ”€â”€ exp1_original_resolution.py ~ exp13_macro_average.py
    â”œâ”€â”€ exp_tap_combinations.py     # Exp14
    â”œâ”€â”€ exp_spread3_benchmark.py    # Exp15
    â”œâ”€â”€ exp_last4_benchmark.py      # Exp16
    â””â”€â”€ (ê¸°íƒ€ ë””ë²„ê¹…/ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸)
```

---

## ì‚¬ìš©ë²•

```bash
# VisA í‰ê°€ (MVTecìœ¼ë¡œ í•™ìŠµ)
python run_feclip.py --mode visa --seed 42

# MVTec í‰ê°€ (VisAë¡œ í•™ìŠµ)
python run_feclip.py --mode mvtec --seed 42

# TensorBoard
tensorboard --logdir results/ --bind_all --port 6010
```

---

## Python API ì‚¬ìš©ë²•

```python
import torch
from anomalib.models.image import FEClip

# ëª¨ë¸ ìƒì„± (ìµœì  ì„¤ì •)
model = FEClip(tap_indices=[20, 21, 22, 23])
model.cuda()
model.eval()
model.model.setup_text()

# ì¶”ë¡ 
image = torch.randn(1, 3, 336, 336).cuda()
with torch.no_grad():
    output = model.model(image)

print(f"Anomaly score: {output.pred_score.item():.4f}")
print(f"Anomaly map shape: {output.anomaly_map.shape}")
```

---

## ì°¸ê³  ìë£Œ

- **ë…¼ë¬¸**: FE-CLIP: Frequency Enhanced CLIP Model for Zero-Shot Anomaly Detection
- **ì•„í‚¤í…ì²˜**: `FECLIP_architecure.png`
- **ë²¤ì¹˜ë§ˆí¬**: `FECLIP_benchmark.png`
