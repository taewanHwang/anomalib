1. [레포] 해당 레포지토리는 github에 오픈된 anomalib이라는 cv AD 관련 라이브러리를 모아둔 라이브러리르 내가 가진 것에 맞게 수정한 레포야.
2. [데이터] 내가 가진 데이터셋은 health datamap이라고하며, 4개의 서로 다른 도메인 혹은 카테고리가 있어.  datasets/HDMAP/1000_tiff_minmax 하위 참고해. 개별 이미지는 tiff 포맷이며, 0~inf 를 가지며, 정규화를 진행했기때문에 대략 0~1 스케일을 가지지만 일부 샘플은 픽셀 값이 1을 넘는것도 있어. 대략 이 데이터의 의미는 기어박스의 진동 신호를 이미지화 한것으로 큰 값이 큰 진동을 가지는 것이며, 이미지의 가로축과 세로축은 gear meshing point를 의미해. 따라서 특정 기어치에 결함이 있으면 가로 혹은 세로 결함이 발생해. 다만, 데이터셋의 특징은 결함은 가로 패턴이 있다고 생각해줘. 데이터 특성을 봐서 알겠지만, train은 정상 데이터만 있고, test는 정상, 고장 데이터가 다 있어. 그리고 각 test (정상/고장) 데이터의 경우 1000개씩 있는데, 앞에 500개는 cold state에서 얻어진 데이터이고, 후반 500개는 warm state에서 얻어진 데이터야. 따라서 이로 인한 pixel amplitude scale의 차이도 있어. 자세한 내용은 examples/hdmap/EDA/HDMAP_vis/results 에 있는 시각화 결과를 참고해. 예를 들어, examples/hdmap/EDA/HDMAP_vis/results/hdmap_domainA_20251227_040432.png 이미지에서 row=1은 training normal, row=2는 test normal, row=3는 test fault야. 위에서 말한 cold, warm의 차이도 대략적으로 확인 가능해.
3. [배경 지식1] 기존에 나는 winclip 기반의 few shot learning을 내가 가진 health datamap에 적용하고, 개선 방안을 찾고 있었어. 여러가지 시도를 했는데, (1) prompt change - examples/notebooks/09_winclip_variant/winclip_hdmap.md 참고, (2) condition aware reference association - examples/notebooks/09_winclip_variant/CA_WinCLIP_README.md 파일 참고, (3) 전반적인 실험 결과 - examples/notebooks/09_winclip_variant/WINCLIP_HDMAP_FINAL_ANALYSIS.md,  아무튼 이런 시도들을 통해서 성능을 올리긴 했는데, 내가 원하는 만큼 성능을 얻지 못하였고, 특히 domain C라는 특성에서 cold fault의 결함이 눈으로는 보이는데, 결함 크기가 작고 패턴이 두드러지지 않아서 CLIP 계열에서 embedding 특성이 잘 추출되지 않더라는것을 확인했어. 다만 CA_WINCLIP에서 확인했듯이 cold reference와 warm reference가 다른데, test image의 state가 cold인지 warm인지 판단하는 gating 이후에 적절한 레퍼런스 기반으로 few shot test하는것의 가능성은 일부 보았어.
4. [배경 지식2] 위의 가능성을 다른 모델에 적용하는것을 고민하다가 patchcore에 memory bank가 있는데, 여기에 conditon aware를 접목해보고 싶다는 생각을 했어. 특히 기존에 실험했을떄 accuracy 기준으로 patchcore는 96.3%(domainA), 96.4%(domainB), 79.9% (domainC), 91.6% (domainD)의 성능을 보였어. 참고로 해당 시점에는 patchcore + dino backbone을 사용했고, 관련된 실험은 examples/hdmap/analyze_experiment_results_single.py 파일과 examples/hdmap/single_domain/exp_23_patchcore.json 을 사용했으니 참고해 (지금보니 backbone은 vit_small_patch14_dinov2을 사용했네.) 그리고 그때는 학습 이미지를 엄청 많이 넣어여해서 모델도 작게 쓰고 layer도 작은것 위주로 했음.
5. [가설1] 내가 배경지식2에서 말한것처럼 patch core + dino 조합이 기존에 성능이 좋았던 점은 dino feature extractor 자체의 성능이 좋은점이 한몫했어. clip이랑 비교하면 clip은 text와 align을 맞춰야했던 반면 dino는 이미지 자체를 엄청 많이 잘 학습했기 때문에 그 성능이 훌륭했던것 같아. 그래서 내 생각에 domain C 같은 미세한 결함도 잘 추출할 수 있을것 같아. (물론 좀 더 봐야겠지만, 특히 domain C가 기존에 79.9% 였기때문에)
6. [가설2] 기존 방식으로 cold normal image, hot normal image를 few shot으로 2k개 주고 patchcore를 수행했을때와, 동일하게 2k fewshot주고 gating 기반으로 적절한것을 사용했을때와 비교했을때 scale 상의 차이 때문에 후자가더 좋을것으로 생각해. 특히 domain C의 cold fault 같은 경우 결함 위치에서 hot normal과 유사한 패치가 나올수 있는데, 이걸 gating 통해서 차단하면 cold normal이랑만 비교하게 되니까 patch core 내부에서 kNN 수행할때 저 이상감지가 잘 될 것이라고 생각함.
7. 이러한 가설을 검증하기 위해 실험 계획을 수립해. 참고로 기존에 제공한 실험 시도들을 보면 어떻게 이미지 전처리 해야하는지 등의 유의사항 있으니까 잘 파악하고, 최종 실험은 examples/notebooks/10_patchcore_variant 하위에 스크립트를 생성하면서 갔으면 좋겠어. 기존과 마찬가지로 script 레벨에서 실험 가능한 항목은 examples/notebooks/10_patchcore_variant 에 구현하고, 모델을 수정해야하는 경우 src/anomalib/models/image/patchcore_variants  라는 폴더를 만들어서 사용하도록 해. bottom up으로 한개씩 차근차근 가설을 검증하면서 가는것과 top down으로 그냥 실험 돌리고 생각하는 것 중에는 bottom up으로 하나씩 가설을 짚어가면서 가는것을 선호해. 그리고 domain 중에는 domain C의 성능을 끌어올리는게 아주 중요한 포인트임. 그렇지 않으면 전반적 성능 향상이 어려움. (다른 모델 SOTA 기준 domain C의 accuracy= 98.2%)
8. 자 이제 차근차근 문서들 읽고 해야할 일을 계획 수립해보자. 계획이 수립되면 그 내용을 examples/notebooks/10_patchcore_variant/plan.md로 만들어서 내가 볼 수 있도록 해.