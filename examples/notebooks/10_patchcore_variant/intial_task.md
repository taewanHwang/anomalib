1. [레포] 해당 레포지토리는 github에 오픈된 anomalib이라는 cv AD 관련 라이브러리를 모아둔 라이브러리르 내가 가진 것에 맞게 수정한 레포야.
2. [데이터] 내가 가진 데이터셋은 health datamap이라고하며, 4개의 서로 다른 도메인 혹은 카테고리가 있어.  datasets/HDMAP/1000_tiff_minmax 하위 참고해. 개별 이미지는 tiff 포맷이며, 0~inf 를 가지며, 정규화를 진행했기때문에 대략 0~1 스케일을 가지지만 일부 샘플은 픽셀 값이 1을 넘는것도 있어. 대략 이 데이터의 의미는 기어박스의 진동 신호를 이미지화 한것으로 큰 값이 큰 진동을 가지는 것이며, 이미지의 가로축과 세로축은 gear meshing point를 의미해. 따라서 특정 기어치에 결함이 있으면 가로 혹은 세로 결함이 발생해. 다만, 데이터셋의 특징은 결함은 가로 패턴이 있다고 생각해줘. 데이터 특성을 봐서 알겠지만, train은 정상 데이터만 있고, test는 정상, 고장 데이터가 다 있어. 그리고 각 test (정상/고장) 데이터의 경우 1000개씩 있는데, 앞에 500개는 cold state에서 얻어진 데이터이고, 후반 500개는 warm state에서 얻어진 데이터야. 따라서 이로 인한 pixel amplitude scale의 차이도 있어. 자세한 내용은 examples/hdmap/EDA/HDMAP_vis/results 에 있는 시각화 결과를 참고해. 예를 들어, examples/hdmap/EDA/HDMAP_vis/results/hdmap_domainA_20251227_040432.png 이미지에서 row=1은 training normal, row=2는 test normal, row=3는 test fault야. 위에서 말한 cold, warm의 차이도 대략적으로 확인 가능해.
3. [배경 지식1] 기존에 나는 winclip 기반의 few shot learning을 내가 가진 health datamap에 적용하고, 개선 방안을 찾고 있었어. 여러가지 시도를 했는데, (1) prompt change - examples/notebooks/09_winclip_variant/winclip_hdmap.md 참고, (2) condition aware reference association - examples/notebooks/09_winclip_variant/CA_WinCLIP_README.md 파일 참고, (3) 전반적인 실험 결과 - examples/notebooks/09_winclip_variant/WINCLIP_HDMAP_FINAL_ANALYSIS.md,  아무튼 이런 시도들을 통해서 성능을 올리긴 했는데, 내가 원하는 만큼 성능을 얻지 못하였고, 특히 domain C라는 특성에서 cold fault의 결함이 눈으로는 보이는데, 결함 크기가 작고 패턴이 두드러지지 않아서 CLIP 계열에서 embedding 특성이 잘 추출되지 않더라는것을 확인했어. 다만 CA_WINCLIP에서 확인했듯이 cold reference와 warm reference가 다른데, test image의 state가 cold인지 warm인지 판단하는 gating 이후에 적절한 레퍼런스 기반으로 few shot test하는것의 가능성은 일부 보았어.
4. [배경 지식2] 위의 가능성을 다른 모델에 적용하는것을 고민하다가 patchcore에 memory bank가 있는데, 여기에 conditon aware를 접목해보고 싶다는 생각을 했어. 특히 기존에 실험했을떄 accuracy 기준으로 patchcore는 96.3%(domainA), 96.4%(domainB), 79.9% (domainC), 91.6% (domainD)의 성능을 보였어. 참고로 해당 시점에는 patchcore + dino backbone을 사용했고, 관련된 실험은 examples/hdmap/analyze_experiment_results_single.py 파일과 examples/hdmap/single_domain/exp_23_patchcore.json 을 사용했으니 참고해 (지금보니 backbone은 vit_small_patch14_dinov2을 사용했네.) 그리고 그때는 학습 이미지를 엄청 많이 넣어여해서 모델도 작게 쓰고 layer도 작은것 위주로 했음.
5. [배경 지식3] 가장 최근에 patch core varaint 실험을 해서 cㅇd를 적용해서, 도메인 별로 2~3%정도의 성능 향상을 이끌었어. (중요: examples/notebooks/10_patchcore_variant/006_cpd_baseline_compare.md, examples/notebooks/10_patchcore_variant/006_cpd_results.md) 그 주변 마크다운 읽어도 좋고.
6. 그 와중에 FE_CLIP이라는 신규 논문을 찾아내었고, 나에게 적용하기 적절하다는 판단을 했어. 논문: Gong_FE-CLIP_Frequency_Enhanced_CLIP_Model_for_Zero-Shot_Anomaly_Detection_and_ICCV_2025_paper.pdf
7. 그래서 나는 winclip 모델(src/anomalib/models/image/winclip)이 있는것처럼 . FECLIP을 src/anomalib/models/image/feclip에 구현하고, 그 다음에 벤치마크 처럼 성능이 나오는지 확인하고, variant 실험을 해보고 싶어. 구체적인 fe clip 구현 가이드라인은 