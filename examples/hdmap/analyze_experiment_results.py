#!/usr/bin/env python3
"""
ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì—¬ëŸ¬ ì‹¤í—˜ ì„¸ì…˜ì˜ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ê° ì‹¤í—˜ ì¡°ê±´ë³„ë¡œ
image_AUROCì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

==============================================================================
ğŸš€ ê¸°ë³¸ ì‚¬ìš©ë²•:
==============================================================================

1. ë‹¨ì¼ ëª¨ë¸ ë¶„ì„:
   .venv/bin/python examples/hdmap/analyze_experiment_results.py --results_dir results/draem_single
   .venv/bin/python examples/hdmap/analyze_experiment_results.py --results_dir results/dinomaly_single
   .venv/bin/python examples/hdmap/analyze_experiment_results.py --results_dir results/patchcore_single

2. ëª¨ë“  ëª¨ë¸ í†µí•© ë¶„ì„ (ì¶”ì²œ):
   .venv/bin/python examples/hdmap/analyze_experiment_results.py --results_dir results --all-models

3. íŠ¹ì • ì‹¤í—˜ ì¡°ê±´ë§Œ ë¶„ì„:
   .venv/bin/python examples/hdmap/analyze_experiment_results.py --results_dir results --all-models --experiment_name "baseline"

4. ê²°ê³¼ CSVë¡œ ì €ì¥:
   .venv/bin/python examples/hdmap/analyze_experiment_results.py --results_dir results --all-models --output comparison.csv

==============================================================================
ğŸ“ ëŒ€ìƒ í´ë” êµ¬ì¡° (base-run.sh ê²°ê³¼):
==============================================================================

results/
â”œâ”€â”€ draem_single/20250830_143052/SingleDomainHDMAP/DRAEM/...
â”œâ”€â”€ dinomaly_single/20250830_143052/SingleDomainHDMAP/Dinomaly/...  
â”œâ”€â”€ patchcore_single/20250830_143052/SingleDomainHDMAP/PatchCore/...
â””â”€â”€ draem_sevnet_single/20250830_143052/SingleDomainHDMAP/DRAEM_SevNet/...

==============================================================================
ğŸ“Š ì¶œë ¥ ë‚´ìš©:
==============================================================================

--all-models ì‚¬ìš© ì‹œ:
- ëª¨ë¸ë³„ í‰ê· /ìµœê³ /ìµœì € AUROC ìš”ì•½
- ì „ì²´ ì‹¤í—˜ ì¡°ê±´ë³„ ìƒì„¸ ì„±ëŠ¥ (AUROC ìˆœ ì •ë ¬)  
- CSV íŒŒì¼ ìë™ ìƒì„±:
  * all_models_analysis_summary.csv (ì „ì²´ ìƒì„¸ ê²°ê³¼)
  * models_summary_all_models_analysis.csv (ëª¨ë¸ë³„ ìš”ì•½)

==============================================================================
ğŸ”§ ê³ ê¸‰ ì˜µì…˜:
==============================================================================

--model_type: ëª¨ë¸ íƒ€ì… ëª…ì‹œ (draem, dinomaly, patchcore ë“±)
--experiment_name: íŠ¹ì • ì‹¤í—˜ë§Œ ë¶„ì„ (ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­)
--output: ê²°ê³¼ CSV ì €ì¥ ê²½ë¡œ ì§€ì •

==============================================================================
ğŸ’¡ ì´ì „ ë²„ì „ í˜¸í™˜ì„±:
==============================================================================

ê¸°ì¡´ multidomain ê²°ê³¼ë„ ë¶„ì„ ê°€ëŠ¥:
    .venv/bin/python examples/hdmap/analyze_experiment_results.py --results_dir results_draem_14íšŒ/draem
    .venv/bin/python examples/hdmap/analyze_experiment_results.py --results_dir results_patchcore_AtoD/patchcore
"""

import argparse
import json
import re
from collections import defaultdict
from pathlib import Path
from typing import List, Tuple, Dict

import numpy as np
import pandas as pd


def extract_auroc_from_json(json_file_path: str) -> float:
    """JSON ê²°ê³¼ íŒŒì¼ì—ì„œ Image AUROC ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        json_file_path: JSON ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        AUROC ê°’ (float) ë˜ëŠ” None
    """
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        # source_resultsì—ì„œ test_image_AUROC ì¶”ì¶œ
        if 'source_results' in data and 'test_image_AUROC' in data['source_results']:
            return float(data['source_results']['test_image_AUROC'])
        else:
            print(f"   âš ï¸ {json_file_path}ì—ì„œ test_image_AUROC ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
    except Exception as e:
        print(f"   âŒ {json_file_path} íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None


def extract_auroc_from_log(log_file_path: str) -> float:
    """ë¡œê·¸ íŒŒì¼ì—ì„œ Image AUROC ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        log_file_path: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        AUROC ê°’ (float) ë˜ëŠ” None
    """
    try:
        with open(log_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # "Image AUROC=0.8445" íŒ¨í„´ ì°¾ê¸°
        import re
        pattern = r'Image AUROC=([0-9.]+)'
        match = re.search(pattern, content)
        
        if match:
            return float(match.group(1))
        else:
            print(f"   âš ï¸ {log_file_path}ì—ì„œ AUROC ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
    except Exception as e:
        print(f"   âŒ {log_file_path} íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None


class ExperimentResultsAnalyzer:
    """ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ê¸°"""
    
    def __init__(self, results_dir: str, model_type: str = None):
        """
        Args:
            results_dir: ì‹¤í—˜ ê²°ê³¼ê°€ ì €ì¥ëœ ê¸°ë³¸ ë””ë ‰í† ë¦¬ (ì˜ˆ: results/draem)
            model_type: ëª¨ë¸ íƒ€ì… ('draem', 'draem_sevnet', 'fastflow' ë“±). Noneì´ë©´ ìë™ ê°ì§€
        """
        self.results_dir = Path(results_dir)
        self.model_type = model_type
        self.experiment_data = defaultdict(list)
        
        # ëª¨ë¸ íƒ€ì… ìë™ ê°ì§€
        if self.model_type is None:
            self.model_type = self._detect_model_type()
            print(f"ìë™ ê°ì§€ëœ ëª¨ë¸ íƒ€ì…: {self.model_type}")
        
    def _detect_model_type(self) -> str:
        """ê²°ê³¼ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ íƒ€ì…ì„ ìë™ ê°ì§€í•©ë‹ˆë‹¤"""
        dir_name = self.results_dir.name.lower()
        
        # ë””ë ‰í† ë¦¬ ì´ë¦„ì—ì„œ ëª¨ë¸ íƒ€ì… ì¶”ì¶œ (ëŒ€ë¬¸ì ë°˜í™˜)
        if 'draem_sevnet' in dir_name:
            return 'DRAEM_SevNet'
        elif 'draem' in dir_name:
            return 'DRAEM'
        elif 'dinomaly' in dir_name:
            return 'Dinomaly'
        elif 'fastflow' in dir_name:
            return 'FastFlow'
        elif 'padim' in dir_name:
            return 'Padim'
        elif 'patchcore' in dir_name:
            return 'PatchCore'
        else:
            # ê¸°ë³¸ê°’ìœ¼ë¡œ DRAEM ì‚¬ìš©
            return 'DRAEM'
        
    def find_all_experiment_sessions(self) -> List[Path]:
        """ëª¨ë“  ì‹¤í—˜ ì„¸ì…˜ í´ë”ë¥¼ ì°¾ìŠµë‹ˆë‹¤ (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)"""
        sessions = []
        if not self.results_dir.exists():
            print(f"ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.results_dir}")
            return sessions
            
        for item in self.results_dir.iterdir():
            if item.is_dir() and item.name.startswith('2025'):  # íƒ€ì„ìŠ¤íƒ¬í”„ íŒ¨í„´
                sessions.append(item)
                
        return sorted(sessions, key=lambda x: x.name)
    
    def load_experiment_results(self, session_path: Path) -> Dict[str, dict]:
        """íŠ¹ì • ì„¸ì…˜ì˜ ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤"""
        results = {}
        
        # MultiDomainHDMAP/{model_type}/ ë˜ëŠ” SingleDomainHDMAP/{model_type}/ í•˜ìœ„ì˜ ëª¨ë“  ì‹¤í—˜ í´ë” ê²€ìƒ‰
        possible_paths = [
            session_path / "MultiDomainHDMAP" / self.model_type,
            session_path / "SingleDomainHDMAP" / self.model_type
        ]
        
        experiment_base_path = None
        for path in possible_paths:
            if path.exists():
                experiment_base_path = path
                break
        
        if experiment_base_path is None:
            print(f"ì‹¤í—˜ ê²°ê³¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {possible_paths}")
            return results
            
        for exp_folder in experiment_base_path.iterdir():
            if not exp_folder.is_dir():
                continue
                
            # tensorboard_logs/result_*.json íŒŒì¼ ì°¾ê¸°
            tensorboard_path = exp_folder / "tensorboard_logs"
            if not tensorboard_path.exists():
                continue
                
            for json_file in tensorboard_path.glob("result_*.json"):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        
                    # ì‹¤í—˜ ì´ë¦„ ì¶”ì¶œ - condition.name ìš°ì„ , ì—†ìœ¼ë©´ experiment_name ì‚¬ìš©
                    condition_info = data.get('condition', {})
                    if isinstance(condition_info, dict) and 'name' in condition_info:
                        condition_name = condition_info['name']
                    else:
                        condition_name = data.get('experiment_name', 'unknown')
                    
                    # íƒ€ì„ìŠ¤íƒ¬í”„ íŒ¨í„´ ì œê±° (ì˜ˆ: _20250817_145220)
                    if condition_name.startswith('DRAEM_'):
                        condition_name = re.sub(r'_\d{8}_\d{6}$', '', condition_name)
                    
                    results[condition_name] = data
                    
                except Exception as e:
                    print(f"JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {json_file}, ì˜¤ë¥˜: {e}")
                    
        return results
    
    def collect_all_results(self) -> None:
        """ëª¨ë“  ì„¸ì…˜ì˜ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤"""
        sessions = self.find_all_experiment_sessions()
        print(f"ë°œê²¬ëœ ì‹¤í—˜ ì„¸ì…˜: {len(sessions)}ê°œ")
        
        for session in sessions:
            print(f"\nì„¸ì…˜ ë¶„ì„ ì¤‘: {session.name}")
            session_results = self.load_experiment_results(session)
            
            for condition_name, data in session_results.items():
                self.experiment_data[condition_name].append(data)
                
        print(f"\nì´ ìˆ˜ì§‘ëœ ì‹¤í—˜ ì¡°ê±´: {len(self.experiment_data)}ê°œ")
        for condition, runs in self.experiment_data.items():
            print(f"  {condition}: {len(runs)}íšŒ ì‹¤í–‰")
    
    def calculate_statistics(self, experiment_name: str = None) -> pd.DataFrame:
        """í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤"""
        if experiment_name and experiment_name not in self.experiment_data:
            print(f"ì‹¤í—˜ '{experiment_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        conditions_to_analyze = [experiment_name] if experiment_name else list(self.experiment_data.keys())
        
        results = []
        
        for condition_name in conditions_to_analyze:
            runs = self.experiment_data[condition_name]
            if not runs:
                continue
                
            print(f"\n=== {condition_name} ë¶„ì„ ===")
            print(f"ì´ ì‹¤í–‰ íšŸìˆ˜: {len(runs)}")
            
            # ë™ì ìœ¼ë¡œ sourceì™€ target ë„ë©”ì¸ ê°ì§€
            source_aurocs = []
            target_aurocs_by_domain = {}  # domain_name -> [auroc_values]
            avg_target_aurocs = []
            source_domain = None
            target_domains = []
            
            for run in runs:
                # Source domain ì°¾ê¸° - source_resultsì—ì„œ ë¨¼ì € ì°¾ê³ , ì—†ìœ¼ë©´ resultsì—ì„œ ì°¾ê¸° (ë‹¨ì¼ ë„ë©”ì¸ ì‹¤í—˜ìš©)
                source_result = run.get('source_results', {})
                auroc_value = None
                
                if 'test_image_AUROC' in source_result:
                    auroc_value = source_result['test_image_AUROC']
                elif 'image_AUROC' in run.get('results', {}):
                    # ë‹¨ì¼ ë„ë©”ì¸ ì‹¤í—˜ì˜ ê²½ìš° results.image_AUROC ì‚¬ìš©
                    auroc_value = run.get('results', {})['image_AUROC']
                elif 'test_image_AUROC' in run.get('source_results', {}):
                    auroc_value = run.get('source_results', {})['test_image_AUROC']
                
                if auroc_value is not None:
                    source_aurocs.append(auroc_value)
                    # source ë„ë©”ì¸ ì´ë¦„ ì¶”ì¶œ (condition.configì—ì„œ)
                    if source_domain is None:
                        condition = run.get('condition', {})
                        config = condition.get('config', {})
                        if 'source_domain' in config:
                            source_domain = config['source_domain'].replace('domain_', '')  # domain_A -> A
                        elif 'domain' in run.get('results', {}):
                            # ë‹¨ì¼ ë„ë©”ì¸ ì‹¤í—˜ì˜ ê²½ìš° results.domain ì‚¬ìš©
                            source_domain = run.get('results', {})['domain'].replace('domain_', '')
                
                # Target domains ìˆ˜ì§‘
                target_results = run.get('target_results', {})
                current_run_target_aucs = []
                
                for domain_key, domain_data in target_results.items():
                    if 'test_image_AUROC' in domain_data:
                        domain_name = domain_key.replace('domain_', '')  # domain_B -> B
                        
                        if domain_name not in target_aurocs_by_domain:
                            target_aurocs_by_domain[domain_name] = []
                            target_domains.append(domain_name)
                        
                        auroc_value = domain_data['test_image_AUROC']
                        target_aurocs_by_domain[domain_name].append(auroc_value)
                        current_run_target_aucs.append(auroc_value)
                
                # ì´ë²ˆ runì˜ í‰ê·  target AUROC ê³„ì‚°
                if current_run_target_aucs:
                    avg_target_aurocs.append(np.mean(current_run_target_aucs))
            
            # target_domains ì •ë ¬ (ì¼ê´€ì„±ì„ ìœ„í•´)
            target_domains = sorted(target_domains)
            
            # í†µê³„ ê³„ì‚° ë° ì €ì¥
            def calc_stats(values: List[float]) -> Tuple[float, float, int]:
                if not values:
                    return 0.0, 0.0, 0
                return np.mean(values), np.std(values, ddof=1) if len(values) > 1 else 0.0, len(values)
            
            source_mean, source_std, source_count = calc_stats(source_aurocs)
            avg_target_mean, avg_target_std, avg_target_count = calc_stats(avg_target_aurocs)
            
            # ê° target ë„ë©”ì¸ë³„ í†µê³„ ê³„ì‚°
            target_stats = {}
            for domain in target_domains:
                if domain in target_aurocs_by_domain:
                    mean, std, count = calc_stats(target_aurocs_by_domain[domain])
                    target_stats[domain] = {
                        'mean': mean,
                        'std': std,
                        'count': count
                    }
            
            # Transfer ratio ê³„ì‚° (avg_target_auroc_mean / source_auroc_mean)
            transfer_ratio = avg_target_mean / source_mean if source_mean > 0 else 0.0
            
            # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë™ì  êµ¬ì„± (experiment_nameì€ ê°„ë‹¨í•œ ì´ë¦„ë§Œ)
            result_dict = {
                'experiment_name': condition_name,  # ê°„ë‹¨í•œ ì‹¤í—˜ ì´ë¦„
                'total_runs': len(runs),
                'source_domain': source_domain or 'Unknown',
                'source_auroc_mean': source_mean,
                'source_auroc_std': source_std,
                'source_auroc_count': source_count,
                'avg_target_auroc_mean': avg_target_mean,
                'avg_target_auroc_std': avg_target_std,
                'avg_target_auroc_count': avg_target_count,
                'transfer_ratio': transfer_ratio
            }
            
            # ê° target ë„ë©”ì¸ë³„ ê²°ê³¼ ì¶”ê°€ (ì‹¤ì œ target ë„ë©”ì¸ë§Œ)
            for domain in target_domains:
                if domain in target_stats:
                    result_dict[f'target_{domain}_auroc_mean'] = target_stats[domain]['mean']
                    result_dict[f'target_{domain}_auroc_std'] = target_stats[domain]['std']
                    result_dict[f'target_{domain}_auroc_count'] = target_stats[domain]['count']
            
            results.append(result_dict)
            
            # ì½˜ì†” ì¶œë ¥
            print(f"Source Domain: {source_domain or 'Unknown'}")
            print(f"Source AUROC: {source_mean:.4f} Â± {source_std:.4f} (n={source_count})")
            
            # Target ë„ë©”ì¸ë³„ ì¶œë ¥
            for domain in sorted(target_domains):
                if domain in target_stats:
                    stats = target_stats[domain]
                    print(f"Target {domain} AUROC: {stats['mean']:.4f} Â± {stats['std']:.4f} (n={stats['count']})")
            
            print(f"í‰ê·  Target AUROC: {avg_target_mean:.4f} Â± {avg_target_std:.4f} (n={avg_target_count})")
            print(f"Transfer Ratio: {transfer_ratio:.4f}")
        
        return pd.DataFrame(results)
    
    def save_results(self, df: pd.DataFrame, output_path: str = None) -> None:
        """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤"""
        if df.empty:
            print("ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        if output_path is None:
            output_path = self.results_dir / "experiment_analysis_summary.csv"
        
        df.to_csv(output_path, index=False, encoding='utf-8')
        print(f"\nê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
    
    def print_summary(self, df: pd.DataFrame) -> None:
        """ìš”ì•½ í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤"""
        if df.empty:
            print("ì¶œë ¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        print("\n" + "="*80)
        print("ì‹¤í—˜ ê²°ê³¼ ìš”ì•½")
        print("="*80)
        
        # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •ì„ ìœ„í•œ ì„¤ì •
        pd.set_option('display.max_columns', None)
        pd.set_option('display.width', None)
        pd.set_option('display.max_colwidth', 30)
        pd.set_option('display.expand_frame_repr', False)
        
        # ì£¼ìš” ì»¬ëŸ¼ë§Œ ì„ íƒí•´ì„œ ì¶œë ¥
        summary_cols = [
            'experiment_name', 'total_runs', 'source_domain',
            'source_auroc_mean', 'source_auroc_std',
            'avg_target_auroc_mean', 'avg_target_auroc_std',
            'transfer_ratio'
        ]
        
        summary_df = df[summary_cols].copy()
        
        # ì •ë ¬: source_auroc_mean ë†’ì€ ìˆœ, ê°™ë‹¤ë©´ avg_target_auroc_mean ë†’ì€ ìˆœ
        summary_df = summary_df.sort_values(
            by=['source_auroc_mean', 'avg_target_auroc_mean'], 
            ascending=[False, False]
        )
        
        summary_df['source_auroc_mean'] = summary_df['source_auroc_mean'].round(4)
        summary_df['source_auroc_std'] = summary_df['source_auroc_std'].round(4)
        summary_df['avg_target_auroc_mean'] = summary_df['avg_target_auroc_mean'].round(4)
        summary_df['avg_target_auroc_std'] = summary_df['avg_target_auroc_std'].round(4)
        summary_df['transfer_ratio'] = summary_df['transfer_ratio'].round(4)
        
        print(summary_df.to_string(index=False))
        
        print("\n" + "="*80)


def analyze_all_models(results_base_dir: str, experiment_name: str = None, output: str = None):
    """ëª¨ë“  ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ í†µí•© ë¶„ì„"""
    results_base_path = Path(results_base_dir)
    
    print(f"ğŸ” ëª¨ë“  ëª¨ë¸ í†µí•© ë¶„ì„ ì‹œì‘...")
    print(f"ğŸ“ ê¸°ë³¸ ë””ë ‰í† ë¦¬: {results_base_path}")
    
    # ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ êµ¬ì¡°: results/timestamp/experiment_name/
    # ëª¨ë“  timestamp ë””ë ‰í† ë¦¬ë¥¼ ì°¾ê³ , ê·¸ ì•ˆì˜ ì‹¤í—˜ ë””ë ‰í† ë¦¬ë“¤ì„ ë¶„ì„
    timestamp_dirs = [d for d in results_base_path.iterdir() if d.is_dir() and d.name.replace('_', '').isdigit()]
    
    if not timestamp_dirs:
        print(f"âŒ {results_base_path}ì—ì„œ timestamp ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ëª¨ë“  ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ìˆ˜ì§‘
    all_experiment_dirs = []
    for timestamp_dir in timestamp_dirs:
        experiment_dirs = [d for d in timestamp_dir.iterdir() if d.is_dir()]
        all_experiment_dirs.extend(experiment_dirs)
    
    if not all_experiment_dirs:
        print(f"âŒ timestamp ë””ë ‰í† ë¦¬ë“¤ì—ì„œ ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“Š ë°œê²¬ëœ ì‹¤í—˜ ë””ë ‰í† ë¦¬: {len(all_experiment_dirs)}ê°œ")
    print(f"   ì˜ˆì‹œ: {[d.name for d in all_experiment_dirs[:3]]}")
    
    # ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ëª¨ë¸ë³„ë¡œ ê·¸ë£¹í™”
    model_groups = {}
    for exp_dir in all_experiment_dirs:
        # ì‹¤í—˜ ì´ë¦„ì—ì„œ ëª¨ë¸ íƒ€ì… ì¶”ì¶œ (ì˜ˆ: domainA_patchcore_baseline_timestamp -> patchcore)
        exp_name = exp_dir.name
        
        # timestamp ë¶€ë¶„ ì œê±° (ë§ˆì§€ë§‰ _YYYYMMDD_HHMMSS íŒ¨í„´)
        import re
        exp_name_clean = re.sub(r'_\d{8}_\d{6}$', '', exp_name)
        
        # domainA_ ë¶€ë¶„ ì œê±°
        if exp_name_clean.startswith('domainA_'):
            remaining = exp_name_clean[8:]  # 'domainA_' ì œê±°
            
            # ëª¨ë¸ íƒ€ì… ì¶”ì¶œ (ì²« ë²ˆì§¸ ë‹¨ì–´ê°€ ëª¨ë¸ íƒ€ì…)
            if '_' in remaining:
                model_type_lower = remaining.split('_')[0]
            else:
                model_type_lower = remaining
                
            if model_type_lower not in model_groups:
                model_groups[model_type_lower] = []
            model_groups[model_type_lower].append(exp_dir)
    
    if not model_groups:
        print(f"âŒ ìœ íš¨í•œ ëª¨ë¸ ì‹¤í—˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ¯ ë°œê²¬ëœ ëª¨ë¸ë“¤: {list(model_groups.keys())}")
    
    all_results = []
    
    for model_type_lower, experiment_dirs in model_groups.items():
        # ëª¨ë¸ íƒ€ì… ë§¤í•‘ (ëŒ€ë¬¸ì)
        model_type_mapping = {
            'draem': 'DRAEM',
            'dinomaly': 'Dinomaly', 
            'patchcore': 'PatchCore',
            'draem_sevnet': 'DRAEM_SevNet'
        }
        model_type = model_type_mapping.get(model_type_lower, model_type_lower.upper())
        
        print(f"\nğŸ”¬ {model_type} ë¶„ì„ ì¤‘... ({len(experiment_dirs)}ê°œ ì‹¤í—˜)")
        
        try:
            # ê° ì‹¤í—˜ ë””ë ‰í† ë¦¬ì—ì„œ ê²°ê³¼ ìˆ˜ì§‘
            experiment_results = []
            
            for exp_dir in experiment_dirs:
                # ë¨¼ì € JSON ê²°ê³¼ íŒŒì¼ ì°¾ê¸° (ìš°ì„ ìˆœìœ„)
                json_files = list((exp_dir / "tensorboard_logs").glob("result_*.json")) if (exp_dir / "tensorboard_logs").exists() else []
                auroc = None
                
                if json_files:
                    # JSON íŒŒì¼ì´ ìˆìœ¼ë©´ JSONì—ì„œ ì¶”ì¶œ
                    try:
                        auroc = extract_auroc_from_json(str(json_files[0]))
                    except Exception as e:
                        print(f"   âš ï¸ {exp_dir.name} JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                
                if auroc is None:
                    # JSONì—ì„œ ëª» ì°¾ìœ¼ë©´ ë¡œê·¸ íŒŒì¼ì—ì„œ ì°¾ê¸° (ë°±ì—…)
                    log_file = exp_dir / "domain_A_single.log"
                    if log_file.exists():
                        try:
                            auroc = extract_auroc_from_log(str(log_file))
                        except Exception as e:
                            print(f"   âš ï¸ {exp_dir.name} ë¡œê·¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
                
                if auroc is not None:
                    experiment_results.append({
                        'experiment_name': exp_dir.name,
                        'image_AUROC': auroc,
                        'session_id': exp_dir.parent.name  # timestamp
                    })
            
            if not experiment_results:
                print(f"âš ï¸ {model_type}ì—ì„œ ìœ íš¨í•œ AUROC ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # DataFrame ìƒì„± ë° í†µê³„ ê³„ì‚°
            model_df = pd.DataFrame(experiment_results)
            
            if not model_df.empty:
                # ëª¨ë¸ íƒ€ì… ì»¬ëŸ¼ ì¶”ê°€
                model_df['Model'] = model_type
                all_results.append(model_df)
                print(f"âœ… {model_type}: {len(model_df)} ê°œ ì‹¤í—˜ ì¡°ê±´")
            else:
                print(f"âš ï¸ {model_type}: ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ {model_type} ë¶„ì„ ì‹¤íŒ¨: {e}")
            continue
    
    if not all_results:
        print("âŒ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ëª¨ë“  ê²°ê³¼ í†µí•©
    combined_df = pd.concat(all_results, ignore_index=True)
    
    # ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬ (Modelì„ ì•ìœ¼ë¡œ)
    cols = ['Model'] + [col for col in combined_df.columns if col != 'Model']
    combined_df = combined_df[cols]
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*80}")
    print(f"ğŸ¯ ëª¨ë“  ëª¨ë¸ í†µí•© ë¶„ì„ ê²°ê³¼")
    print(f"{'='*80}")
    print(f"ì´ ëª¨ë¸ ìˆ˜: {combined_df['Model'].nunique()}")
    print(f"ì´ ì‹¤í—˜ ì¡°ê±´ ìˆ˜: {len(combined_df)}")
    print(f"\nğŸ“Š ëª¨ë¸ë³„ Image AUROC ìš”ì•½:")
    
    # ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥ ì¶œë ¥ (ì‹¤ì œ ì»¬ëŸ¼ëª… ì‚¬ìš©)
    auroc_column = 'image_AUROC'  # ì‹¤ì œ ì»¬ëŸ¼ëª…ì€ image_AUROC
    model_summary = None
    
    if auroc_column in combined_df.columns:
        model_summary = combined_df.groupby('Model')[auroc_column].agg(['mean', 'max', 'min', 'count']).round(4)
        model_summary.columns = ['í‰ê· _AUROC', 'ìµœê³ _AUROC', 'ìµœì €_AUROC', 'ì‹¤í—˜_ìˆ˜']
        model_summary = model_summary.sort_values('í‰ê· _AUROC', ascending=False)
        
        print(model_summary)
        
        print(f"\nğŸ“ˆ ì „ì²´ ìƒì„¸ ê²°ê³¼:")
        # Image AUROC ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•´ì„œ ì¶œë ¥
        display_df = combined_df.sort_values(auroc_column, ascending=False)
    else:
        print(f"âš ï¸ AUROC ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(combined_df.columns)}")
        display_df = combined_df
    print(display_df.to_string(index=False))
    
    # ê²°ê³¼ ì €ì¥
    if output is None:
        output = results_base_path / "all_models_analysis_summary.csv"
    else:
        output = Path(output)
    
    combined_df.to_csv(output, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ í†µí•© ê²°ê³¼ ì €ì¥ë¨: {output}")
    
    # ëª¨ë¸ë³„ ìš”ì•½ë„ ì €ì¥ (model_summaryê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
    if model_summary is not None:
        summary_output = output.parent / f"models_summary_{output.stem}.csv"
        model_summary.to_csv(summary_output, encoding='utf-8-sig')
        print(f"ğŸ“‹ ëª¨ë¸ë³„ ìš”ì•½ ì €ì¥ë¨: {summary_output}")
    else:
        print("âš ï¸ ëª¨ë¸ë³„ ìš”ì•½ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")


def main():
    parser = argparse.ArgumentParser(description='ì‹¤í—˜ ê²°ê³¼ ë¶„ì„')
    parser.add_argument(
        '--results_dir', 
        type=str, 
        default='/home/taewan.hwang/study/anomalib/results/draem',
        help='ì‹¤í—˜ ê²°ê³¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ'
    )
    parser.add_argument(
        '--model_type', 
        type=str, 
        default=None,
        help='ëª¨ë¸ íƒ€ì… (draem, draem_sevnet, fastflow, padim ë“±). Noneì´ë©´ ìë™ ê°ì§€'
    )
    parser.add_argument(
        '--experiment_name', 
        type=str, 
        default=None,
        help='íŠ¹ì • ì‹¤í—˜ë§Œ ë¶„ì„ (ì˜ˆ: DRAEM_baseline_50epochs)'
    )
    parser.add_argument(
        '--output', 
        type=str, 
        default=None,
        help='ê²°ê³¼ ì €ì¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: results_dir/experiment_analysis_summary.csv)'
    )
    parser.add_argument(
        '--all-models',
        action='store_true',
        help='results ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ëª¨ë¸ ê²°ê³¼ë¥¼ í†µí•© ë¶„ì„ (ì˜ˆ: results/)'
    )
    
    args = parser.parse_args()
    
    if args.all_models:
        # ëª¨ë“  ëª¨ë¸ í†µí•© ë¶„ì„
        analyze_all_models(args.results_dir, args.experiment_name, args.output)
    else:
        # ë‹¨ì¼ ëª¨ë¸ ë¶„ì„ (ê¸°ì¡´ ë°©ì‹)
        print(f"ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ì‹œì‘...")
        print(f"ê²°ê³¼ ë””ë ‰í† ë¦¬: {args.results_dir}")
        if args.model_type:
            print(f"ì§€ì •ëœ ëª¨ë¸ íƒ€ì…: {args.model_type}")
        if args.experiment_name:
            print(f"íŠ¹ì • ì‹¤í—˜ ë¶„ì„: {args.experiment_name}")
        
        # ë¶„ì„ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
        analyzer = ExperimentResultsAnalyzer(args.results_dir, args.model_type)
        analyzer.collect_all_results()
        
        # í†µê³„ ê³„ì‚°
        results_df = analyzer.calculate_statistics(args.experiment_name)
        
        # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
        analyzer.print_summary(results_df)
        analyzer.save_results(results_df, args.output)


if __name__ == "__main__":
    main()
