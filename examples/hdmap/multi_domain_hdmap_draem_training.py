#!/usr/bin/env python3
"""HDMAP ë‹¤ì¤‘ ë„ë©”ì¸ DRAEM ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ ìŠ¤í¬ë¦½íŠ¸.

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” HDMAP ë°ì´í„°ì…‹ì—ì„œ DRAEM ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ë‹¤ì¤‘ ë„ë©”ì¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- DRAEM ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ìƒ íƒì§€
- ì†ŒìŠ¤ ë„ë©”ì¸(domain_A)ì—ì„œ í›ˆë ¨
- íƒ€ê²Ÿ ë„ë©”ì¸ë“¤(domain_B, C, D)ì—ì„œ í‰ê°€
- ì‹¤í—˜ ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
- ì²´ê³„ì ì¸ ì‹¤í—˜ ì¡°ê±´ ê´€ë¦¬

ì‚¬ìš©ë²•:
    python multi_domain_hdmap_draem_training.py --experiment_name my_experiment --max_epochs 50
    python multi_domain_hdmap_draem_training.py --run_all_experiments

"""

import argparse
import json
import logging
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

from anomalib.models.image.draem import Draem
from anomalib.data.datamodules.image.multi_domain_hdmap import MultiDomainHDMAPDataModule
from anomalib.engine import Engine
from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint
from pytorch_lightning.loggers import TensorBoardLogger

# Experiment utilities import
from experiment_utils import (
    setup_warnings_filter,
    setup_experiment_logging,
    cleanup_gpu_memory,
    create_multi_domain_datamodule,
    evaluate_source_domain,
    evaluate_target_domains,
    extract_training_info,
    create_experiment_visualization,
    organize_source_domain_results,
    save_experiment_results,
    analyze_multi_experiment_results
)

# ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™” (DraemSevNetê³¼ ë™ì¼)
setup_warnings_filter()
logging.getLogger("anomalib.visualization.image.item_visualizer").setLevel(logging.ERROR)
logging.getLogger("anomalib.visualization").setLevel(logging.ERROR)
logging.getLogger("anomalib.callbacks").setLevel(logging.ERROR)
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="lightning")



# ì‹¤í—˜ ì¡°ê±´ ì •ì˜
EXPERIMENT_CONDITIONS = [
    {
        "name": "DRAEM_quick_3epochs",
        "description": "DRAEM ê°„ë‹¨ í…ŒìŠ¤íŠ¸ (3 ì—í¬í¬)",
        "config": {
            "max_epochs": 3,
            "early_stopping_patience": 1,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "image_size": "224x224"
        }
    },
    {
        "name": "DRAEM_baseline_50epochs",
        "description": "DRAEM ê¸°ë³¸ ì„¤ì • (50 ì—í¬í¬)",
        "config": {
            "max_epochs": 50,
            "early_stopping_patience": 10,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "image_size": "224x224"
        }
    },
    {
        "name": "DRAEM_extended_100epochs",
        "description": "DRAEM í™•ì¥ í›ˆë ¨ (100 ì—í¬í¬)",
        "config": {
            "max_epochs": 100,
            "early_stopping_patience": 15,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "image_size": "224x224"
        }
    },
    {
        "name": "DRAEM_lower_lr",
        "description": "DRAEM ë‚®ì€ í•™ìŠµë¥  (0.00005)",
        "config": {
            "max_epochs": 50,
            "early_stopping_patience": 10,
            "learning_rate": 0.00005,
            "batch_size": 16,
            "image_size": "224x224"
        }
    },
    {
        "name": "DRAEM_higher_lr",
        "description": "DRAEM ë†’ì€ í•™ìŠµë¥  (0.0002)",
        "config": {
            "max_epochs": 50,
            "early_stopping_patience": 10,
            "learning_rate": 0.0002,
            "batch_size": 16,
            "image_size": "224x224"
        }
    },
    {
        "name": "DRAEM_larger_batch",
        "description": "DRAEM í° ë°°ì¹˜ í¬ê¸° (32)",
        "config": {
            "max_epochs": 50,
            "early_stopping_patience": 10,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "image_size": "224x224"
        }
    },
    {
        "name": "DRAEM_smaller_batch",
        "description": "DRAEM ì‘ì€ ë°°ì¹˜ í¬ê¸° (8)",
        "config": {
            "max_epochs": 50,
            "early_stopping_patience": 10,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "image_size": "224x224"
        }
    },
    {
        "name": "DRAEM_longer_patience",
        "description": "DRAEM ê¸´ patience (20)",
        "config": {
            "max_epochs": 50,
            "early_stopping_patience": 20,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "image_size": "224x224"
        }
    },
    {
        "name": "DRAEM_shorter_patience",
        "description": "DRAEM ì§§ì€ patience (5)",
        "config": {
            "max_epochs": 50,
            "early_stopping_patience": 5,
            "learning_rate": 0.0001,
            "batch_size": 16,
            "image_size": "224x224"
        }
    },
    {
        "name": "DRAEM_quick_test",
        "description": "DRAEM ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (5 ì—í¬í¬)",
        "config": {
            "max_epochs": 5,
            "early_stopping_patience": 3,
            "learning_rate": 0.0001,
            "batch_size": 8,
            "image_size": "224x224"
        }
    }
]


def train_draem_model_multi_domain(
    datamodule: MultiDomainHDMAPDataModule, 
    config: Dict[str, Any],
    results_base_dir: str,
    experiment_name: str,
    logger: logging.Logger
) -> tuple[Draem, Engine, str]:
    """DRAEM ëª¨ë¸ í›ˆë ¨ ìˆ˜í–‰.
    
    Args:
        datamodule: ì„¤ì •ëœ MultiDomainHDMAPDataModule
        config: í›ˆë ¨ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        results_base_dir: ê²°ê³¼ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ
        experiment_name: ì‹¤í—˜ ì´ë¦„
        logger: ë¡œê±° ê°ì²´
        
    Returns:
        tuple: (í›ˆë ¨ëœ ëª¨ë¸, Engine ê°ì²´, ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ)
    """
    print(f"\nğŸš€ DRAEM ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    logger.info("ğŸš€ DRAEM ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    
    # DRAEM ëª¨ë¸ ì´ˆê¸°í™” (validation loss í¬í•¨)
    model = Draem()
    print(f"   âœ… DRAEM ëª¨ë¸ ìƒì„± ì™„ë£Œ (validation loss í¬í•¨)")
    logger.info("âœ… DRAEM ëª¨ë¸ ìƒì„± ì™„ë£Œ (validation loss í¬í•¨)")
    
    # Early stoppingê³¼ model checkpoint ì„¤ì •
    early_stopping = EarlyStopping(
        monitor="val_loss",
        patience=config["early_stopping_patience"],
        mode="min",
        verbose=True
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì •
    checkpoint_callback = ModelCheckpoint(
        filename=f"draem_multi_domain_{datamodule.source_domain}_" + "{epoch:02d}_{val_loss:.4f}",
        monitor="val_loss",
        mode="min",
        save_top_k=1,
        verbose=True
    )
    
    print(f"   ğŸ“Š Early Stopping: patience={config['early_stopping_patience']}, monitor=val_loss")
    print(f"   ğŸ’¾ Model Checkpoint: monitor=val_loss, save_top_k=1")
    logger.info(f"ğŸ“Š Early Stopping ì„¤ì •: patience={config['early_stopping_patience']}")
    logger.info(f"ğŸ’¾ Model Checkpoint ì„¤ì •: monitor=val_loss")
    
    # TensorBoard ë¡œê±° ì„¤ì • (DraemSevNetê³¼ ë™ì¼)
    tb_logger = TensorBoardLogger(
        save_dir=results_base_dir,
        name="tensorboard_logs",
        version=""  # ë¹ˆ ë²„ì „ìœ¼ë¡œ version_x í´ë” ë°©ì§€
    )
    
    # Engine ìƒì„± ë° í›ˆë ¨
    engine = Engine(
        accelerator="gpu" if torch.cuda.is_available() else "cpu",
        devices=[0] if torch.cuda.is_available() else 1,
        logger=tb_logger,
        max_epochs=config["max_epochs"],
        callbacks=[early_stopping, checkpoint_callback],
        check_val_every_n_epoch=1,
        enable_checkpointing=True,
        log_every_n_steps=10,
        enable_model_summary=True,
        num_sanity_val_steps=0,
        default_root_dir=results_base_dir
    )
    
    print(f"   ğŸ”§ Engine ì„¤ì • ì™„ë£Œ - max_epochs: {config['max_epochs']}")
    print(f"   ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {results_base_dir}")
    logger.info(f"ğŸ”§ Engine ì„¤ì • ì™„ë£Œ - max_epochs: {config['max_epochs']}")
    logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {results_base_dir}")
    
    # ëª¨ë¸ í›ˆë ¨
    print(f"   ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    logger.info("ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    
    engine.fit(
        model=model,
        datamodule=datamodule
    )
    
    print(f"   âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    logger.info("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    
    # ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ í™•ì¸
    best_checkpoint = checkpoint_callback.best_model_path
    print(f"   ğŸ† Best Checkpoint: {best_checkpoint}")
    logger.info(f"ğŸ† Best Checkpoint: {best_checkpoint}")
    
    # ì‹¤ì œ ìƒì„±ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì¶”ì¶œ
    if hasattr(engine.trainer, 'default_root_dir'):
        actual_results_dir = engine.trainer.default_root_dir
        print(f"   ğŸ“‚ ì‹¤ì œ ê²°ê³¼ ë””ë ‰í† ë¦¬: {actual_results_dir}")
        logger.info(f"ğŸ“‚ ì‹¤ì œ ê²°ê³¼ ë””ë ‰í† ë¦¬: {actual_results_dir}")
    else:
        actual_results_dir = results_base_dir
    
    return model, engine, best_checkpoint


def analyze_draem_results(
    source_results: Dict[str, Any],
    target_results: Dict[str, Dict[str, Any]],
    training_info: Dict[str, Any],
    condition: Dict[str, Any],
    logger: logging.Logger
) -> Dict[str, Any]:
    """DRAEM ì‹¤í—˜ ê²°ê³¼ ë¶„ì„.
    
    Args:
        source_results: ì†ŒìŠ¤ ë„ë©”ì¸ í‰ê°€ ê²°ê³¼
        target_results: íƒ€ê²Ÿ ë„ë©”ì¸ í‰ê°€ ê²°ê³¼
        training_info: í›ˆë ¨ ì •ë³´
        condition: ì‹¤í—˜ ì¡°ê±´
        logger: ë¡œê±° ê°ì²´
        
    Returns:
        Dict[str, Any]: ë¶„ì„ëœ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print(f"\nğŸ“Š DRAEM ì‹¤í—˜ ê²°ê³¼ ë¶„ì„")
    logger.info("ğŸ“Š DRAEM ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ì‹œì‘")
    
    # íƒ€ê²Ÿ ë„ë©”ì¸ í‰ê·  AUROC ê³„ì‚°
    target_aurocs = []
    for domain, result in target_results.items():
        if isinstance(result.get('image_AUROC'), (int, float)):
            target_aurocs.append(result['image_AUROC'])
    
    avg_target_auroc = sum(target_aurocs) / len(target_aurocs) if target_aurocs else 0.0
    
    # ì†ŒìŠ¤ ë„ë©”ì¸ AUROC
    source_auroc = source_results.get('image_AUROC', 0.0) if source_results else 0.0
    
    # ë„ë©”ì¸ ì „ì´ íš¨ê³¼ ê³„ì‚°
    transfer_ratio = avg_target_auroc / source_auroc if source_auroc > 0 else 0.0
    
    # ì„±ëŠ¥ í‰ê°€
    if transfer_ratio > 0.9:
        transfer_grade = "ìš°ìˆ˜"
    elif transfer_ratio > 0.8:
        transfer_grade = "ì–‘í˜¸"
    elif transfer_ratio > 0.7:
        transfer_grade = "ë³´í†µ"
    else:
        transfer_grade = "ê°œì„ í•„ìš”"
    
    # ê²°ê³¼ ìš”ì•½
    analysis = {
        "experiment_name": condition["name"],
        "source_auroc": source_auroc,
        "avg_target_auroc": avg_target_auroc,
        "transfer_ratio": transfer_ratio,
        "transfer_grade": transfer_grade,
        "target_domain_count": len(target_results),
        "training_epochs": training_info.get("last_trained_epoch", 0),
        "early_stopped": training_info.get("early_stopped", False),
        "best_val_auroc": training_info.get("best_val_auroc", 0.0)
    }
    
    # ë„ë©”ì¸ë³„ ìƒì„¸ ì„±ëŠ¥
    domain_performances = {}
    for domain, result in target_results.items():
        domain_performances[domain] = {
            "auroc": result.get('image_AUROC', 0.0),
            "f1_score": result.get('image_F1Score', 0.0)
        }
    
    analysis["domain_performances"] = domain_performances
    
    # ë¡œê¹…
    print(f"   ğŸ“ˆ Source AUROC: {source_auroc:.4f}")
    print(f"   ğŸ¯ Target í‰ê·  AUROC: {avg_target_auroc:.4f}")
    print(f"   ğŸ”„ ì „ì´ ë¹„ìœ¨: {transfer_ratio:.3f} ({transfer_grade})")
    print(f"   ğŸ“š í›ˆë ¨ ì—í¬í¬: {analysis['training_epochs']}")
    
    logger.info(f"ğŸ“ˆ Source AUROC: {source_auroc:.4f}")
    logger.info(f"ğŸ¯ Target í‰ê·  AUROC: {avg_target_auroc:.4f}")
    logger.info(f"ğŸ”„ ì „ì´ ë¹„ìœ¨: {transfer_ratio:.3f} ({transfer_grade})")
    logger.info(f"ğŸ“š í›ˆë ¨ ì—í¬í¬: {analysis['training_epochs']}")
    
    for domain, perf in domain_performances.items():
        print(f"   â””â”€ {domain}: AUROC={perf['auroc']:.4f}")
        logger.info(f"   â””â”€ {domain}: AUROC={perf['auroc']:.4f}")
    
    return analysis


def run_single_draem_experiment(
    condition: Dict[str, Any],
    source_domain: str = "domain_A",
    target_domains: List[str] = None,
    dataset_root: str = None,
    results_base_dir: str = "./results",
    logger: logging.Logger = None
) -> Dict[str, Any]:
    """ë‹¨ì¼ DRAEM ì‹¤í—˜ ìˆ˜í–‰.
    
    Args:
        condition: ì‹¤í—˜ ì¡°ê±´ ë”•ì…”ë„ˆë¦¬
        source_domain: ì†ŒìŠ¤ ë„ë©”ì¸
        target_domains: íƒ€ê²Ÿ ë„ë©”ì¸ ë¦¬ìŠ¤íŠ¸
        dataset_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
        results_base_dir: ê²°ê³¼ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ
        logger: ë¡œê±° ê°ì²´
        
    Returns:
        Dict[str, Any]: ì‹¤í—˜ ê²°ê³¼
    """
    if target_domains is None:
        target_domains = ["domain_B", "domain_C", "domain_D"]
    
    experiment_name = condition["name"]
    config = condition["config"]
    
    print(f"\n{'='*80}")
    print(f"ğŸ§ª DRAEM ì‹¤í—˜ ì‹œì‘: {experiment_name}")
    print(f"{'='*80}")
    
    if logger:
        logger.info(f"ğŸ§ª DRAEM ì‹¤í—˜ ì‹œì‘: {experiment_name}")
        logger.info(f"ì‹¤í—˜ ì„¤ì •: {config}")
    
    try:
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        cleanup_gpu_memory()
        
        # ì‹¤í—˜ë³„ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„± (DraemSevNetê³¼ ë™ì¼í•œ êµ¬ì¡°)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        experiment_folder = f"{experiment_name}_{timestamp}"
        # DraemSevNetê³¼ ë™ì¼í•œ êµ¬ì¡°ë¡œ ìƒì„±
        experiment_dir = Path(results_base_dir) / "MultiDomainHDMAP" / "draem" / experiment_folder
        experiment_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“ ì‹¤í—˜ ë””ë ‰í† ë¦¬: {experiment_dir}")
        if logger:
            logger.info(f"ğŸ“ ì‹¤í—˜ ë””ë ‰í† ë¦¬: {experiment_dir}")
        
        # DataModule ìƒì„±
        datamodule = create_multi_domain_datamodule(
            datamodule_class=MultiDomainHDMAPDataModule,
            source_domain=source_domain,
            target_domains=target_domains,
            batch_size=config["batch_size"],
            image_size=config["image_size"],
            dataset_root=dataset_root
        )
        
        # ëª¨ë¸ í›ˆë ¨
        model, engine, best_checkpoint = train_draem_model_multi_domain(
            datamodule=datamodule,
            config=config,
            results_base_dir=str(experiment_dir),
            experiment_name=experiment_name,
            logger=logger or logging.getLogger(__name__)
        )
        
        # í›ˆë ¨ ì •ë³´ ì¶”ì¶œ
        training_info = extract_training_info(engine)
        
        # ì‹¤ì œ Anomalib ê²°ê³¼ ê²½ë¡œ ì°¾ê¸° (DraemSevNetê³¼ ë™ì¼í•œ ë¡œì§)
        try:
            # 1. TensorBoardLogger ê²½ë¡œ í™•ì¸
            trainer_log_dir = None
            if hasattr(engine.trainer, 'logger') and hasattr(engine.trainer.logger, 'log_dir'):
                trainer_log_dir = Path(engine.trainer.logger.log_dir)
                print(f"   ğŸ“‚ Trainer log_dir: {trainer_log_dir}")
            
            # 2. ì‹¤ì œ Anomalib ì´ë¯¸ì§€ ê²½ë¡œ íƒìƒ‰
            anomalib_image_paths = []
            base_search_path = Path(str(experiment_dir))
            
            # DRAEM ì´ë¯¸ì§€ ê²½ë¡œ íŒ¨í„´ ê²€ìƒ‰ (ì‹¤ì œ êµ¬ì¡°ì— ë§ì¶¤)
            patterns = [
                "**/Draem/MultiDomainHDMAPDataModule/**/images",  # ì›ë˜ ì˜ˆìƒ íŒ¨í„´
                "**/Draem/latest/images",                        # ì‹¤ì œ ìƒì„±ëœ íŒ¨í„´
                "**/Draem/**/images",                           # ë” ë„“ì€ íŒ¨í„´
                "**/images"                                     # ë§ˆì§€ë§‰ fallback
            ]
            for pattern in patterns:
                found_paths = list(base_search_path.glob(pattern))
                anomalib_image_paths.extend(found_paths)
            
            # ì¤‘ë³µ ì œê±°
            anomalib_image_paths = list(set(anomalib_image_paths))
            print(f"   ğŸ” ë°œê²¬ëœ ì´ë¯¸ì§€ ê²½ë¡œë“¤: {[str(p) for p in anomalib_image_paths]}")
            
            # ê°€ì¥ ìµœì‹  ì´ë¯¸ì§€ ê²½ë¡œ ì„ íƒ
            if anomalib_image_paths:
                latest_image_path = max(anomalib_image_paths, key=lambda p: p.stat().st_mtime if p.exists() else 0)
                anomalib_results_path = latest_image_path.parent  # images í´ë”ì˜ ë¶€ëª¨
                print(f"   âœ… ì‹¤ì œ Anomalib ê²°ê³¼ ê²½ë¡œ: {anomalib_results_path}")
                actual_results_dir = str(anomalib_results_path)
            else:
                print(f"   âš ï¸ Warning: ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
            # ì‹œê°í™” í´ë”ëŠ” TensorBoardLogger ê²½ë¡œì— ìƒì„±
            if trainer_log_dir:
                latest_version_path = trainer_log_dir
            else:
                latest_version_path = Path(str(experiment_dir))
                
        except Exception as e:
            print(f"   âš ï¸ Warning: ì‹¤ì œ ì´ë¯¸ì§€ ê²½ë¡œ ì°¾ê¸° ì‹¤íŒ¨: {e}")
            latest_version_path = Path(str(experiment_dir))
        
        # ì‹œê°í™” í´ë” ìƒì„± (ì‹¤ì œ ê²°ê³¼ ê²½ë¡œ ì‚¬ìš©)
        viz_path = create_experiment_visualization(
            experiment_name=experiment_name,
            model_type="DRAEM",
            results_base_dir=str(latest_version_path),  # TensorBoard ë¡œê·¸ ê²½ë¡œ ì‚¬ìš©
            source_domain=source_domain,
            target_domains=target_domains
        )
        
        # Source Domain í‰ê°€
        print(f"\nğŸ“Š Source Domain í‰ê°€ ì‹œì‘")
        if logger:
            logger.info("ğŸ“Š Source Domain í‰ê°€ ì‹œì‘")
        
        engine_for_eval = Engine(default_root_dir=str(latest_version_path))
        source_results = evaluate_source_domain(
            model=model,
            engine=engine_for_eval,
            datamodule=datamodule,
            checkpoint_path=best_checkpoint
        )
        
        # Source Domain ê²°ê³¼ ì •ë¦¬
        organize_source_domain_results(
            sevnet_viz_path=viz_path,
            results_base_dir=str(latest_version_path),
            source_domain=source_domain
        )
        
        # Target Domains í‰ê°€
        print(f"\nğŸ¯ Target Domains í‰ê°€ ì‹œì‘")
        if logger:
            logger.info("ğŸ¯ Target Domains í‰ê°€ ì‹œì‘")
        
        target_results = evaluate_target_domains(
            model=model,
            engine=engine_for_eval,
            datamodule=datamodule,
            checkpoint_path=best_checkpoint,
            results_base_dir=str(latest_version_path),
            current_version_path=str(latest_version_path)
        )
        
        # ê²°ê³¼ ë¶„ì„
        analysis = analyze_draem_results(
            source_results=source_results,
            target_results=target_results,
            training_info=training_info,
            condition=condition,
            logger=logger or logging.getLogger(__name__)
        )
        
        # ì‹¤í—˜ ê²°ê³¼ ì •ë¦¬ (DraemSevNetê³¼ ë™ì¼í•œ êµ¬ì¡°)
        experiment_result = {
            "condition": condition,
            "experiment_name": experiment_name, 
            "source_results": source_results,
            "target_results": target_results,
            "best_checkpoint": best_checkpoint,
            "training_info": training_info,
            "status": "success",
            "experiment_path": str(latest_version_path),  # ì‹¤ì œ ê²°ê³¼ ê²½ë¡œ ì‚¬ìš©
            "avg_target_auroc": analysis["avg_target_auroc"]
        }
        
        # DraemSevNetì²˜ëŸ¼ ê° ì‹¤í—˜ì˜ tensorboard_logs í´ë”ì— JSON ê²°ê³¼ ì €ì¥
        result_filename = f"result_{condition['name']}_{timestamp}.json"
        result_path = latest_version_path / result_filename
        
        try:
            with open(result_path, 'w', encoding='utf-8') as f:
                json.dump(experiment_result, f, indent=2, ensure_ascii=False)
            print(f"ğŸ“„ ì‹¤í—˜ ê²°ê³¼ JSON ì €ì¥: {result_path}")
            if logger:
                logger.info(f"ğŸ“„ ì‹¤í—˜ ê²°ê³¼ JSON ì €ì¥: {result_path}")
        except Exception as e:
            print(f"âš ï¸  JSON ì €ì¥ ì‹¤íŒ¨: {e}")
            if logger:
                logger.warning(f"âš ï¸  JSON ì €ì¥ ì‹¤íŒ¨: {e}")
        
        print(f"\nâœ… ì‹¤í—˜ ì™„ë£Œ: {experiment_name}")
        if logger:
            logger.info(f"âœ… ì‹¤í—˜ ì™„ë£Œ: {experiment_name}")
        
        return experiment_result
        
    except Exception as e:
        error_msg = f"ì‹¤í—˜ ì‹¤íŒ¨: {e}"
        print(f"\nâŒ {error_msg}")
        if logger:
            logger.error(f"âŒ {error_msg}")
        
        return {
            "status": "failed",
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "experiment_name": experiment_name,
            "condition": condition,
            "error": str(e)
        }


def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì‹¤í—˜ ì„¤ì • ë° ì‹¤í–‰."""
    parser = argparse.ArgumentParser(description="HDMAP ë‹¤ì¤‘ ë„ë©”ì¸ DRAEM ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--experiment_name", type=str, help="ê°œë³„ ì‹¤í—˜ ì´ë¦„")
    parser.add_argument("--max_epochs", type=int, default=50, help="ìµœëŒ€ ì—í¬í¬ ìˆ˜")
    parser.add_argument("--batch_size", type=int, default=16, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--learning_rate", type=float, default=0.0001, help="í•™ìŠµë¥ ")
    parser.add_argument("--early_stopping_patience", type=int, default=10, help="Early stopping patience")
    parser.add_argument("--source_domain", type=str, default="domain_A", help="ì†ŒìŠ¤ ë„ë©”ì¸")
    parser.add_argument("--dataset_root", type=str, help="ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ")
    parser.add_argument("--results_dir", type=str, default="./results", help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--run_all_experiments", action="store_true", help="ëª¨ë“  ì‹¤í—˜ ì¡°ê±´ ì‹¤í–‰")
    parser.add_argument("--log_level", type=str, default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"], help="ë¡œê·¸ ë ˆë²¨")
    
    args = parser.parse_args()
    
    # ê²½ê³  í•„í„°ë§ ì„¤ì •
    setup_warnings_filter()
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„± (results_dir ë‚´ë¶€ì—)
    results_dir = Path(args.results_dir)
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # ë¡œê±° ì„¤ì • (DraemSevNetê³¼ ë™ì¼í•˜ê²Œ ê³ ì •ëœ ë¡œê·¸ íŒŒì¼ëª… ì‚¬ìš©)
    import re
    # results_dirì—ì„œ timestamp ì¶”ì¶œ (ì˜ˆ: results/draem/20250817_120156)
    dir_parts = str(results_dir).split('/')
    run_timestamp = None
    for part in dir_parts:
        if re.match(r'\d{8}_\d{6}', part):  # 20250817_120156 íŒ¨í„´
            run_timestamp = part
            break
    
    if not run_timestamp:
        # ì§ì ‘ ì‹¤í–‰ëœ ê²½ìš°: ìƒˆë¡œìš´ timestamp ìƒì„±
        run_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    log_file = results_dir / f"draem_experiment_{run_timestamp}.log"
    logger = setup_experiment_logging(str(log_file), "draem_experiment")
    logger.setLevel(getattr(logging, args.log_level))
    
    print(f"\nğŸš€ HDMAP ë‹¤ì¤‘ ë„ë©”ì¸ DRAEM ì‹¤í—˜ ì‹œì‘")
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ ë¡œê·¸ íŒŒì¼: {log_file}")
    
    logger.info("ğŸš€ HDMAP ë‹¤ì¤‘ ë„ë©”ì¸ DRAEM ì‹¤í—˜ ì‹œì‘")
    logger.info(f"ëª…ë ¹í–‰ ì¸ìˆ˜: {vars(args)}")
    
    all_results = []
    
    try:
        if args.run_all_experiments:
            # ëª¨ë“  ì‹¤í—˜ ì¡°ê±´ ì‹¤í–‰
            print(f"\nğŸ“‹ ì „ì²´ ì‹¤í—˜ ì‹¤í–‰ - {len(EXPERIMENT_CONDITIONS)}ê°œ ì¡°ê±´")
            logger.info(f"ğŸ“‹ ì „ì²´ ì‹¤í—˜ ì‹¤í–‰ - {len(EXPERIMENT_CONDITIONS)}ê°œ ì¡°ê±´")
            
            for i, condition in enumerate(EXPERIMENT_CONDITIONS, 1):
                print(f"\n[{i}/{len(EXPERIMENT_CONDITIONS)}] {condition['name']} ì‹œì‘")
                logger.info(f"[{i}/{len(EXPERIMENT_CONDITIONS)}] {condition['name']} ì‹œì‘")
                
                result = run_single_draem_experiment(
                    condition=condition,
                    source_domain=args.source_domain,
                    dataset_root=args.dataset_root,
                    results_base_dir=args.results_dir,
                    logger=logger
                )
                
                all_results.append(result)
                
                print(f"âœ… [{i}/{len(EXPERIMENT_CONDITIONS)}] {condition['name']} ì™„ë£Œ")
                logger.info(f"âœ… [{i}/{len(EXPERIMENT_CONDITIONS)}] {condition['name']} ì™„ë£Œ")
        else:
            # ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰
            if args.experiment_name:
                # ê¸°ì¡´ ì¡°ê±´ì—ì„œ ì°¾ê¸°
                condition = None
                for c in EXPERIMENT_CONDITIONS:
                    if c["name"] == args.experiment_name:
                        condition = c
                        break
            
            if not condition:
                # ì‚¬ìš©ì ì •ì˜ ì¡°ê±´ ìƒì„±
                condition = {
                    "name": args.experiment_name or f"custom_draem_{timestamp}",
                    "description": "ì‚¬ìš©ì ì •ì˜ DRAEM ì‹¤í—˜",
                    "config": {
                        "max_epochs": args.max_epochs,
                        "early_stopping_patience": args.early_stopping_patience,
                        "learning_rate": args.learning_rate,
                        "batch_size": args.batch_size,
                        "image_size": "224x224"
                    }
                }
            
            print(f"\nğŸ¯ ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰: {condition['name']}")
            logger.info(f"ğŸ¯ ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰: {condition['name']}")
            
            result = run_single_draem_experiment(
                condition=condition,
                source_domain=args.source_domain,
                dataset_root=args.dataset_root,
                results_base_dir=args.results_dir,
                logger=logger
            )
            
            all_results.append(result)
        
        # ë‹¤ì¤‘ ì‹¤í—˜ ë¶„ì„ (2ê°œ ì´ìƒì¸ ê²½ìš°)
        if len(all_results) > 1:
            analyze_multi_experiment_results(all_results, args.source_domain)
        
        print(f"\nğŸ‰ ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {args.results_dir}")
        print(f"ğŸ“ ë¡œê·¸ íŒŒì¼: {log_file}")
        
        logger.info("ğŸ‰ ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!")
        logger.info(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {args.results_dir}")
        
    except Exception as e:
        error_msg = f"ì‹¤í—˜ ë„ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        print(f"\nâŒ {error_msg}")
        logger.error(f"âŒ {error_msg}")
        raise


if __name__ == "__main__":
    main()
