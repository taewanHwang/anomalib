#!/usr/bin/env python3
"""
HDMAP ë°ì´í„°ì…‹ì˜ Scaling ì „/í›„ í”½ì…€ ê°’ ë¶„í¬ ì‹œê°í™”

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ ìƒì„±í•©ë‹ˆë‹¤:
1. Figure 1: Unscaled range - ì›ë³¸ TIFF ì´ë¯¸ì§€ì˜ í”½ì…€ ê°’ ë¶„í¬
2. Figure 2: Scaled range - MinMax scaling í›„ì˜ í”½ì…€ ê°’ ë¶„í¬

ì‹¤í–‰ ë°©ë²•:
    python examples/hdmap/paper/visualize_data_distribution.py

ì¶œë ¥:
    - examples/hdmap/paper/figure1_unscaled_distribution.png
    - examples/hdmap/paper/figure2_scaled_distribution.png
    - examples/hdmap/paper/distribution_statistics.txt
"""

import sys
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import tifffile
import scipy.io
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
# __file__ = .../anomalib/examples/hdmap/paper/visualize_data_distribution.py
# parents[0] = .../anomalib/examples/hdmap/paper
# parents[1] = .../anomalib/examples/hdmap
# parents[2] = .../anomalib/examples
# parents[3] = .../anomalib (í”„ë¡œì íŠ¸ ë£¨íŠ¸)
project_root = Path(__file__).parents[3]
sys.path.insert(0, str(project_root))

# Matplotlib í°íŠ¸ ì„¤ì • - Computer Modern (LaTeX ê¸°ë³¸ í°íŠ¸)
plt.rcParams['font.family'] = 'serif'
plt.rcParams['font.serif'] = ['cmr10', 'DejaVu Serif']
plt.rcParams['mathtext.fontset'] = 'cm'  # Computer Modern for math text
plt.rcParams['axes.formatter.use_mathtext'] = True
plt.rcParams['font.size'] = 12

# =============================================================================
# ì„¤ì •
# =============================================================================
# ë°ì´í„°ì…‹ ì„ íƒ (1000 ë˜ëŠ” 100000)
N_SAMPLES = 100000  # 1000 ë˜ëŠ” 100000

# ìƒ˜í”Œë§ ì„¤ì • (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¼ë¶€ ìƒ˜í”Œë§Œ ì‚¬ìš©)
MAX_SAMPLES_PER_CATEGORY = None  # Noneì´ë©´ ì „ì²´ ì‚¬ìš©, ìˆ«ì ì§€ì •ì‹œ í•´ë‹¹ ê°œìˆ˜ë§Œ ìƒ˜í”Œë§ (í…ŒìŠ¤íŠ¸: 100)

# ë°ì´í„°ì…‹ ê²½ë¡œ
DATASET_ROOT = project_root / "datasets" / "HDMAP"
SCALED_DATASET = DATASET_ROOT / f"{N_SAMPLES}_tiff_minmax"

# ì›ë³¸ mat íŒŒì¼ ê²½ë¡œ (unscaled í†µê³„ ê³„ì‚°ìš©)
RAW_DATA_PATH = project_root / "datasets" / "raw" / "KRISS_share_nipa2023"

# ì¶œë ¥ ê²½ë¡œ
OUTPUT_DIR = project_root / "examples" / "hdmap" / "paper"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# DOMAIN_CONFIG (prepare_hdmap_dataset.pyì™€ ë™ì¼)
# IEEE/Nature journal style colors
DOMAIN_CONFIG = {
    'A': {
        'user_min': 0.0,
        'user_max': 0.324670,
        'color': '#1f77b4'  # Blue (IEEE style)
    },
    'B': {
        'user_min': 0.0,
        'user_max': 1.324418,
        'color': '#d62728'  # Red (IEEE style)
    },
    'C': {
        'user_min': 0.0,
        'user_max': 0.087341,
        'color': '#2ca02c'  # Green (IEEE style)
    },
    'D': {
        'user_min': 0.0,
        'user_max': 0.418999,
        'color': '#ff7f0e'  # Orange (IEEE style)
    },
}

# ì¹´í…Œê³ ë¦¬ ì •ì˜
CATEGORIES = [
    ('train', 'good', 'Train (Normal)'),
    ('test', 'good', 'Test (Normal)'),
    ('test', 'fault', 'Test (Fault)')
]

# =============================================================================
# ë°ì´í„° ë¡œë“œ ë° í†µê³„ ê³„ì‚°
# =============================================================================
def generate_mat_paths():
    """ë„ë©”ì¸ êµ¬ì„± ì •ë³´ë¡œë¶€í„° mat íŒŒì¼ ê²½ë¡œ ìƒì„±"""
    paths = {}

    for domain, config in DOMAIN_CONFIG.items():
        sensor_path = config.get('sensor', DOMAIN_CONFIG[domain].get('sensor'))
        data_type = config.get('data_type', DOMAIN_CONFIG[domain].get('data_type'))

        # DOMAIN_CONFIGì—ì„œ sensor, data_type ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        # prepare_hdmap_dataset.pyì—ì„œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼í•œ êµ¬ì¡°
        if domain == 'A':
            sensor_path = 'Class1/1'
            data_type = '3_TSA_DIF'
        elif domain == 'B':
            sensor_path = 'Class1/1'
            data_type = '1_TSA_DIF'
        elif domain == 'C':
            sensor_path = 'Class3/1'
            data_type = '3_TSA_DIF'
        elif domain == 'D':
            sensor_path = 'Class3/1'
            data_type = '1_TSA_DIF'

        # ê¸°ë³¸ ê²½ë¡œ êµ¬ì„±
        normal_base = RAW_DATA_PATH / "Normal" / "Normal2_LSSm0.3_HSS0" / sensor_path / "HDMap_train_test"
        fault_base = RAW_DATA_PATH / "Planet_fault_ring" / "1.42_LSSm0.3_HSS0" / sensor_path / "HDMap_train_test"

        paths[domain] = {
            'train_good': normal_base / f"{data_type}_train.mat",
            'test_good': normal_base / f"{data_type}_test.mat",
            'test_fault': fault_base / f"{data_type}_test.mat"
        }

    return paths

def load_mat_statistics(domain, split, label, max_samples=None):
    """
    ì›ë³¸ mat íŒŒì¼ì—ì„œ ì§ì ‘ í†µê³„ ê³„ì‚° (unscaled)

    Args:
        domain: 'A', 'B', 'C', 'D'
        split: 'train' ë˜ëŠ” 'test'
        label: 'good' ë˜ëŠ” 'fault'
        max_samples: ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (Noneì´ë©´ ì „ì²´)

    Returns:
        dict: {'min', 'mean', 'max', 'std', 'median', 'q25', 'q75', 'all_values'}
    """
    mat_paths = generate_mat_paths()
    category_key = f"{split}_{label}"
    mat_path = mat_paths[domain][category_key]

    if not mat_path.exists():
        print(f"  âš ï¸ Warning: {mat_path} does not exist")
        return None

    try:
        # mat íŒŒì¼ ë¡œë“œ
        print(f"  Loading {mat_path.name}...")
        mat_data = scipy.io.loadmat(str(mat_path))
        image_data = mat_data['Xdata']

        # ìƒ˜í”Œ ìˆ˜ ê²°ì •
        actual_samples = image_data.shape[3] if len(image_data.shape) > 3 else 1
        num_samples = min(max_samples, actual_samples) if max_samples else actual_samples

        # ëª¨ë“  í”½ì…€ ê°’ ìˆ˜ì§‘
        all_pixels = []
        for i in tqdm(range(num_samples), desc=f"  Processing {domain}-{split}-{label}", leave=False):
            img = image_data[:, :, 0, i]
            all_pixels.append(img.flatten())

        all_pixels = np.concatenate(all_pixels)

        # í†µê³„ ê³„ì‚°
        stats = {
            'min': float(np.min(all_pixels)),
            'mean': float(np.mean(all_pixels)),
            'max': float(np.max(all_pixels)),
            'std': float(np.std(all_pixels)),
            'median': float(np.median(all_pixels)),
            'q25': float(np.percentile(all_pixels, 25)),
            'q75': float(np.percentile(all_pixels, 75)),
            'all_values': all_pixels,  # Violin plotìš©
            'n_images': num_samples,
            'n_pixels': len(all_pixels)
        }

        return stats

    except Exception as e:
        print(f"  âŒ Error loading {mat_path}: {e}")
        return None

def load_tiff_statistics(domain, split, label, dataset_path, max_images=None):
    """
    íŠ¹ì • ë„ë©”ì¸/ì¹´í…Œê³ ë¦¬ì˜ TIFF ì´ë¯¸ì§€ë“¤ì„ ë¡œë“œí•˜ê³  í†µê³„ ê³„ì‚°

    Args:
        domain: 'A', 'B', 'C', 'D'
        split: 'train' ë˜ëŠ” 'test'
        label: 'good' ë˜ëŠ” 'fault'
        dataset_path: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
        max_images: ìµœëŒ€ ë¡œë“œ ì´ë¯¸ì§€ ìˆ˜ (Noneì´ë©´ ì „ì²´)

    Returns:
        dict: {'min', 'mean', 'max', 'std', 'median', 'q25', 'q75', 'all_values'}
    """
    data_path = dataset_path / f"domain_{domain}" / split / label

    if not data_path.exists():
        print(f"  âš ï¸ Warning: {data_path} does not exist")
        return None

    # TIFF íŒŒì¼ ëª©ë¡
    tiff_files = sorted(data_path.glob("*.tiff")) + sorted(data_path.glob("*.tif"))

    if not tiff_files:
        print(f"  âš ï¸ Warning: No TIFF files found in {data_path}")
        return None

    # ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ ì œí•œ
    if max_images is not None:
        tiff_files = tiff_files[:max_images]

    # ëª¨ë“  í”½ì…€ ê°’ ìˆ˜ì§‘
    all_pixels = []
    for tiff_file in tqdm(tiff_files, desc=f"  Loading {domain}-{split}-{label}", leave=False):
        try:
            img = tifffile.imread(tiff_file)
            all_pixels.append(img.flatten())
        except Exception as e:
            print(f"    Error loading {tiff_file}: {e}")
            continue

    if not all_pixels:
        return None

    # í†µê³„ ê³„ì‚°
    all_pixels = np.concatenate(all_pixels)

    stats = {
        'min': float(np.min(all_pixels)),
        'mean': float(np.mean(all_pixels)),
        'max': float(np.max(all_pixels)),
        'std': float(np.std(all_pixels)),
        'median': float(np.median(all_pixels)),
        'q25': float(np.percentile(all_pixels, 25)),
        'q75': float(np.percentile(all_pixels, 75)),
        'all_values': all_pixels,  # Violin plotìš©
        'n_images': len(tiff_files),
        'n_pixels': len(all_pixels)
    }

    return stats

def collect_unscaled_statistics(domains=['A', 'B', 'C', 'D'], max_samples=None):
    """
    ì›ë³¸ mat íŒŒì¼ì—ì„œ unscaled í†µê³„ ìˆ˜ì§‘

    Returns:
        dict: {domain: {category_key: stats_dict}}
    """
    print(f"ğŸ“Š Unscaled í†µê³„ ìˆ˜ì§‘ ì¤‘ (ì›ë³¸ mat íŒŒì¼)")

    all_stats = {}

    for domain in domains:
        print(f"\nğŸ”¹ Domain {domain}")
        domain_stats = {}

        for split, label, name in CATEGORIES:
            category_key = f"{split}_{label}"
            stats = load_mat_statistics(domain, split, label, max_samples)

            if stats:
                domain_stats[category_key] = stats
                print(f"  âœ… {name}: {stats['n_images']} images, "
                      f"range=[{stats['min']:.6f}, {stats['max']:.6f}], "
                      f"mean={stats['mean']:.6f}")
            else:
                domain_stats[category_key] = None

        all_stats[domain] = domain_stats

    return all_stats

def collect_scaled_statistics(dataset_path, domains=['A', 'B', 'C', 'D'], max_images=None):
    """
    TIFF íŒŒì¼ì—ì„œ scaled í†µê³„ ìˆ˜ì§‘

    Returns:
        dict: {domain: {category_key: stats_dict}}
    """
    print(f"ğŸ“Š Scaled í†µê³„ ìˆ˜ì§‘ ì¤‘: {dataset_path.name}")

    all_stats = {}

    for domain in domains:
        print(f"\nğŸ”¹ Domain {domain}")
        domain_stats = {}

        for split, label, name in CATEGORIES:
            category_key = f"{split}_{label}"
            stats = load_tiff_statistics(domain, split, label, dataset_path, max_images)

            if stats:
                domain_stats[category_key] = stats
                print(f"  âœ… {name}: {stats['n_images']} images, "
                      f"range=[{stats['min']:.6f}, {stats['max']:.6f}], "
                      f"mean={stats['mean']:.6f}")
            else:
                domain_stats[category_key] = None

        all_stats[domain] = domain_stats

    return all_stats

# =============================================================================
# ì‹œê°í™” í•¨ìˆ˜
# =============================================================================
def plot_distribution_bars(stats_data, title, xlabel, output_path, include_violin=False):
    """
    Horizontal bar chartë¡œ ë¶„í¬ ì‹œê°í™” (ì°¸ê³  ì´ë¯¸ì§€ì™€ ë™ì¼í•œ ìŠ¤íƒ€ì¼)

    Args:
        stats_data: {domain: {category: stats}} êµ¬ì¡°
        title: ê·¸ë˜í”„ ì œëª©
        xlabel: xì¶• ë ˆì´ë¸”
        output_path: ì €ì¥ ê²½ë¡œ
        include_violin: Violin plot í¬í•¨ ì—¬ë¶€
    """
    # 12ê°œ ì¹´í…Œê³ ë¦¬ ìƒì„± (ì—­ìˆœìœ¼ë¡œ ë°°ì¹˜ - ê·¸ë¦¼ì—ì„œ Aê°€ ìœ„ì— ì˜¤ë„ë¡)
    categories = []
    colors = []
    mins = []
    maxs = []
    means = []

    domains = ['D', 'C', 'B', 'A']  # ì—­ìˆœ

    for domain in domains:
        for split, label, name in reversed(CATEGORIES):  # ì—­ìˆœ
            category_key = f"{split}_{label}"
            category_label = f"{domain}-{name}"

            stats = stats_data.get(domain, {}).get(category_key)

            if stats:
                categories.append(category_label)
                colors.append(DOMAIN_CONFIG[domain]['color'])
                mins.append(stats['min'])
                maxs.append(stats['max'])
                means.append(stats['mean'])
            else:
                # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€
                categories.append(category_label)
                colors.append(DOMAIN_CONFIG[domain]['color'])
                mins.append(0)
                maxs.append(0)
                means.append(0)

    # ê·¸ë˜í”„ ìƒì„±
    fig, ax = plt.subplots(figsize=(14, 10))

    y_pos = np.arange(len(categories))

    # Horizontal bar (min ~ max ë²”ìœ„)
    for i, (cat, color, min_val, max_val, mean_val) in enumerate(zip(categories, colors, mins, maxs, means)):
        # Bar ê·¸ë¦¬ê¸° (minì—ì„œ maxê¹Œì§€)
        width = max_val - min_val
        ax.barh(i, width, left=min_val, height=0.6, color=color, alpha=0.7, edgecolor='black', linewidth=0.5)

        # Mean marker (ì›)
        ax.plot(mean_val, i, 'o', color='black', markersize=8, markeredgecolor='black', markeredgewidth=1.5, zorder=3)

    # Yì¶• ì„¤ì •
    ax.set_yticks(y_pos)
    ax.set_yticklabels(categories, fontsize=12)
    ax.set_ylim(-0.5, len(categories) - 0.5)

    # Xì¶• ì„¤ì •
    ax.set_xlabel(xlabel, fontsize=14, fontweight='bold')
    ax.grid(axis='x', alpha=0.3, linestyle='--')

    # ì œëª©
    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)

    # ë²”ë¡€ (ë„ë©”ì¸ë³„)
    from matplotlib.patches import Patch
    legend_elements = [Patch(facecolor=DOMAIN_CONFIG[d]['color'], edgecolor='black', label=f'Domain {d}')
                      for d in ['A', 'B', 'C', 'D']]
    ax.legend(handles=legend_elements, loc='lower right', fontsize=12, framealpha=0.9)

    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"âœ… Saved: {output_path}")

def plot_violin_distribution(stats_data, title, xlabel, output_path):
    """
    Violin plotìœ¼ë¡œ ìƒì„¸ ë¶„í¬ ì‹œê°í™” (ì„ íƒì )

    Args:
        stats_data: {domain: {category: stats}} êµ¬ì¡°
        title: ê·¸ë˜í”„ ì œëª©
        xlabel: xì¶• ë ˆì´ë¸”
        output_path: ì €ì¥ ê²½ë¡œ
    """
    # ì¹´í…Œê³ ë¦¬ ë° ë°ì´í„° ì¤€ë¹„
    categories = []
    all_data = []
    colors = []
    original_stats = []  # ì›ë³¸ min/max ì €ì¥

    domains = ['D', 'C', 'B', 'A']  # ì—­ìˆœ

    # Set random seed for reproducibility
    np.random.seed(42)

    for domain in domains:
        for split, label, name in reversed(CATEGORIES):
            category_key = f"{split}_{label}"
            category_label = f"{domain}-{name}"

            stats = stats_data.get(domain, {}).get(category_key)

            if stats and 'all_values' in stats and len(stats['all_values']) > 0:
                # ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ì€ ë°ì´í„° í¬ì¸íŠ¸ ë°©ì§€) - deterministic sampling
                n_samples = min(50000, len(stats['all_values']))  # Increased from 10000 to 50000
                sampled_values = np.random.choice(stats['all_values'],
                                                  n_samples,
                                                  replace=False)
                categories.append(category_label)
                all_data.append(sampled_values)
                colors.append(DOMAIN_CONFIG[domain]['color'])

                # ì›ë³¸ í†µê³„ ì €ì¥ (ìƒ˜í”Œë§ê³¼ ê´€ê³„ì—†ì´ ì „ì²´ ë°ì´í„°ì˜ min/max)
                original_stats.append({
                    'min': stats['min'],
                    'max': stats['max']
                })

                # Debug: Print statistics for train data
                if 'train' in split and 'good' in label:
                    print(f"  Debug {category_label}: sampled_min={np.min(sampled_values):.4f}, "
                          f"sampled_max={np.max(sampled_values):.4f}, "
                          f"original_min={stats['min']:.4f}, original_max={stats['max']:.4f}")

    # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê·¸ë˜í”„ ìƒì„± ê±´ë„ˆë›°ê¸°
    if not all_data:
        print(f"  âš ï¸ Warning: No data available for violin plot. Skipping {output_path.name}")
        return

    # Violin plot ìƒì„±
    fig, ax = plt.subplots(figsize=(14, 10))

    positions = np.arange(len(categories))
    parts = ax.violinplot(all_data, positions=positions, vert=False, widths=0.7,
                          showmeans=True, showmedians=False, showextrema=False)

    # Violin ìƒ‰ìƒ ì„¤ì •
    for i, pc in enumerate(parts['bodies']):
        pc.set_facecolor(colors[i])
        pc.set_alpha(0.7)
        pc.set_edgecolor('black')
        pc.set_linewidth(0.5)

    # Mean ë¼ì¸ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ ë³€ê²½
    if 'cmeans' in parts:
        parts['cmeans'].set_edgecolor('black')
        parts['cmeans'].set_linewidth(1.5)
    if 'cbars' in parts:
        parts['cbars'].set_edgecolor('black')
        parts['cbars'].set_linewidth(1.5)
    if 'cmaxes' in parts:
        parts['cmaxes'].set_edgecolor('black')
        parts['cmaxes'].set_linewidth(1.5)
    if 'cmins' in parts:
        parts['cmins'].set_edgecolor('black')
        parts['cmins'].set_linewidth(1.5)

    # Min/Max í‘œì‹œ ì¶”ê°€ (ì›ë³¸ í†µê³„ ì‚¬ìš©)
    for i, (data, pos) in enumerate(zip(all_data, positions)):
        # ì›ë³¸ ë°ì´í„°ì…‹ì˜ ì‹¤ì œ í†µê³„ê°’ ì‚¬ìš© (ìƒ˜í”Œë§ëœ ë°ì´í„°ê°€ ì•„ë‹Œ)
        min_val = original_stats[i]['min']
        max_val = original_stats[i]['max']

        # Whiskers (min-max) - ì–‡ì€ ìˆ˜í‰ì„ 
        ax.plot([min_val, max_val], [pos, pos], color='black', linewidth=1.0, alpha=0.8, zorder=3)

        # Min/Max markers - ì‘ì€ ì„¸ë¡œì„ 
        ax.plot([min_val, min_val], [pos-0.05, pos+0.05], color='black', linewidth=1.5, alpha=0.8, zorder=3)
        ax.plot([max_val, max_val], [pos-0.05, pos+0.05], color='black', linewidth=1.5, alpha=0.8, zorder=3)

    # Yì¶• ì„¤ì • (í°íŠ¸ 150%)
    ax.set_yticks(positions)
    ax.set_yticklabels(categories, fontsize=18)  # 12 * 1.5 = 18
    ax.set_ylim(-0.5, len(categories) - 0.5)
    ax.tick_params(axis='x', labelsize=18)  # Xì¶• ëˆˆê¸ˆ í°íŠ¸ë„ 150%

    # Xì¶• ì„¤ì • (í°íŠ¸ 150%)
    ax.set_xlabel(xlabel, fontsize=21, fontweight='bold')  # 14 * 1.5 = 21
    ax.grid(axis='x', alpha=0.3, linestyle='--', linewidth=0.5, color='gray')

    # ì œëª© (í°íŠ¸ 150%)
    ax.set_title(title, fontsize=24, fontweight='bold', pad=20)  # 16 * 1.5 = 24

    # ë²”ë¡€ (í°íŠ¸ 150%)
    from matplotlib.patches import Patch
    legend_elements = [Patch(facecolor=DOMAIN_CONFIG[d]['color'], edgecolor='black', label=f'Domain {d}')
                      for d in ['A', 'B', 'C', 'D']]
    ax.legend(handles=legend_elements, loc='lower right', fontsize=18, framealpha=0.9)  # 12 * 1.5 = 18

    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"âœ… Saved: {output_path}")

# =============================================================================
# ë©”ì¸ ì‹¤í–‰
# =============================================================================
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("ğŸ“Š HDMAP ë°ì´í„°ì…‹ ë¶„í¬ ì‹œê°í™”")
    print("=" * 80)
    print(f"ë°ì´í„°ì…‹: {N_SAMPLES}ê°œ ìƒ˜í”Œ")
    print(f"Unscaled: ì›ë³¸ mat íŒŒì¼ì—ì„œ ë¡œë“œ")
    print(f"Scaled: {SCALED_DATASET}")
    print("=" * 80)

    # 1. Unscaled í†µê³„ ìˆ˜ì§‘ (ì›ë³¸ mat íŒŒì¼ì—ì„œ)
    print("\n" + "=" * 80)
    print("ğŸ“ˆ Figure 1: Unscaled Distribution (from mat files)")
    print("=" * 80)
    unscaled_stats = collect_unscaled_statistics(max_samples=MAX_SAMPLES_PER_CATEGORY)

    # 2. Scaled í†µê³„ ìˆ˜ì§‘ (TIFF íŒŒì¼ì—ì„œ)
    print("\n" + "=" * 80)
    print("ğŸ“ˆ Figure 2: Scaled Distribution (from TIFF files)")
    print("=" * 80)
    scaled_stats = collect_scaled_statistics(SCALED_DATASET, max_images=MAX_SAMPLES_PER_CATEGORY)

    # 3. Figure 1 ìƒì„± (Unscaled)
    print("\n" + "=" * 80)
    print("ğŸ¨ Generating Figure 1: Unscaled Range")
    print("=" * 80)
    plot_distribution_bars(
        unscaled_stats,
        title="Unscaled range",
        xlabel="Value",
        output_path=OUTPUT_DIR / "figure1_unscaled_distribution.png"
    )

    # 4. Figure 2 ìƒì„± (Scaled)
    print("\n" + "=" * 80)
    print("ğŸ¨ Generating Figure 2: Scaled Range")
    print("=" * 80)
    plot_distribution_bars(
        scaled_stats,
        title="Scaled range",
        xlabel="Scaled Value",
        output_path=OUTPUT_DIR / "figure2_scaled_distribution.png"
    )

    # 5. (ì„ íƒì ) Violin plot ìƒì„±
    print("\n" + "=" * 80)
    print("ğŸ¨ Generating Violin Plots (Optional)")
    print("=" * 80)

    print("Generating unscaled violin plot...")
    plot_violin_distribution(
        unscaled_stats,
        title="Unscaled Data Distribution",
        xlabel="Value",
        output_path=OUTPUT_DIR / "figure1_unscaled_violin.png"
    )

    print("Generating scaled violin plot...")
    plot_violin_distribution(
        scaled_stats,
        title="Scaled Data Distribution",
        xlabel="Scaled Value",
        output_path=OUTPUT_DIR / "figure2_scaled_violin.png"
    )

    # 6. í†µê³„ ë¦¬í¬íŠ¸ ì €ì¥
    print("\n" + "=" * 80)
    print("ğŸ“„ Saving Statistics Report")
    print("=" * 80)

    report_path = OUTPUT_DIR / "distribution_statistics.txt"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("HDMAP ë°ì´í„°ì…‹ ë¶„í¬ í†µê³„ ë¦¬í¬íŠ¸\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"ë°ì´í„°ì…‹: {N_SAMPLES}ê°œ ìƒ˜í”Œ\n")
        f.write(f"Unscaled: ì›ë³¸ mat íŒŒì¼ì—ì„œ ë¡œë“œ\n")
        f.write(f"Scaled: {SCALED_DATASET}\n\n")

        f.write("=" * 80 + "\n")
        f.write("Unscaled Statistics\n")
        f.write("=" * 80 + "\n\n")

        for domain in ['A', 'B', 'C', 'D']:
            f.write(f"\në„ë©”ì¸ {domain} (user_min={DOMAIN_CONFIG[domain]['user_min']}, "
                   f"user_max={DOMAIN_CONFIG[domain]['user_max']})\n")
            f.write("-" * 80 + "\n")

            for split, label, name in CATEGORIES:
                category_key = f"{split}_{label}"
                stats = unscaled_stats.get(domain, {}).get(category_key)

                if stats:
                    f.write(f"  {name}:\n")
                    f.write(f"    ì´ë¯¸ì§€ ìˆ˜: {stats['n_images']}\n")
                    f.write(f"    í”½ì…€ ìˆ˜: {stats['n_pixels']:,}\n")
                    f.write(f"    Min: {stats['min']:.6f}\n")
                    f.write(f"    Max: {stats['max']:.6f}\n")
                    f.write(f"    Mean: {stats['mean']:.6f}\n")
                    f.write(f"    Std: {stats['std']:.6f}\n")
                    f.write(f"    Median: {stats['median']:.6f}\n")
                    f.write(f"    Q25: {stats['q25']:.6f}\n")
                    f.write(f"    Q75: {stats['q75']:.6f}\n\n")

        f.write("\n" + "=" * 80 + "\n")
        f.write("Scaled Statistics\n")
        f.write("=" * 80 + "\n\n")

        for domain in ['A', 'B', 'C', 'D']:
            f.write(f"\në„ë©”ì¸ {domain}\n")
            f.write("-" * 80 + "\n")

            for split, label, name in CATEGORIES:
                category_key = f"{split}_{label}"
                stats = scaled_stats.get(domain, {}).get(category_key)

                if stats:
                    f.write(f"  {name}:\n")
                    f.write(f"    ì´ë¯¸ì§€ ìˆ˜: {stats['n_images']}\n")
                    f.write(f"    í”½ì…€ ìˆ˜: {stats['n_pixels']:,}\n")
                    f.write(f"    Min: {stats['min']:.6f}\n")
                    f.write(f"    Max: {stats['max']:.6f}\n")
                    f.write(f"    Mean: {stats['mean']:.6f}\n")
                    f.write(f"    Std: {stats['std']:.6f}\n")
                    f.write(f"    Median: {stats['median']:.6f}\n")
                    f.write(f"    Q25: {stats['q25']:.6f}\n")
                    f.write(f"    Q75: {stats['q75']:.6f}\n\n")

    print(f"âœ… Statistics report saved: {report_path}")

    # ì™„ë£Œ ë©”ì‹œì§€
    print("\n" + "=" * 80)
    print("âœ… ëª¨ë“  ì‹œê°í™” ì™„ë£Œ!")
    print("=" * 80)
    print(f"\nìƒì„±ëœ íŒŒì¼:")
    print(f"  - {OUTPUT_DIR / 'figure1_unscaled_distribution.png'}")
    print(f"  - {OUTPUT_DIR / 'figure2_scaled_distribution.png'}")
    print(f"  - {OUTPUT_DIR / 'figure1_unscaled_violin.png'} (ì„ íƒì )")
    print(f"  - {OUTPUT_DIR / 'figure2_scaled_violin.png'} (ì„ íƒì )")
    print(f"  - {OUTPUT_DIR / 'distribution_statistics.txt'}")
    print("=" * 80)

if __name__ == "__main__":
    main()
