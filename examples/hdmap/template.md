# ë©€í‹° ë„ë©”ì¸ ë¨¸ì‹ ëŸ¬ë‹ ì‹¤í—˜ í…œí”Œë¦¿

ì´ ë¬¸ì„œëŠ” HDMAP ë°ì´í„°ì…‹ì—ì„œ ë‹¤ì–‘í•œ Anomaly Detection ëª¨ë¸ì„ ìœ„í•œ í‘œì¤€í™”ëœ ì‹¤í—˜ í…œí”Œë¦¿ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ íŒŒì¼ êµ¬ì¡°

ê° ëª¨ë¸ì€ **Python ìŠ¤í¬ë¦½íŠ¸**ì™€ **ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸** í•œ ì„¸íŠ¸ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

```
examples/hdmap/
â”œâ”€â”€ multi_domain_hdmap_{MODEL_NAME}_training.py       # Python ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ multi_domain_hdmap_{MODEL_NAME}_training_run.sh   # Bash ë³‘ë ¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ experiment_utils.py                               # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
â””â”€â”€ template.md                                       # ì´ ë¬¸ì„œ
```

## ğŸ¯ í…œí”Œë¦¿ êµ¬ì¡°

### 1. Python ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ (`multi_domain_hdmap_{MODEL_NAME}_training.py`)

#### 1.1 íŒŒì¼ í—¤ë” ë° Docstring
```python
#!/usr/bin/env python3
"""HDMAP ë‹¤ì¤‘ ë„ë©”ì¸ {MODEL_NAME} ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ ìŠ¤í¬ë¦½íŠ¸.

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” HDMAP ë°ì´í„°ì…‹ì—ì„œ {MODEL_NAME} ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ë‹¤ì¤‘ ë„ë©”ì¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- {MODEL_NAME} ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ìƒ íƒì§€
- ì†ŒìŠ¤ ë„ë©”ì¸(domain_A)ì—ì„œ í›ˆë ¨
- íƒ€ê²Ÿ ë„ë©”ì¸ë“¤(domain_B, C, D)ì—ì„œ í‰ê°€
- ì‹¤í—˜ ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
- ì²´ê³„ì ì¸ ì‹¤í—˜ ì¡°ê±´ ê´€ë¦¬

ì‚¬ìš©ë²•:
    python multi_domain_hdmap_{MODEL_NAME}_training.py --experiment_name my_experiment --max_epochs 50
    python multi_domain_hdmap_{MODEL_NAME}_training.py --run_all_experiments
"""
```

#### 1.2 í•„ìˆ˜ Import êµ¬ì¡°
```python
import argparse
import json
import logging
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# ëª¨ë¸ë³„ íŠ¹í™” import
from anomalib.models.image.{MODEL_NAME} import {ModelClass}
from anomalib.data.datamodules.image.multi_domain_hdmap import MultiDomainHDMAPDataModule
from anomalib.engine import Engine
from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint
from pytorch_lightning.loggers import TensorBoardLogger

# ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ import
from experiment_utils import (
    setup_warnings_filter,
    setup_experiment_logging,
    cleanup_gpu_memory,
    create_multi_domain_datamodule,
    evaluate_source_domain,
    evaluate_target_domains,
    extract_training_info,
    create_experiment_visualization,
    organize_source_domain_results,
    save_experiment_results,
    analyze_multi_experiment_results
)

# ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™”
setup_warnings_filter()
logging.getLogger("anomalib.visualization.image.item_visualizer").setLevel(logging.ERROR)
```

#### 1.3 ì‹¤í—˜ ì¡°ê±´ ì •ì˜ (`EXPERIMENT_CONDITIONS`)
```python
# {MODEL_NAME} ì‹¤í—˜ ì¡°ê±´ë“¤ ì •ì˜
EXPERIMENT_CONDITIONS = [
    {
        "name": "{MODEL_NAME}_baseline",
        "description": "{MODEL_NAME} ê¸°ë³¸ ì„¤ì •",
        "config": {
            "max_epochs": 30,
            "early_stopping_patience": 5,
            "learning_rate": 1e-4,
            "batch_size": 32,
            "image_size": "224x224"
        }
        # ëª¨ë¸ë³„ íŠ¹í™” íŒŒë¼ë¯¸í„° ì¶”ê°€
    },
    # ì¶”ê°€ ì‹¤í—˜ ì¡°ê±´ë“¤...
]
```

#### 1.4 í•µì‹¬ í•¨ìˆ˜ë“¤

##### A. ëª¨ë¸ í›ˆë ¨ í•¨ìˆ˜
```python
def train_{MODEL_NAME}_model_multi_domain(
    datamodule: MultiDomainHDMAPDataModule, 
    config: Dict[str, Any],
    results_base_dir: str,
    experiment_name: str,
    logger: logging.Logger
) -> tuple[{ModelClass}, Engine, str]:
    """
    {MODEL_NAME} ëª¨ë¸ í›ˆë ¨ ìˆ˜í–‰.
    
    Returns:
        tuple: (í›ˆë ¨ëœ ëª¨ë¸, Engine ê°ì²´, ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ)
    """
    # 1. ëª¨ë¸ ì´ˆê¸°í™”
    model = {ModelClass}()
    
    # 2. Early stoppingê³¼ model checkpoint ì„¤ì •
    early_stopping = EarlyStopping(
        monitor="val_loss",  # ë˜ëŠ” ëª¨ë¸ë³„ ì ì ˆí•œ ë©”íŠ¸ë¦­
        patience=config["early_stopping_patience"],
        mode="min",
        verbose=True
    )
    
    checkpoint_callback = ModelCheckpoint(
        filename=f"{MODEL_NAME}_multi_domain_{datamodule.source_domain}_" + "{epoch:02d}_{val_loss:.4f}",
        monitor="val_loss",
        mode="min",
        save_top_k=1,
        verbose=True
    )
    
    # 3. TensorBoard ë¡œê±° ì„¤ì •
    tb_logger = TensorBoardLogger(
        save_dir=results_base_dir,
        name="tensorboard_logs",
        version=""  # ë¹ˆ ë²„ì „ìœ¼ë¡œ version_x í´ë” ë°©ì§€
    )
    
    # 4. Engine ìƒì„± ë° í›ˆë ¨
    engine = Engine(
        accelerator="gpu" if torch.cuda.is_available() else "cpu",
        devices=[0] if torch.cuda.is_available() else 1,
        logger=tb_logger,
        max_epochs=config["max_epochs"],
        callbacks=[early_stopping, checkpoint_callback],
        check_val_every_n_epoch=1,
        enable_checkpointing=True,
        log_every_n_steps=10,
        enable_model_summary=True,
        num_sanity_val_steps=0,
        default_root_dir=results_base_dir
    )
    
    # 5. ëª¨ë¸ í›ˆë ¨
    engine.fit(model=model, datamodule=datamodule)
    
    return model, engine, checkpoint_callback.best_model_path
```

##### B. ê²°ê³¼ ë¶„ì„ í•¨ìˆ˜
```python
def analyze_{MODEL_NAME}_results(
    source_results: Dict[str, Any],
    target_results: Dict[str, Dict[str, Any]],
    training_info: Dict[str, Any],
    condition: Dict[str, Any],
    logger: logging.Logger
) -> Dict[str, Any]:
    """ëª¨ë¸ë³„ íŠ¹í™” ê²°ê³¼ ë¶„ì„ ë¡œì§"""
    # í‰ê·  íƒ€ê²Ÿ AUROC ê³„ì‚° ë“±
    pass
```

##### C. ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰ í•¨ìˆ˜
```python
def run_single_{MODEL_NAME}_experiment(
    condition: Dict[str, Any],
    source_domain: str = "domain_A",
    target_domains: List[str] = None,
    dataset_root: str = None,
    results_base_dir: str = "./results",
    logger: logging.Logger = None
) -> Dict[str, Any]:
    """ë‹¨ì¼ {MODEL_NAME} ì‹¤í—˜ ì¡°ê±´ì— ëŒ€í•œ ì‹¤í—˜ ìˆ˜í–‰."""
    
    try:
        # 1. GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        cleanup_gpu_memory()
        
        # 2. ì‹¤í—˜ë³„ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        experiment_folder = f"{experiment_name}_{timestamp}"
        experiment_dir = Path(results_base_dir) / "MultiDomainHDMAP" / "{MODEL_NAME}" / experiment_folder
        experiment_dir.mkdir(parents=True, exist_ok=True)
        
        # 3. DataModule ìƒì„±
        datamodule = create_multi_domain_datamodule(...)
        
        # 4. ëª¨ë¸ í›ˆë ¨
        model, engine, best_checkpoint = train_{MODEL_NAME}_model_multi_domain(...)
        
        # 5. í›ˆë ¨ ì •ë³´ ì¶”ì¶œ
        training_info = extract_training_info(engine)
        
        # 6. ì„±ëŠ¥ í‰ê°€
        source_results = evaluate_source_domain(...)
        target_results = evaluate_target_domains(...)
        
        # 7. ì‹œê°í™” ìƒì„±
        viz_path = create_experiment_visualization(...)
        
        # 8. ê²°ê³¼ ë¶„ì„
        analysis = analyze_{MODEL_NAME}_results(...)
        
        # 9. ì‹¤í—˜ ê²°ê³¼ ì •ë¦¬ ë° JSON ì €ì¥
        experiment_result = {
            "condition": condition,
            "experiment_name": experiment_name, 
            "source_results": source_results,
            "target_results": target_results,
            "best_checkpoint": best_checkpoint,
            "training_info": training_info,
            "status": "success",
            "experiment_path": str(latest_version_path),
            "avg_target_auroc": analysis["avg_target_auroc"]
        }
        
        # JSON ê²°ê³¼ íŒŒì¼ ì €ì¥ (ê° ì‹¤í—˜ì˜ tensorboard_logs í´ë”ì—)
        result_filename = f"result_{condition['name']}_{timestamp}.json"
        result_path = latest_version_path / result_filename
        
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(experiment_result, f, indent=2, ensure_ascii=False)
        
        return experiment_result
        
    except Exception as e:
        return {
            "status": "failed",
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "experiment_name": experiment_name,
            "condition": condition,
            "error": str(e)
        }
```

#### 1.5 ë©”ì¸ í•¨ìˆ˜
```python
def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì‹¤í—˜ ì„¤ì • ë° ì‹¤í–‰."""
    parser = argparse.ArgumentParser(description="HDMAP ë‹¤ì¤‘ ë„ë©”ì¸ {MODEL_NAME} ì‹¤í—˜")
    
    # ê³µí†µ ì¸ìë“¤
    parser.add_argument("--experiment_name", type=str, help="ì‹¤í—˜ ì´ë¦„")
    parser.add_argument("--max_epochs", type=int, default=30, help="ìµœëŒ€ ì—í­ ìˆ˜")
    parser.add_argument("--early_stopping_patience", type=int, default=5, help="Early stopping patience")
    parser.add_argument("--learning_rate", type=float, default=1e-4, help="í•™ìŠµë¥ ")
    parser.add_argument("--batch_size", type=int, default=32, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--source_domain", type=str, default="domain_A", help="ì†ŒìŠ¤ ë„ë©”ì¸")
    parser.add_argument("--dataset_root", type=str, help="ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ")
    parser.add_argument("--results_dir", type=str, default="./results", help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--run_all_experiments", action="store_true", help="ëª¨ë“  ì‹¤í—˜ ì¡°ê±´ ì‹¤í–‰")
    parser.add_argument("--log_level", type=str, default="INFO", help="ë¡œê·¸ ë ˆë²¨")
    
    args = parser.parse_args()
    
    # ë¡œê·¸ ì„¤ì • (ê³µí†µ íŒ¨í„´)
    results_dir = Path(args.results_dir)
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # results_dirì—ì„œ timestamp ì¶”ì¶œí•˜ì—¬ í†µí•© ë¡œê·¸ íŒŒì¼ ìƒì„±
    import re
    dir_parts = str(results_dir).split('/')
    run_timestamp = None
    for part in dir_parts:
        if re.match(r'\d{8}_\d{6}', part):
            run_timestamp = part
            break
    
    if not run_timestamp:
        run_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    log_file = results_dir / f"{MODEL_NAME}_experiment_{run_timestamp}.log"
    logger = setup_experiment_logging(str(log_file), f"{MODEL_NAME}_experiment")
    
    # ì‹¤í—˜ ì‹¤í–‰ ë¡œì§
    all_results = []
    
    if args.run_all_experiments:
        # ëª¨ë“  ì‹¤í—˜ ì¡°ê±´ ì‹¤í–‰
        for condition in EXPERIMENT_CONDITIONS:
            result = run_single_{MODEL_NAME}_experiment(...)
            all_results.append(result)
    else:
        # ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰
        result = run_single_{MODEL_NAME}_experiment(...)
        all_results.append(result)
    
    # ë‹¤ì¤‘ ì‹¤í—˜ ë¶„ì„
    if len(all_results) > 1:
        analyze_multi_experiment_results(all_results, args.source_domain)


if __name__ == "__main__":
    main()
```

### 2. Bash ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (`multi_domain_hdmap_{MODEL_NAME}_training_run.sh`)

#### 2.1 ìŠ¤í¬ë¦½íŠ¸ í—¤ë”
```bash
#!/bin/bash

# {MODEL_NAME} ë³‘ë ¬ ì‹¤í—˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
# ë©€í‹° GPUë¥¼ í™œìš©í•˜ì—¬ ì‹¤í—˜ ì¡°ê±´ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
```

#### 2.2 ì‹¤í—˜ ì„¤ì •
```bash
# ì„¤ì • (ì‚¬ìš© ê°€ëŠ¥í•œ GPUì™€ ì‹¤í—˜ ì¡°ê±´ë“¤)
AVAILABLE_GPUS=(3 4 5 6 7 8)  # ì‚¬ìš©í•  GPU ëª©ë¡
EXPERIMENT_CONDITIONS=(
    "{MODEL_NAME}_baseline"
    "{MODEL_NAME}_variant1"
    "{MODEL_NAME}_variant2"
    # ì¶”ê°€ ì‹¤í—˜ ì¡°ê±´ë“¤...
)
NUM_EXPERIMENTS=${#EXPERIMENT_CONDITIONS[@]}

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„± (í†µí•© timestamp í´ë”)
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_DIR="results/{MODEL_NAME}/${TIMESTAMP}"
mkdir -p "${LOG_DIR}"

SCRIPT_PATH="examples/hdmap/multi_domain_hdmap_{MODEL_NAME}_training.py"
```

#### 2.3 ì‹¤í—˜ ì‹¤í–‰ ë¡œì§
```bash
echo "=================================="
echo "ğŸš€ {MODEL_NAME} ë³‘ë ¬ ì‹¤í—˜ ì‹œì‘"
echo "=================================="
echo "ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: ${LOG_DIR}"
echo "ğŸ–¥ï¸  ì‚¬ìš© GPU: ${AVAILABLE_GPUS[*]}"
echo "ğŸ§ª ì‹¤í—˜ ì¡°ê±´: ${NUM_EXPERIMENTS}ê°œ"
echo ""

# ì‹¤í—˜ í• ë‹¹ ë° ì‹¤í–‰
echo "ğŸ“‹ ì‹¤í—˜ í• ë‹¹:"
for i in $(seq 0 $((NUM_EXPERIMENTS-1))); do
    GPU_ID=${AVAILABLE_GPUS[$((i % ${#AVAILABLE_GPUS[@]}))]}
    EXP_NAME=${EXPERIMENT_CONDITIONS[$i]}
    echo "   GPU ${GPU_ID}: ì‹¤í—˜ ${i} - ${EXP_NAME}"
done
echo ""

echo "ğŸš€ ë³‘ë ¬ ì‹¤í—˜ ì‹œì‘..."

# ë°±ê·¸ë¼ìš´ë“œë¡œ ëª¨ë“  ì‹¤í—˜ ì‹¤í–‰
SUCCESS_COUNT=0
FAILED_COUNT=0
PIDS=()

for i in $(seq 0 $((NUM_EXPERIMENTS-1))); do
    GPU_ID=${AVAILABLE_GPUS[$((i % ${#AVAILABLE_GPUS[@]}))]}
    EXP_NAME=${EXPERIMENT_CONDITIONS[$i]}
    
    echo "[$(date +%H:%M:%S)] ì‹œì‘: GPU ${GPU_ID} - ${EXP_NAME}"
    
    # ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í—˜ ì‹¤í–‰
    cd /home/taewan.hwang/study/anomalib
    uv run "${SCRIPT_PATH}" \
        --gpu-id "${GPU_ID}" \
        --experiment-id "${i}" \
        --log-dir "${LOG_DIR}" \
        > "${LOG_DIR}/output_exp_${i}_gpu${GPU_ID}.log" 2>&1 &
    
    PID=$!
    PIDS[$i]=$PID
    
    sleep 2  # GPU ë©”ëª¨ë¦¬ ì¶©ëŒ ë°©ì§€
done

# ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ ëŒ€ê¸°
for i in $(seq 0 $((NUM_EXPERIMENTS-1))); do
    PID=${PIDS[$i]}
    GPU_ID=${AVAILABLE_GPUS[$((i % ${#AVAILABLE_GPUS[@]}))]}
    EXP_NAME=${EXPERIMENT_CONDITIONS[$i]}
    
    # í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸°
    wait $PID
    EXIT_CODE=$?
    
    if [ $EXIT_CODE -eq 0 ]; then
        echo "[$(date +%H:%M:%S)] âœ… ì™„ë£Œ: GPU ${GPU_ID} - ${EXP_NAME}"
        ((SUCCESS_COUNT++))
    else
        echo "[$(date +%H:%M:%S)] âŒ ì‹¤íŒ¨: GPU ${GPU_ID} - ${EXP_NAME} (ì¢…ë£Œ ì½”ë“œ: ${EXIT_CODE})"
        ((FAILED_COUNT++))
    fi
done

echo ""
echo "=================================="
echo "ğŸ‰ ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!"
echo "   ì„±ê³µ: ${SUCCESS_COUNT}/${NUM_EXPERIMENTS}"
echo "   ì‹¤íŒ¨: ${FAILED_COUNT}/${NUM_EXPERIMENTS}"
echo "   ë¡œê·¸ ë””ë ‰í† ë¦¬: ${LOG_DIR}"
echo "=================================="

# ì‹¤íŒ¨í•œ ì‹¤í—˜ì´ ìˆìœ¼ë©´ ê²½ê³ 
if [ $FAILED_COUNT -gt 0 ]; then
    echo "âš ï¸  ${FAILED_COUNT}ê°œ ì‹¤í—˜ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    echo "   ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”: ${LOG_DIR}/"
fi

echo ""
echo "ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:"
echo "   ì‹¤í—˜ ë¡œê·¸: ${LOG_DIR}/{MODEL_NAME}_experiment_*.log"
echo "   ì¶œë ¥ ë¡œê·¸: ${LOG_DIR}/output_exp_*_gpu*.log"
echo "   ì‹¤í—˜ë³„ í´ë”: ${LOG_DIR}/MultiDomainHDMAP/{MODEL_NAME}/*/"
echo "   ì²´í¬í¬ì¸íŠ¸: ${LOG_DIR}/MultiDomainHDMAP/{MODEL_NAME}/*/tensorboard_logs/checkpoints/"
echo "   ì‹œê°í™” ê²°ê³¼: ${LOG_DIR}/MultiDomainHDMAP/{MODEL_NAME}/*/tensorboard_logs/visualize/"
echo "   JSON ê²°ê³¼: ${LOG_DIR}/MultiDomainHDMAP/{MODEL_NAME}/*/tensorboard_logs/result_*.json"
```

## ğŸ”§ êµ¬í˜„ ê°€ì´ë“œ

### 3.1 ìƒˆ ëª¨ë¸ ì¶”ê°€ ì‹œ ì²´í¬ë¦¬ìŠ¤íŠ¸

1. **íŒŒì¼ ìƒì„±**
   - [ ] `multi_domain_hdmap_{MODEL_NAME}_training.py` ìƒì„±
   - [ ] `multi_domain_hdmap_{MODEL_NAME}_training_run.sh` ìƒì„±

2. **Python ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •ì‚¬í•­**
   - [ ] Docstringì—ì„œ `{MODEL_NAME}` êµì²´
   - [ ] ëª¨ë¸ import ê²½ë¡œ ìˆ˜ì •: `from anomalib.models.image.{MODEL_NAME} import {ModelClass}`
   - [ ] `EXPERIMENT_CONDITIONS` ëª¨ë¸ë³„ íŠ¹í™” íŒŒë¼ë¯¸í„° ì •ì˜
   - [ ] `train_{MODEL_NAME}_model_multi_domain` í•¨ìˆ˜ êµ¬í˜„
   - [ ] `analyze_{MODEL_NAME}_results` í•¨ìˆ˜ êµ¬í˜„ (ëª¨ë¸ë³„ íŠ¹í™” ë¶„ì„)
   - [ ] `run_single_{MODEL_NAME}_experiment` í•¨ìˆ˜ êµ¬í˜„
   - [ ] Early stopping ë©”íŠ¸ë¦­ í™•ì¸ (`val_loss` vs `val_image_AUROC` ë“±)

3. **Bash ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •ì‚¬í•­**
   - [ ] `AVAILABLE_GPUS` ë°°ì—´ ì„¤ì •
   - [ ] `EXPERIMENT_CONDITIONS` ë°°ì—´ì— ëª¨ë¸ë³„ ì‹¤í—˜ ì¡°ê±´ ì •ì˜
   - [ ] `LOG_DIR` ê²½ë¡œë¥¼ `results/{MODEL_NAME}/${TIMESTAMP}` í˜•ì‹ìœ¼ë¡œ ì„¤ì •
   - [ ] `SCRIPT_PATH` ì˜¬ë°”ë¥¸ Python ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œë¡œ ì„¤ì •

### 3.2 ê³µí†µ ìœ í‹¸ë¦¬í‹° í™œìš©

ëª¨ë“  ëª¨ë¸ì€ `experiment_utils.py`ì˜ ê³µí†µ í•¨ìˆ˜ë“¤ì„ ìµœëŒ€í•œ í™œìš©:

- `setup_warnings_filter()`: ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§
- `setup_experiment_logging()`: ë¡œê¹… ì„¤ì •
- `cleanup_gpu_memory()`: GPU ë©”ëª¨ë¦¬ ì •ë¦¬
- `create_multi_domain_datamodule()`: ë°ì´í„° ëª¨ë“ˆ ìƒì„±
- `evaluate_source_domain()`: ì†ŒìŠ¤ ë„ë©”ì¸ í‰ê°€
- `evaluate_target_domains()`: íƒ€ê²Ÿ ë„ë©”ì¸ë“¤ í‰ê°€
- `extract_training_info()`: í›ˆë ¨ ì •ë³´ ì¶”ì¶œ
- `create_experiment_visualization()`: ì‹œê°í™” ìƒì„±
- `analyze_multi_experiment_results()`: ë‹¤ì¤‘ ì‹¤í—˜ ë¶„ì„

### 3.3 ê²°ê³¼ í´ë” êµ¬ì¡° (í‘œì¤€í™”)

```
results/{MODEL_NAME}/{TIMESTAMP}/
â”œâ”€â”€ {MODEL_NAME}_experiment_{TIMESTAMP}.log      # í†µí•© ì‹¤í—˜ ë¡œê·¸ (Pythonì—ì„œ ìƒì„±)
â”œâ”€â”€ output_exp_0_gpu*.log                        # ê°œë³„ ì‹¤í—˜ ì¶œë ¥ (Bashì—ì„œ ìƒì„±)
â”œâ”€â”€ output_exp_1_gpu*.log
â”œâ”€â”€ ...
â””â”€â”€ MultiDomainHDMAP/
    â””â”€â”€ {MODEL_NAME}/
        â”œâ”€â”€ {EXPERIMENT_NAME_1}_{TIMESTAMP}/
        â”‚   â””â”€â”€ tensorboard_logs/
        â”‚       â”œâ”€â”€ result_{EXPERIMENT_NAME_1}_{TIMESTAMP}.json   # ì‹¤í—˜ ê²°ê³¼ JSON
        â”‚       â”œâ”€â”€ checkpoints/
        â”‚       â”‚   â””â”€â”€ {MODEL_NAME}_multi_domain_domain_A_*.ckpt
        â”‚       â””â”€â”€ visualize/
        â”‚           â”œâ”€â”€ source_images/
        â”‚           â””â”€â”€ target_images/
        â”œâ”€â”€ {EXPERIMENT_NAME_2}_{TIMESTAMP}/
        â””â”€â”€ ...
```

### 3.4 JSON ê²°ê³¼ íŒŒì¼ í‘œì¤€ êµ¬ì¡°

```json
{
  "condition": {
    "name": "...",
    "description": "...",
    "config": {...}
  },
  "experiment_name": "domain_A",
  "source_results": {
    "image_AUROC": 0.xxx,
    "image_F1Score": 0.xxx
  },
  "target_results": {
    "domain_B": {...},
    "domain_C": {...},
    "domain_D": {...}
  },
  "best_checkpoint": "/path/to/checkpoint.ckpt",
  "training_info": {
    "max_epochs_configured": 30,
    "last_trained_epoch": 15,
    "early_stopped": true,
    "completion_type": "early_stopping"
  },
  "status": "success",
  "experiment_path": "/path/to/tensorboard_logs",
  "avg_target_auroc": 0.xxx
}
```

## ğŸ“‹ ì˜ˆì‹œ: ìƒˆ ëª¨ë¸ ì¶”ê°€

ì˜ˆë¥¼ ë“¤ì–´, `PatchCore` ëª¨ë¸ì„ ì¶”ê°€í•œë‹¤ë©´:

1. **íŒŒì¼ ìƒì„±**:
   - `multi_domain_hdmap_patchcore_training.py`
   - `multi_domain_hdmap_patchcore_training_run.sh`

2. **ì£¼ìš” ë³€ê²½ì‚¬í•­**:
   ```python
   # Import ë³€ê²½
   from anomalib.models.image.patchcore import PatchCore
   
   # í•¨ìˆ˜ëª… ë³€ê²½
   def train_patchcore_model_multi_domain(...):
   def analyze_patchcore_results(...):
   def run_single_patchcore_experiment(...):
   
   # ì‹¤í—˜ ì¡°ê±´ ì •ì˜
   EXPERIMENT_CONDITIONS = [
       {
           "name": "patchcore_baseline",
           "description": "PatchCore ê¸°ë³¸ ì„¤ì •",
           "config": {
               "backbone": "wide_resnet50_2",
               "pre_trained": True,
               "layers": ["layer2", "layer3"],
               "coreset_sampling_ratio": 0.1,
               # PatchCore íŠ¹í™” íŒŒë¼ë¯¸í„°ë“¤...
           }
       }
   ]
   ```

3. **Bash ìŠ¤í¬ë¦½íŠ¸**:
   ```bash
   LOG_DIR="results/patchcore/${TIMESTAMP}"
   SCRIPT_PATH="examples/hdmap/multi_domain_hdmap_patchcore_training.py"
   EXPERIMENT_CONDITIONS=(
       "patchcore_baseline"
       "patchcore_variant1"
       # ...
   )
   ```

ì´ í…œí”Œë¦¿ì„ ë”°ë¥´ë©´ **ì¼ê´€ëœ ì‹¤í—˜ í™˜ê²½**ê³¼ **í‘œì¤€í™”ëœ ê²°ê³¼ êµ¬ì¡°**ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì‹¤í—˜ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
