#!/usr/bin/env python3
"""HDMAP ë°ì´í„°ì…‹ ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸ (Clean Version).

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” mat íŒŒì¼ í˜•íƒœì˜ ì›ë³¸ HDMAP ë°ì´í„°ë¥¼ PNG ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
í”„ë¡œí† íƒ€ì…ê³¼ ë™ì¼í•œ ì „ì—­ ì •ê·œí™” ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ ì €í•˜ ì—†ì´ ë³€í™˜í•©ë‹ˆë‹¤.

ì‹¤í–‰ ëª…ë ¹ì–´:
nohup python /mnt/ex-disk/taewan.hwang/study/anomalib/examples/hdmap/prepare_hdmap_dataset.py > hdmap_dataset.log 2>&1 &

í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ:
1. ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸: ps aux | grep prepare_hdmap_dataset.py
2. í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ: kill -9 <PID>
ë˜ëŠ”
pkill -f prepare_hdmap_dataset.py
"""

import os
import shutil

import cv2
import numpy as np
import scipy.io
import tifffile

# =============================================================================
# ğŸš€ ì‚¬ìš©ì ì„¤ì • (í•„ìš”ì— ë”°ë¼ ìˆ˜ì •)
# =============================================================================
# ë°ì´í„° ì„¤ì •
N_TRAINING = 1000  # í›ˆë ¨ ìƒ˜í”Œ ìˆ˜
N_TESTING = 2000   # í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜
SAVE_FORMATS = ['png']  # ì €ì¥ í˜•ì‹ (TIFF, PNG)
BASE_FOLDER = "HDMAP"    # ìµœìƒìœ„ í´ë”ëª…
RANDOM_SEED = 42  # ëœë¤ ì‹œë“œ (ì¬í˜„ì„± ë³´ì¥)

# ì •ê·œí™” ë°©ì‹ ì„¤ì •
NORMALIZATION_MODES = [
    'original',    # ì›ë³¸ ë°ì´í„° (ìŠ¤ì¼€ì¼ë§ ì—†ìŒ)
    'zscore',      # ê¸°ì¡´ domain_stats ê¸°ë°˜ z-score ì •ê·œí™”
    'minmax',      # ì‚¬ìš©ì ì œê³µ min-max ìŠ¤ì¼€ì¼ë§
]

# =============================================================================
# ë„ë©”ì¸ êµ¬ì„± ì •ë³´ (ì¤‘ì•™ ì§‘ì¤‘ì‹ ê´€ë¦¬)
# =============================================================================
DOMAIN_CONFIG = {
    'A': {
        'sensor': 'Class1/1',
        'data_type': '3_TSA_DIF',
        'user_min': 0.0,
        'user_max': 0.32
    },
    'B': {
        'sensor': 'Class1/1',
        'data_type': '1_TSA_DIF',
        'user_min': 0.0,
        'user_max': 1.2
    },
    'C': {
        'sensor': 'Class3/1',
        'data_type': '3_TSA_DIF',
        'user_min': 0.0,
        'user_max': 0.09
    },
    'D': {
        'sensor': 'Class3/1', 
        'data_type': '1_TSA_DIF',
        'user_min': 0.0,
        'user_max': 0.41
    },
}

# ê¸°ë³¸ ê²½ë¡œ
BASE_DATA_PATH = 'datasets/raw/KRISS_share_nipa2023'

# =============================================================================
# í•µì‹¬ í•¨ìˆ˜ë“¤
# =============================================================================
def normalize_zscore(X, X_mean=None, X_std=None):
    """Z-score ì •ê·œí™” (í”„ë¡œí† íƒ€ì…ê³¼ ë™ì¼)"""
    if X_mean is None or X_std is None:
        X_mean = np.mean(X)
        X_std = np.std(X)
    X_normalized = (X - X_mean) / X_std
    return X_normalized, X_mean, X_std

def normalize_minmax(X, user_min, user_max):
    """ì‚¬ìš©ì ì œê³µ min-max ê°’ìœ¼ë¡œ [0, 1] ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§"""
    # ì‚¬ìš©ì ì œê³µ ë²”ìœ„ë¡œ í´ë¦¬í•‘
    X_clipped = np.clip(X, user_min, user_max)
    # [user_min, user_max] â†’ [0, 1] ë§¤í•‘
    X_scaled = (X_clipped - user_min) / (user_max - user_min)
    return X_scaled

def generate_paths():
    """ë„ë©”ì¸ êµ¬ì„± ì •ë³´ë¡œë¶€í„° ëª¨ë“  ê²½ë¡œ ìƒì„±"""
    paths = {}
    
    for domain, config in DOMAIN_CONFIG.items():
        sensor_path = config['sensor']
        data_type = config['data_type']
        
        # ê¸°ë³¸ ê²½ë¡œ êµ¬ì„±
        normal_base = f"{BASE_DATA_PATH}/Normal/Normal2_LSSm0.3_HSS0/{sensor_path}/HDMap_train_test"
        fault_base = f"{BASE_DATA_PATH}/Planet_fault_ring/1.42_LSSm0.3_HSS0/{sensor_path}/HDMap_train_test"
        
        paths[domain] = {
            'train_normal': f"{normal_base}/{data_type}_train.mat",
            'test_normal': f"{normal_base}/{data_type}_test.mat", 
            'test_fault': f"{fault_base}/{data_type}_test.mat"
        }
    
    return paths

def generate_folder_name(save_format, normalization_mode):
    """ì„¤ì •ì— ë”°ë¥¸ ë°ì´í„°ì…‹ í´ë”ëª… ìƒì„±"""
    if normalization_mode == 'original':
        return f"{N_TRAINING}_{save_format}_original"
    else:
        return f"{N_TRAINING}_{save_format}_{normalization_mode}"

def save_tiff_image(img_array, save_path):
    """ì´ë¯¸ì§€ë¥¼ 32ë¹„íŠ¸ ë¶€ë™ì†Œìˆ˜ì  TIFF íŒŒì¼ë¡œ ì €ì¥"""
    tifffile.imwrite(save_path, img_array.astype(np.float32))

def save_png_image(img_array, save_path):
    """ì´ë¯¸ì§€ë¥¼ 16ë¹„íŠ¸ PNG íŒŒì¼ë¡œ ì €ì¥"""
    # [0, 1] ë²”ìœ„ë¥¼ [0, 65535]ë¡œ ìŠ¤ì¼€ì¼ë§
    img_16bit = (img_array * 65535).astype(np.uint16)
    cv2.imwrite(save_path, img_16bit)

def compute_domain_statistics():
    """ê° ë„ë©”ì¸ë³„ ì „ì—­ í†µê³„ëŸ‰ ê³„ì‚°"""
    print("="*80)
    print("ğŸ”¢ ë„ë©”ì¸ë³„ ì „ì—­ í†µê³„ëŸ‰ ê³„ì‚° ì¤‘...")
    print("="*80)
    
    paths = generate_paths()
    domain_stats = {}
    
    for domain, domain_paths in paths.items():
        train_path = domain_paths['train_normal']
        
        if os.path.exists(train_path):
            print(f"ë„ë©”ì¸ {domain} í†µê³„ëŸ‰ ê³„ì‚° ì¤‘...")
            
            # mat íŒŒì¼ ë¡œë“œ
            mat_data = scipy.io.loadmat(train_path)
            train_data = mat_data['Xdata']
            
            # ë°ì´í„° í˜•íƒœ ë³€í™˜ (í”„ë¡œí† íƒ€ì…ê³¼ ë™ì¼)
            X_train = train_data.transpose(3,2,0,1)  # (samples, channels, height, width)
            
            # ì „ì—­ í†µê³„ëŸ‰ ê³„ì‚°
            _, X_mean, X_std = normalize_zscore(X_train)
            domain_stats[domain] = {'mean': X_mean, 'std': X_std}
            
            # ì •ê·œí™” í›„ í†µê³„ëŸ‰ í™•ì¸
            X_normalized, _, _ = normalize_zscore(X_train, X_mean, X_std)
            
            print(f"  ë„ë©”ì¸ {domain}:")
            print(f"    ì›ë³¸: mean={X_mean:.6f}, std={X_std:.6f}")
            print(f"    ì •ê·œí™” í›„: min={X_normalized.min():.6f}, max={X_normalized.max():.6f}, mean={X_normalized.mean():.6f}, std={X_normalized.std():.6f}")
        else:
            print(f"  âš ï¸ ê²½ê³ : {train_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return domain_stats

def process_single_domain(domain, domain_paths, domain_stats, folder_name, save_format, normalization_mode):
    """ë„ë©”ì¸ë³„ ë°ì´í„° ì²˜ë¦¬"""
    print(f"\nğŸ”„ ë„ë©”ì¸ {domain} ì²˜ë¦¬ ì¤‘... (í˜•ì‹: {save_format}, ì •ê·œí™”: {normalization_mode})")
    
    # ì €ì¥ ê²½ë¡œ ì„¤ì •
    save_dirs = {}
    for data_type in ['train/good', 'test/good', 'test/fault']:
        save_dir = f"datasets/{BASE_FOLDER}/{folder_name}/domain_{domain}/{data_type}"
        save_dirs[data_type] = save_dir
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        if os.path.exists(save_dir):
            shutil.rmtree(save_dir)
        os.makedirs(save_dir, exist_ok=True)
    
    # ë°ì´í„° ì²˜ë¦¬ ë§¤í•‘ (data_key, save_key, max_samples, description, shuffle)
    data_mapping = [
        ('train_normal', 'train/good', N_TRAINING, "ì •ìƒ í›ˆë ¨", True),
        ('test_normal', 'test/good', N_TESTING, "ì •ìƒ í…ŒìŠ¤íŠ¸", False),
        ('test_fault', 'test/fault', N_TESTING, "ê³ ì¥ í…ŒìŠ¤íŠ¸", False)
    ]
    
    # ì •ê·œí™” ëª¨ë“œì— ë”°ë¼ í•„ìš”í•œ ë³€ìˆ˜ë§Œ ì¤€ë¹„
    stats = {}
    user_min = user_max = None
    
    if normalization_mode == 'zscore':
        stats = domain_stats.get(domain, {})
        if 'mean' not in stats or 'std' not in stats:
            print(f"  âš ï¸ ê²½ê³ : ë„ë©”ì¸ {domain}ì˜ í†µê³„ëŸ‰ì´ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ ë„ë©”ì¸ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
    elif normalization_mode == 'minmax':
        domain_config = DOMAIN_CONFIG[domain]
        user_min = domain_config['user_min']
        user_max = domain_config['user_max']
    
    for data_key, save_key, max_samples, description, shuffle in data_mapping:
        mat_path = domain_paths[data_key]
        save_dir = save_dirs[save_key]

        if not os.path.exists(mat_path):
            print(f"  âš ï¸ {description}: {mat_path} íŒŒì¼ ì—†ìŒ")
            continue

        print(f"  ğŸ“‚ {description} ë°ì´í„° ì²˜ë¦¬ ì¤‘... (shuffle={shuffle})")

        # mat íŒŒì¼ ë¡œë“œ
        mat_data = scipy.io.loadmat(mat_path)
        image_data = mat_data['Xdata']

        # ìƒ˜í”Œ ìˆ˜ ê²°ì •
        actual_samples = image_data.shape[3] if len(image_data.shape) > 3 else 1
        num_samples = min(max_samples, actual_samples)

        # ì¸ë±ìŠ¤ ìƒì„± (shuffle ì˜µì…˜ì— ë”°ë¼)
        if shuffle:
            np.random.seed(RANDOM_SEED)
            indices = np.random.choice(actual_samples, num_samples, replace=False)
            print(f"    ğŸ”€ ëœë¤ ìƒ˜í”Œë§: {num_samples}ê°œ ì„ íƒ (ì „ì²´ {actual_samples}ê°œ ì¤‘)")
        else:
            indices = np.arange(num_samples)
            print(f"    ğŸ“‹ ìˆœì°¨ ìƒ˜í”Œë§: ì²˜ìŒ {num_samples}ê°œ ì„ íƒ")

        # ì´ë¯¸ì§€ ì €ì¥
        for idx, i in enumerate(indices):
            img = image_data[:, :, 0, i]

            # íŒŒì¼ í™•ì¥ì ê²°ì •
            file_ext = 'tiff' if save_format == 'tiff' else 'png'
            # íŒŒì¼ëª…ì€ ìˆœì°¨ì ìœ¼ë¡œ ì €ì¥ (000000.png, 000001.png, ...)
            filename = f'{idx:06d}.{file_ext}'
            save_path = os.path.join(save_dir, filename)

            # ì •ê·œí™” ë°©ì‹ì— ë”°ë¥¸ ì²˜ë¦¬
            if normalization_mode == 'original':
                # ì›ë³¸ ë°ì´í„° ê·¸ëŒ€ë¡œ ì €ì¥ (ìŠ¤ì¼€ì¼ë§ ì—†ìŒ)
                processed_img = img

            elif normalization_mode == 'zscore':
                # Z-score ì •ê·œí™” ë°©ì‹
                processed_img, _, _ = normalize_zscore(img, stats['mean'], stats['std'])

            elif normalization_mode == 'minmax':
                # Min-Max ìŠ¤ì¼€ì¼ë§ ë°©ì‹ (ë„ë©”ì¸ë³„ ì„¤ì • ì‚¬ìš©)
                processed_img = normalize_minmax(img, user_min, user_max)

            else:
                raise ValueError(f"Unknown normalization mode: {normalization_mode}")

            # ì €ì¥ í˜•ì‹ì— ë”°ë¥¸ ì €ì¥
            if save_format == 'tiff':
                save_tiff_image(processed_img, save_path)
            elif save_format == 'png':
                save_png_image(processed_img, save_path)
            else:
                raise ValueError(f"Unknown save format: {save_format}")
            
            # ì§„í–‰ìƒí™© ì¶œë ¥
            if (idx + 1) % 10000 == 0:
                print(f"    ì§„í–‰: {idx + 1}/{num_samples}")
        
        print(f"  âœ… {description}: {num_samples}ê°œ ì €ì¥ ì™„ë£Œ")

def create_hdmap_datasets():
    """ì—¬ëŸ¬ ì²˜ë¦¬ ëª¨ë“œë¡œ HDMAP ë°ì´í„°ì…‹ ì¤€ë¹„ (z-score + min-max ì •ê·œí™” ì§€ì›)"""
    print("="*80)
    print("ğŸš€ HDMAP ë°ì´í„°ì…‹ ë³€í™˜ ì‹œì‘ (ë‹¤ì¤‘ ëª¨ë“œ)")
    print("="*80)
    print(f"í›ˆë ¨ ìƒ˜í”Œ ìˆ˜: {N_TRAINING:,}")
    print(f"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {N_TESTING:,}")
    print(f"ì €ì¥ í˜•ì‹: {len(SAVE_FORMATS)}ê°œ ({', '.join(SAVE_FORMATS)})")
    print(f"ì •ê·œí™” ë°©ì‹: {len(NORMALIZATION_MODES)}ê°œ ({', '.join(NORMALIZATION_MODES)})")
    
    print(f"\nì •ê·œí™” ì„¤ì •:")
    print(f"  - Original: ì›ë³¸ ë°ì´í„° ê·¸ëŒ€ë¡œ ì €ì¥ (ìŠ¤ì¼€ì¼ë§ ì—†ìŒ)")
    print(f"  - Z-score: ì „ì—­ í†µê³„ëŸ‰ ê¸°ë°˜")
    print(f"  - Min-Max: ë„ë©”ì¸ë³„ ì‚¬ìš©ì ì œê³µ ë²”ìœ„ â†’ [0, 1]")
    for domain, config in DOMAIN_CONFIG.items():
        print(f"    ë„ë©”ì¸ {domain}: [{config['user_min']}, {config['user_max']}]")
    
    print("="*80)
    
    # 1. ê²½ë¡œ ì¤€ë¹„
    paths = generate_paths()
    
    # 2. z-score ë°©ì‹ìš© ì „ì—­ í†µê³„ëŸ‰ ê³„ì‚° (z-score ëª¨ë“œê°€ í™œì„±í™”ëœ ê²½ìš°ë§Œ)
    domain_stats = {}
    if 'zscore' in NORMALIZATION_MODES:
        domain_stats = compute_domain_statistics()
    else:
        print("ğŸ”¢ Z-score ëª¨ë“œê°€ ë¹„í™œì„±í™”ë˜ì–´ í†µê³„ëŸ‰ ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # 3. ê° ì •ê·œí™” ë°©ì‹, ì €ì¥ í˜•ì‹ë³„ë¡œ ë°ì´í„° ì²˜ë¦¬
    for normalization_mode in NORMALIZATION_MODES:
        for save_format in SAVE_FORMATS:
            print(f"\nğŸ”„ ì²˜ë¦¬: {normalization_mode.upper()} - {save_format.upper()}")
            folder_name = generate_folder_name(save_format, normalization_mode)
            
            for domain in DOMAIN_CONFIG.keys():
                domain_paths = paths[domain]
                process_single_domain(domain, domain_paths, domain_stats, folder_name, save_format, normalization_mode)

    print(f"\nâœ… ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")
    
    # ìƒì„±ëœ í´ë” ìš”ì•½
    print(f"\nğŸ“ ìƒì„±ëœ ë°ì´í„°ì…‹ í´ë”:")
    for normalization_mode in NORMALIZATION_MODES:
        for save_format in SAVE_FORMATS:
            folder_name = generate_folder_name(save_format, normalization_mode)
            print(f"  - datasets/{BASE_FOLDER}/{folder_name}/")
    
    print(f"\nê° í´ë”ì—ëŠ” domain_A, domain_B, domain_C, domain_Dê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    # HDMAP ë°ì´í„°ì…‹ ìƒì„± (Z-score, Min-Max ì •ê·œí™”)
    create_hdmap_datasets()