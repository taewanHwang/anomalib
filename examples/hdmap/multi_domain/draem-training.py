#!/usr/bin/env python3
"""HDMAP ë‹¤ì¤‘ ë„ë©”ì¸ DRAEM ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ ìŠ¤í¬ë¦½íŠ¸.

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” HDMAP ë°ì´í„°ì…‹ì—ì„œ DRAEM ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ë‹¤ì¤‘ ë„ë©”ì¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- DRAEM ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ìƒ íƒì§€
- ì†ŒìŠ¤ ë„ë©”ì¸(domain_A)ì—ì„œ í›ˆë ¨
- íƒ€ê²Ÿ ë„ë©”ì¸ë“¤(domain_B, C, D)ì—ì„œ í‰ê°€
- ì‹¤í—˜ ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
- JSON ê¸°ë°˜ ì‹¤í—˜ ì¡°ê±´ ê´€ë¦¬

ì‚¬ìš©ë²•:
    python multi_domain_hdmap_draem_training.py --experiment_name "DRAEM_quick_3epochs"
    python multi_domain_hdmap_draem_training.py --experiment_name "DRAEM_baseline_50epochs" --log_level DEBUG

ì‹¤í—˜ ì¡°ê±´:
    ëª¨ë“  ì‹¤í—˜ ì¡°ê±´ì€ multi_domain_hdmap_draem-exp_condition.json íŒŒì¼ì—ì„œ ê´€ë¦¬ë©ë‹ˆë‹¤.
    ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•´ì„œëŠ” multi_domain_hdmap_draem-run.sh ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

"""

import argparse
import logging
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict, Any

from anomalib.models.image.draem import Draem
from anomalib.data.datamodules.image.multi_domain_hdmap import MultiDomainHDMAPDataModule
from anomalib.engine import Engine
from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint
from pytorch_lightning.loggers import TensorBoardLogger

# Experiment utilities import
# ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ import - ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ import
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), ".."))
from experiment_utils import (
    setup_warnings_filter,
    setup_experiment_logging,
    cleanup_gpu_memory,
    create_multi_domain_datamodule,
    evaluate_source_domain,
    evaluate_target_domains,
    extract_training_info,
    create_experiment_visualization,
    organize_source_domain_results,
    save_experiment_results,
    analyze_multi_experiment_results,
    load_experiment_conditions,
    analyze_experiment_results,
    extract_target_domains_from_config,
    create_common_experiment_result
)

# ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™” (DraemSevNetê³¼ ë™ì¼)
setup_warnings_filter()
logging.getLogger("anomalib.visualization.image.item_visualizer").setLevel(logging.ERROR)
logging.getLogger("anomalib.visualization").setLevel(logging.ERROR)
logging.getLogger("anomalib.callbacks").setLevel(logging.ERROR)
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="lightning")



# JSON íŒŒì¼ì—ì„œ ì‹¤í—˜ ì¡°ê±´ ë¡œë“œ
EXPERIMENT_CONDITIONS = load_experiment_conditions("multi_domain_hdmap_draem-exp_condition.json")


def train_draem_model_multi_domain(
    datamodule: MultiDomainHDMAPDataModule, 
    config: Dict[str, Any],
    results_base_dir: str,
    logger: logging.Logger
) -> tuple[Draem, Engine, str]:
    """DRAEM ëª¨ë¸ í›ˆë ¨ ìˆ˜í–‰.
    
    Args:
        datamodule: ì„¤ì •ëœ MultiDomainHDMAPDataModule
        config: í›ˆë ¨ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        results_base_dir: ê²°ê³¼ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ
        logger: ë¡œê±° ê°ì²´
        
    Returns:
        tuple: (í›ˆë ¨ëœ ëª¨ë¸, Engine ê°ì²´, ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ)
    """
    print(f"\nğŸš€ DRAEM ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    logger.info("ğŸš€ DRAEM ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    
    # DRAEM ëª¨ë¸ ì´ˆê¸°í™”
    model = Draem()
    
    # Configì—ì„œ ì§€ì›ë˜ëŠ” íŒŒë¼ë¯¸í„°ë“¤ì„ ëª¨ë¸ì— ë™ì ìœ¼ë¡œ ì„¤ì •
    if hasattr(model, '_config'):
        model._config = config
    else:
        # configë¥¼ ëª¨ë¸ì— ì €ì¥í•˜ì—¬ configure_optimizersì—ì„œ ì‚¬ìš©
        setattr(model, '_training_config', config)
    
    print(f"   âœ… DRAEM ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    print(f"   ğŸ”§ Config ì„¤ì •:")
    print(f"      â€¢ ì˜µí‹°ë§ˆì´ì €: {config['optimizer'].upper()}")
    print(f"      â€¢ í•™ìŠµë¥ : {config['learning_rate']}")
    print(f"      â€¢ Weight Decay: {config['weight_decay']}")
    if 'scheduler' in config:
        print(f"      â€¢ ìŠ¤ì¼€ì¤„ëŸ¬: {config['scheduler']}")
    logger.info("âœ… DRAEM ëª¨ë¸ ìƒì„± ì™„ë£Œ (validation loss í¬í•¨)")
    logger.info(f"ğŸ”§ Config ì„¤ì •: optimizer={config['optimizer']}, lr={config['learning_rate']}, weight_decay={config['weight_decay']}")
    
    # Early stoppingê³¼ model checkpoint ì„¤ì • (val_image_AUROC ê¸°ë°˜)
    early_stopping = EarlyStopping(
        monitor="val_image_AUROC",
        patience=config["early_stopping_patience"],
        mode="max",  # AUROCëŠ” ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
        verbose=True
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì •
    checkpoint_callback = ModelCheckpoint(
        filename=f"draem_multi_domain_{datamodule.source_domain}_" + "{epoch:02d}_{val_image_AUROC:.4f}",
        monitor="val_image_AUROC",
        mode="max",  # AUROCëŠ” ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
        save_top_k=1,
        verbose=True
    )
    
    print(f"   ğŸ“Š Early Stopping: patience={config['early_stopping_patience']}, monitor=val_image_AUROC (max)")
    print(f"   ğŸ’¾ Model Checkpoint: monitor=val_image_AUROC (max), save_top_k=1")
    logger.info(f"ğŸ“Š Early Stopping ì„¤ì •: patience={config['early_stopping_patience']}, monitor=val_image_AUROC")
    logger.info(f"ğŸ’¾ Model Checkpoint ì„¤ì •: monitor=val_image_AUROC")
    
    # TensorBoard ë¡œê±° ì„¤ì • (DraemSevNetê³¼ ë™ì¼)
    tb_logger = TensorBoardLogger(
        save_dir=results_base_dir,
        name="tensorboard_logs",
        version=""  # ë¹ˆ ë²„ì „ìœ¼ë¡œ version_x í´ë” ë°©ì§€
    )
    
    # Engine ìƒì„± ë° í›ˆë ¨
    engine_kwargs = {
        "accelerator": "gpu" if torch.cuda.is_available() else "cpu",
        "devices": [0] if torch.cuda.is_available() else 1,
        "logger": tb_logger,
        "max_epochs": config["max_epochs"],
        "callbacks": [early_stopping, checkpoint_callback],
        "check_val_every_n_epoch": 1,
        "enable_checkpointing": True,
        "log_every_n_steps": 10,
        "enable_model_summary": True,
        "num_sanity_val_steps": 0,
        "default_root_dir": results_base_dir
    }
    
    # gradient_clip_val ì„¤ì • (configì—ì„œ ì œê³µë˜ë©´)
    if "gradient_clip_val" in config and config["gradient_clip_val"] is not None:
        engine_kwargs["gradient_clip_val"] = config["gradient_clip_val"]
        print(f"   ğŸ”§ Gradient Clipping ì„¤ì •: {config['gradient_clip_val']}")
        logger.info(f"ğŸ”§ Gradient Clipping ì„¤ì •: {config['gradient_clip_val']}")
    
    engine = Engine(**engine_kwargs)
    
    print(f"   ğŸ”§ Engine ì„¤ì • ì™„ë£Œ - max_epochs: {config['max_epochs']}")
    print(f"   ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {results_base_dir}")
    logger.info(f"ğŸ”§ Engine ì„¤ì • ì™„ë£Œ - max_epochs: {config['max_epochs']}")
    logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {results_base_dir}")
    
    # ëª¨ë¸ í›ˆë ¨
    print(f"   ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    logger.info("ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    
    engine.fit(
        model=model,
        datamodule=datamodule
    )
    
    print(f"   âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    logger.info("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    
    # ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ í™•ì¸
    best_checkpoint = checkpoint_callback.best_model_path
    print(f"   ğŸ† Best Checkpoint: {best_checkpoint}")
    logger.info(f"ğŸ† Best Checkpoint: {best_checkpoint}")
    
    # ì‹¤ì œ ìƒì„±ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì¶”ì¶œ
    if hasattr(engine.trainer, 'default_root_dir'):
        actual_results_dir = engine.trainer.default_root_dir
        print(f"   ğŸ“‚ ì‹¤ì œ ê²°ê³¼ ë””ë ‰í† ë¦¬: {actual_results_dir}")
        logger.info(f"ğŸ“‚ ì‹¤ì œ ê²°ê³¼ ë””ë ‰í† ë¦¬: {actual_results_dir}")
    else:
        actual_results_dir = results_base_dir
    
    return model, engine, best_checkpoint





def run_single_draem_experiment(
    condition: Dict[str, Any],
    dataset_root: str = None,
    results_base_dir: str = "./results",
    logger: logging.Logger = None
) -> Dict[str, Any]:
    """ë‹¨ì¼ DRAEM ì‹¤í—˜ ìˆ˜í–‰.
    
    Args:
        condition: ì‹¤í—˜ ì¡°ê±´ ë”•ì…”ë„ˆë¦¬
        dataset_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
        results_base_dir: ê²°ê³¼ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ
        logger: ë¡œê±° ê°ì²´
        
    Returns:
        Dict[str, Any]: ì‹¤í—˜ ê²°ê³¼
    """
    # configì—ì„œ ë„ë©”ì¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    config = condition["config"]
    source_domain = config["source_domain"]
    target_domains = extract_target_domains_from_config(config)
    
    experiment_name = condition["name"]
    
    print(f"\n{'='*80}")
    print(f"ğŸ§ª DRAEM ì‹¤í—˜ ì‹œì‘: {experiment_name}")
    print(f"{'='*80}")
    
    if logger:
        logger.info(f"ğŸ§ª DRAEM ì‹¤í—˜ ì‹œì‘: {experiment_name}")
        logger.info(f"ì‹¤í—˜ ì„¤ì •: {config}")
    
    try:
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        cleanup_gpu_memory()
        
        # ê° ì‹¤í—˜ë§ˆë‹¤ ê³ ìœ í•œ results ê²½ë¡œ ìƒì„± (DraemSevNetê³¼ ë™ì¼í•œ êµ¬ì¡°)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        experiment_folder = f"{condition['name']}_{timestamp}"
        experiment_dir = Path(results_base_dir) / "MultiDomainHDMAP" / "draem" / experiment_folder
        experiment_dir.mkdir(parents=True, exist_ok=True)
        
        # ì‹¤í—˜ ì´ë¦„ ìƒì„± (DraemSevNetê³¼ ë™ì¼í•˜ê²Œ)
        experiment_name = f"{source_domain}"
        
        print(f"ğŸ“ ì‹¤í—˜ ë””ë ‰í† ë¦¬: {experiment_dir}")
        if logger:
            logger.info(f"ğŸ“ ì‹¤í—˜ ë””ë ‰í† ë¦¬: {experiment_dir}")
        
        # DataModule ìƒì„±
        datamodule = create_multi_domain_datamodule(
            datamodule_class=MultiDomainHDMAPDataModule,
            source_domain=source_domain,
            target_domains=target_domains,
            batch_size=config["batch_size"],
            image_size=config["image_size"],
            dataset_root=dataset_root
        )
        
        # ëª¨ë¸ í›ˆë ¨
        model, engine, best_checkpoint = train_draem_model_multi_domain(
            datamodule=datamodule,
            config=config,
            results_base_dir=str(experiment_dir),
            logger=logger or logging.getLogger(__name__)
        )
        
        # TensorBoardLogger ê²½ë¡œ í™•ì¸
        try:
            if hasattr(engine.trainer, 'logger') and hasattr(engine.trainer.logger, 'log_dir'):
                latest_version_path = Path(engine.trainer.logger.log_dir)
                print(f"   ğŸ“‚ Trainer log_dir: {latest_version_path}")
            else:
                latest_version_path = Path(str(experiment_dir))
                print(f"   ğŸ“‚ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©: {latest_version_path}")
            
            # ì´ë¯¸ì§€ ê²½ë¡œëŠ” í‰ê°€ í›„ì— ìƒì„±ë˜ë¯€ë¡œ ì¼ë‹¨ Noneìœ¼ë¡œ ì„¤ì •
            anomalib_results_path = None
                
        except Exception as e:
            print(f"   âš ï¸ Warning: ë¡œê·¸ ê²½ë¡œ ì„¤ì • ì‹¤íŒ¨: {e}")
            latest_version_path = Path(str(experiment_dir))
            anomalib_results_path = None
        
        # ì‹œê°í™” í´ë” ìƒì„± (ì‹¤ì œ ê²°ê³¼ ê²½ë¡œ ì‚¬ìš©)
        viz_path = create_experiment_visualization(
            experiment_name=experiment_name,
            model_type="DRAEM",
            results_base_dir=str(latest_version_path),  # TensorBoard ë¡œê·¸ ê²½ë¡œ ì‚¬ìš©
            source_domain=source_domain,
            target_domains=target_domains
        )
        
        # Source Domain í‰ê°€
        print(f"\nğŸ“Š Source Domain í‰ê°€ ì‹œì‘")
        if logger:
            logger.info("ğŸ“Š Source Domain í‰ê°€ ì‹œì‘")
        
        engine_for_eval = Engine(default_root_dir=str(latest_version_path))
        source_results = evaluate_source_domain(
            model=model,
            engine=engine_for_eval,
            datamodule=datamodule,
            checkpoint_path=best_checkpoint
        )
        
        # Source Domain ê²°ê³¼ ì •ë¦¬
        organize_source_domain_results(
            sevnet_viz_path=viz_path,
            results_base_dir=str(latest_version_path),
            source_domain=source_domain
        )
        
        # Source Domain í‰ê°€ í›„ ì´ë¯¸ì§€ ê²½ë¡œ íƒìƒ‰
        try:
            print(f"   ğŸ” Source Domain í‰ê°€ í›„ ì´ë¯¸ì§€ ê²½ë¡œ íƒìƒ‰...")
            anomalib_image_paths = []
            
            # DRAEM ì´ë¯¸ì§€ ê²½ë¡œ íŒ¨í„´ ê²€ìƒ‰ (tensorboard_logs ê¸°ì¤€)
            patterns = [
                "**/Draem/latest/images"  # ì‹¤ì œ ìƒì„±ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œ
            ]
            for pattern in patterns:
                found_paths = list(latest_version_path.parent.glob(pattern))
                anomalib_image_paths.extend(found_paths)
            
            # ì¤‘ë³µ ì œê±°
            anomalib_image_paths = list(set(anomalib_image_paths))
            print(f"   ğŸ“‚ ë°œê²¬ëœ ì´ë¯¸ì§€ ê²½ë¡œë“¤: {[str(p) for p in anomalib_image_paths]}")
            
            # ê°€ì¥ ìµœì‹  ì´ë¯¸ì§€ ê²½ë¡œ ì„ íƒ
            if anomalib_image_paths:
                latest_image_path = max(anomalib_image_paths, key=lambda p: p.stat().st_mtime if p.exists() else 0)
                anomalib_results_path = latest_image_path.parent  # images í´ë”ì˜ ë¶€ëª¨
                print(f"   âœ… ì‹¤ì œ Anomalib ê²°ê³¼ ê²½ë¡œ: {anomalib_results_path}")
            else:
                print(f"   âš ï¸ Warning: í‰ê°€ í›„ì—ë„ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                anomalib_results_path = None
                
        except Exception as e:
            print(f"   âš ï¸ Warning: í‰ê°€ í›„ ì´ë¯¸ì§€ ê²½ë¡œ íƒìƒ‰ ì‹¤íŒ¨: {e}")
            anomalib_results_path = None
        
        # Target Domains í‰ê°€
        print(f"\nğŸ¯ Target Domains í‰ê°€ ì‹œì‘")
        if logger:
            logger.info("ğŸ¯ Target Domains í‰ê°€ ì‹œì‘")
        
        target_results = evaluate_target_domains(
            model=model,
            engine=engine_for_eval,
            datamodule=datamodule,
            checkpoint_path=best_checkpoint,
            results_base_dir=str(anomalib_results_path) if anomalib_results_path else str(latest_version_path),
            save_samples=True,  # Target Domain ì´ë¯¸ì§€ ë³µì‚¬ í™œì„±í™”
            current_version_path=str(latest_version_path) if latest_version_path else None  # ì‹œê°í™” í´ë”ëŠ” TensorBoard ê²½ë¡œ
        )
        
        # í›ˆë ¨ ì •ë³´ ì¶”ì¶œ
        training_info = extract_training_info(engine)
        
        # ê²°ê³¼ ë¶„ì„
        analysis = analyze_experiment_results(
            source_results=source_results,
            target_results=target_results,
            training_info=training_info,
            condition=condition,
            model_type="DRAEM"
        )
        
        # ì‹¤í—˜ ê²°ê³¼ ì •ë¦¬ (ê³µí†µ í•¨ìˆ˜ í™œìš©)
        experiment_result = create_common_experiment_result(
            condition=condition,
            status="success",
            experiment_path=str(latest_version_path),
            source_results=source_results,
            target_results=target_results,
            training_info=training_info,
            best_checkpoint=best_checkpoint
        )
        
        # ê²°ê³¼ ì €ì¥ (ê³µí†µ í•¨ìˆ˜ í™œìš©)
        result_filename = f"result_{condition['name']}_{timestamp}.json"
        save_experiment_results(
            result=experiment_result,
            result_filename=result_filename,
            log_dir=latest_version_path,
            logger=logger or logging.getLogger(__name__),
            model_type="DRAEM"
        )
        
        print(f"\nâœ… ì‹¤í—˜ ì™„ë£Œ: {experiment_name}")
        if logger:
            logger.info(f"âœ… ì‹¤í—˜ ì™„ë£Œ: {experiment_name}")
        
        return experiment_result
        
    except Exception as e:
        error_msg = f"ì‹¤í—˜ ì‹¤íŒ¨: {e}"
        print(f"\nâŒ {error_msg}")
        if logger:
            logger.error(f"âŒ {error_msg}")
        
        return create_common_experiment_result(
            condition=condition,
            status="failed",
            error=str(e)
        )


def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì‹¤í—˜ ì„¤ì • ë° ì‹¤í–‰."""
    parser = argparse.ArgumentParser(description="HDMAP ë‹¤ì¤‘ ë„ë©”ì¸ DRAEM ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--experiment_name", type=str, required=True, help="ì‹¤í—˜ ì¡°ê±´ ì´ë¦„ (JSON íŒŒì¼ì— ì •ì˜ëœ)")
    parser.add_argument("--results_dir", type=str, default="./results", help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--log_level", type=str, default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"], help="ë¡œê·¸ ë ˆë²¨")
    
    args = parser.parse_args()
    
    # ê²½ê³  í•„í„°ë§ ì„¤ì •
    setup_warnings_filter()
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„± (results_dir ë‚´ë¶€ì—)
    results_dir = Path(args.results_dir)
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # ë¡œê±° ì„¤ì • (DraemSevNetê³¼ ë™ì¼í•˜ê²Œ ê³ ì •ëœ ë¡œê·¸ íŒŒì¼ëª… ì‚¬ìš©)
    import re
    # results_dirì—ì„œ timestamp ì¶”ì¶œ (ì˜ˆ: results/draem/20250817_120156)
    dir_parts = str(results_dir).split('/')
    run_timestamp = None
    for part in dir_parts:
        if re.match(r'\d{8}_\d{6}', part):  # 20250817_120156 íŒ¨í„´
            run_timestamp = part
            break
    
    if not run_timestamp:
        # ì§ì ‘ ì‹¤í–‰ëœ ê²½ìš°: ìƒˆë¡œìš´ timestamp ìƒì„±
        run_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    log_file = results_dir / f"draem_experiment_{run_timestamp}.log"
    logger = setup_experiment_logging(str(log_file), "draem_experiment")
    logger.setLevel(getattr(logging, args.log_level))
    
    print(f"\nğŸš€ HDMAP ë‹¤ì¤‘ ë„ë©”ì¸ DRAEM ì‹¤í—˜ ì‹œì‘")
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ ë¡œê·¸ íŒŒì¼: {log_file}")
    
    logger.info("ğŸš€ HDMAP ë‹¤ì¤‘ ë„ë©”ì¸ DRAEM ì‹¤í—˜ ì‹œì‘")
    logger.info(f"ëª…ë ¹í–‰ ì¸ìˆ˜: {vars(args)}")
    
    all_results = []
    
    try:
        # JSON íŒŒì¼ì—ì„œ ì‹¤í—˜ ì¡°ê±´ ì°¾ê¸°
        condition = None
        for c in EXPERIMENT_CONDITIONS:
            if c["name"] == args.experiment_name:
                condition = c
                break
        
        if not condition:
            print(f"âŒ ì‹¤í—˜ ì¡°ê±´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.experiment_name}")
            print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í—˜ ì¡°ê±´ë“¤:")
            for c in EXPERIMENT_CONDITIONS:
                print(f"   - {c['name']}: {c['description']}")
            logger.error(f"ì‹¤í—˜ ì¡°ê±´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {args.experiment_name}")
            return
        
        print(f"\nğŸ¯ ì‹¤í—˜ ì‹¤í–‰: {condition['name']}")
        print(f"ğŸ“„ ì„¤ëª…: {condition['description']}")
        logger.info(f"ğŸ¯ ì‹¤í—˜ ì‹¤í–‰: {condition['name']}")
        
        result = run_single_draem_experiment(
            condition=condition,
            dataset_root=None,  # JSON ì„¤ì • ì‚¬ìš©
            results_base_dir=args.results_dir,
            logger=logger
        )
        
        all_results.append(result)
        
        print(f"\nğŸ‰ ì‹¤í—˜ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {args.results_dir}")
        print(f"ğŸ“ ë¡œê·¸ íŒŒì¼: {log_file}")
        
        if result.get("status") == "success":
            print(f"âœ… {condition['name']} ì‹¤í—˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print(f"âŒ {condition['name']} ì‹¤í—˜ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        logger.info("ğŸ‰ ì‹¤í—˜ ì™„ë£Œ!")
        logger.info(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {args.results_dir}")
        
    except Exception as e:
        error_msg = f"ì‹¤í—˜ ë„ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        print(f"\nâŒ {error_msg}")
        logger.error(f"âŒ {error_msg}")
        raise


if __name__ == "__main__":
    main()
