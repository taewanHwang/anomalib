#!/usr/bin/env python3
"""Multi-Domain Anomaly Detection í†µí•© í›ˆë ¨ í´ë˜ìŠ¤

ì´ ëª¨ë“ˆì€ multi-domain anomaly detection ì‹¤í—˜ì„ ìœ„í•œ í†µí•© í›ˆë ¨ í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
Single domainê³¼ ë‹¬ë¦¬ source domainì—ì„œ í›ˆë ¨í•˜ê³  multiple target domainsì—ì„œ í‰ê°€í•©ë‹ˆë‹¤.

ì£¼ìš” íŠ¹ì§•:
- MultiDomainHDMAPDataModule ì‚¬ìš©
- Source domain testê°€ validation ì—­í• 
- Target domains testê°€ í‰ê°€ ëŒ€ìƒ
- Source/Target ì‹œê°í™” í´ë” ë¶„ë¦¬
"""

import os
import json
import logging
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List
from pytorch_lightning.loggers import TensorBoardLogger

# Anomalib imports
from anomalib.models.image.draem import Draem
from anomalib.models.image.dinomaly import Dinomaly
from anomalib.models.image.patchcore import Patchcore
from anomalib.models.image.draem_sevnet import DraemSevNet
from anomalib.data.datamodules.image.multi_domain_hdmap import MultiDomainHDMAPDataModule
from anomalib.engine import Engine
from anomalib.metrics import AUROC, Evaluator
from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint

# Experiment utilities import
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), ".."))
from experiment_utils import (
    setup_warnings_filter,
    cleanup_gpu_memory,
    create_multi_domain_datamodule,
    evaluate_source_domain,
    evaluate_target_domains,
    extract_training_info,
    organize_source_domain_results,
    save_experiment_results,
    create_common_experiment_result,
    analyze_experiment_results
)


class MultiDomainAnomalyTrainer:
    """Multi-Domain Anomaly Detection ì „ìš© í›ˆë ¨ í´ë˜ìŠ¤"""
    
    def __init__(self, config: Dict[str, Any], experiment_name: str, session_timestamp: str, experiment_dir: str):
        """
        Args:
            config: ì‹¤í—˜ ì„¤ì • ë”•ì…”ë„ˆë¦¬ (model_type, source_domain, target_domains í¬í•¨)
            experiment_name: ì‹¤í—˜ ì´ë¦„
            session_timestamp: ì„¸ì…˜ timestamp
            experiment_dir: ì‹¤í—˜ ë””ë ‰í„°ë¦¬ ê²½ë¡œ
        """
        self.config = config
        self.experiment_name = experiment_name
        self.session_timestamp = session_timestamp
        self.experiment_dir = Path(experiment_dir)
        
        # Multi-domain ì„¤ì • ì¶”ì¶œ
        self.model_type = config["model_type"].lower()
        self.source_domain = config["source_domain"]
        self.target_domains = config["target_domains"]
        
        # ê²°ê³¼ ì €ì¥ ê²½ë¡œ ì„¤ì • (single domainê³¼ ë™ì¼í•œ êµ¬ì¡°)
        self.results_dir = self.experiment_dir
        
        # ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger(f"multi_domain_{self.model_type}")
        
    def create_model(self):
        """Factory patternìœ¼ë¡œ ëª¨ë¸ ìƒì„± (multi-domain ìµœì í™”)"""
        if self.model_type == "draem":
            return self._create_draem_model()
        elif self.model_type == "dinomaly":
            return self._create_dinomaly_model()
        elif self.model_type == "patchcore":
            return self._create_patchcore_model()
        elif self.model_type == "draem_sevnet":
            return self._create_draem_sevnet_model()
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {self.model_type}")
    
    def _create_draem_model(self):
        """DRAEM ëª¨ë¸ ìƒì„± (multi-domain í‰ê°€ìš©)"""
        # Multi-domain í‰ê°€ë¥¼ ìœ„í•œ ë©”íŠ¸ë¦­ ì„¤ì •
        val_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="val_image_")
        test_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="test_image_")
        evaluator = Evaluator(val_metrics=[val_auroc], test_metrics=[test_auroc])
        
        model = Draem(evaluator=evaluator)
        
        # Configë¥¼ ëª¨ë¸ì— ì €ì¥ (optimizer ì„¤ì •ìš©)
        if hasattr(model, '_config'):
            model._config = self.config
        else:
            setattr(model, '_training_config', self.config)
            
        return model
    
    def _create_dinomaly_model(self):
        """Dinomaly ëª¨ë¸ ìƒì„± (multi-domain í‰ê°€ìš©)"""
        # Configì—ì„œ Dinomaly íŠ¹í™” ì„¤ì • ì¶”ì¶œ
        encoder_name = self.config["encoder_name"]
        target_layers = self.config["target_layers"]
        remove_class_token = self.config["remove_class_token"]
        
        # Multi-domain í‰ê°€ë¥¼ ìœ„í•œ ë©”íŠ¸ë¦­ ì„¤ì •
        val_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="val_image_")
        test_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="test_image_")
        evaluator = Evaluator(val_metrics=[val_auroc], test_metrics=[test_auroc])
        
        model = Dinomaly(
            encoder_name=encoder_name,
            target_layers=target_layers,
            remove_class_token=remove_class_token,
            evaluator=evaluator
        )
        
        # Config ì €ì¥
        setattr(model, '_training_config', self.config)
        return model
    
    def _create_patchcore_model(self):
        """PatchCore ëª¨ë¸ ìƒì„± (multi-domain í‰ê°€ìš©)"""
        # Configì—ì„œ PatchCore ì„¤ì • ì¶”ì¶œ
        backbone = self.config["backbone"]
        layers = self.config["layers"]
        coreset_sampling_ratio = self.config["coreset_sampling_ratio"]
        num_neighbors = self.config["num_neighbors"]
        
        # Multi-domain í‰ê°€ë¥¼ ìœ„í•œ ë©”íŠ¸ë¦­ ì„¤ì •  
        val_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="val_image_")
        test_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="test_image_")
        evaluator = Evaluator(val_metrics=[val_auroc], test_metrics=[test_auroc])
        
        model = Patchcore(
            backbone=backbone,
            layers=layers,
            coreset_sampling_ratio=coreset_sampling_ratio,
            num_neighbors=num_neighbors,
            evaluator=evaluator
        )
        
        # Config ì €ì¥
        setattr(model, '_training_config', self.config)
        return model
    
    def _create_draem_sevnet_model(self):
        """DRAEM-SevNet ëª¨ë¸ ìƒì„± (multi-domain í‰ê°€ìš©)"""
        # Configì—ì„œ DRAEM-SevNet ì„¤ì • ì¶”ì¶œ
        score_combination = self.config["score_combination"]
        severity_loss_type = self.config["severity_loss_type"]
        severity_head_pooling_type = self.config["severity_head_pooling_type"]
        severity_weight = self.config["severity_weight"]
        
        # Multi-domain í‰ê°€ë¥¼ ìœ„í•œ ë©”íŠ¸ë¦­ ì„¤ì •
        val_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="val_image_")
        test_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="test_image_")
        evaluator = Evaluator(val_metrics=[val_auroc], test_metrics=[test_auroc])
        
        model = DraemSevNet(
            score_combination=score_combination,
            severity_loss_type=severity_loss_type,
            severity_head_pooling_type=severity_head_pooling_type,
            severity_weight=severity_weight,
            evaluator=evaluator
        )
        
        # Config ì €ì¥
        setattr(model, '_training_config', self.config)
        return model
    
    def create_datamodule(self):
        """MultiDomainHDMAPDataModule ìƒì„±"""
        return create_multi_domain_datamodule(
            datamodule_class=MultiDomainHDMAPDataModule,
            source_domain=self.source_domain,
            target_domains=self.target_domains,
            batch_size=self.config["batch_size"],
            image_size=self.config["image_size"],
            num_workers=self.config["num_workers"],
            validation_strategy="source_test"  # Source testê°€ validation ì—­í• 
        )
    
    def train_model(self, model, datamodule) -> tuple:
        """ëª¨ë¸ í›ˆë ¨ ìˆ˜í–‰"""
        print(f"\nğŸš€ {self.model_type.upper()} Multi-Domain ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        self.logger.info(f"ğŸš€ {self.model_type.upper()} Multi-Domain ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        
        # Early stopping ì„¤ì • (multi-domainì€ val_image_AUROC ê¸°ë°˜)
        early_stopping = EarlyStopping(
            monitor="val_image_AUROC",
            patience=self.config["early_stopping_patience"],
            mode="max",  # AUROCëŠ” ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
            verbose=True
        )
        
        # Model checkpoint ì„¤ì •
        checkpoint_callback = ModelCheckpoint(
            filename=f"{self.model_type}_multi_domain_{self.source_domain}_to_targets_" + "{epoch:02d}_{val_image_AUROC:.4f}",
            monitor="val_image_AUROC",
            mode="max",
            save_top_k=1,
            verbose=True
        )
        
        print(f"   ğŸ“Š Early Stopping: patience={self.config['early_stopping_patience']}, monitor=val_image_AUROC (max)")
        print(f"   ğŸ’¾ Model Checkpoint: monitor=val_image_AUROC (max), save_top_k=1")
        
        # TensorBoard ë¡œê±° ì„¤ì •
        tb_logger = TensorBoardLogger(
            save_dir=str(self.results_dir),
            name="tensorboard_logs", 
            version=""
        )
        
        # Engine ì„¤ì • (PatchCore íŠ¹ìˆ˜ ì²˜ë¦¬)
        max_epochs = self.config["max_epochs"]
        
        engine_kwargs = {
            "accelerator": "gpu" if torch.cuda.is_available() else "cpu",
            "devices": [0] if torch.cuda.is_available() else 1,
            "logger": tb_logger,
            "max_epochs": max_epochs,
            "callbacks": [early_stopping, checkpoint_callback],
            "check_val_every_n_epoch": 1,
            "enable_checkpointing": True,
            "log_every_n_steps": 10,
            "enable_model_summary": True,
            "num_sanity_val_steps": 0,
            "default_root_dir": str(self.results_dir)
        }
        
        # Gradient clipping ì„¤ì •
        if "gradient_clip_val" in self.config and self.config["gradient_clip_val"] is not None:
            engine_kwargs["gradient_clip_val"] = self.config["gradient_clip_val"]
            print(f"   ğŸ”§ Gradient Clipping ì„¤ì •: {self.config['gradient_clip_val']}")
        
        engine = Engine(**engine_kwargs)
        
        print(f"   ğŸ”§ Engine ì„¤ì • ì™„ë£Œ - max_epochs: {max_epochs}")
        print(f"   ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {self.results_dir}")
        self.logger.info(f"ğŸ”§ Engine ì„¤ì • ì™„ë£Œ - max_epochs: {max_epochs}")
        
        # ëª¨ë¸ í›ˆë ¨ ì‹œì‘
        print(f"   ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        self.logger.info("ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        if self.model_type == "patchcore":
            # PatchCoreëŠ” fitì´ ì•„ë‹Œ memory bank êµ¬ì¶•
            engine.fit(model=model, datamodule=datamodule)
        else:
            # ì¼ë°˜ í›ˆë ¨ ëª¨ë¸
            engine.fit(model=model, datamodule=datamodule)
        
        print(f"   âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        self.logger.info("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        
        # ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ í™•ì¸
        best_checkpoint = checkpoint_callback.best_model_path
        print(f"   ğŸ† Best Checkpoint: {best_checkpoint}")
        self.logger.info(f"ğŸ† Best Checkpoint: {best_checkpoint}")
        
        return model, engine, best_checkpoint
    
    def run_multi_domain_evaluation(self, model, engine, datamodule, best_checkpoint):
        """Multi-domain í‰ê°€ ìˆ˜í–‰ (source + targets)"""
        print(f"\nğŸ“Š Multi-Domain í‰ê°€ ì‹œì‘")
        self.logger.info("ğŸ“Š Multi-Domain í‰ê°€ ì‹œì‘")
        
        # 1. Source Domain í‰ê°€ (validation ì—­í• )
        print(f"ğŸ“Š Source Domain ({self.source_domain}) í‰ê°€ ì‹œì‘")
        self.logger.info(f"ğŸ“Š Source Domain ({self.source_domain}) í‰ê°€ ì‹œì‘")
        
        source_results = evaluate_source_domain(
            model=model,
            engine=engine,
            datamodule=datamodule,
            checkpoint_path=best_checkpoint
        )
        
        # 2. Target Domains í‰ê°€ (test ì—­í• )
        print(f"\nğŸ¯ Target Domains {self.target_domains} í‰ê°€ ì‹œì‘")
        self.logger.info(f"ğŸ¯ Target Domains {self.target_domains} í‰ê°€ ì‹œì‘")
        
        # TensorBoard ë¡œê·¸ ê²½ë¡œ í™•ì¸
        try:
            if hasattr(engine.trainer, 'logger') and hasattr(engine.trainer.logger, 'log_dir'):
                tensorboard_path = Path(engine.trainer.logger.log_dir)
            else:
                tensorboard_path = self.results_dir / "tensorboard_logs"
        except:
            tensorboard_path = self.results_dir / "tensorboard_logs"
        
        target_results = evaluate_target_domains(
            model=model,
            engine=engine,
            datamodule=datamodule,
            checkpoint_path=best_checkpoint,
            results_base_dir=str(tensorboard_path),
            target_domains=self.target_domains,
            save_samples=True,
            current_version_path=str(tensorboard_path)
        )
        
        # 3. Source/Target ì‹œê°í™” ê²°ê³¼ ì •ë¦¬
        try:
            # Source domain ê²°ê³¼ ì •ë¦¬
            organize_source_domain_results(
                sevnet_viz_path=str(tensorboard_path),
                results_base_dir=str(tensorboard_path),
                source_domain=self.source_domain
            )
            print(f"   âœ… Source domain ì‹œê°í™” ê²°ê³¼ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ Source domain ì‹œê°í™” ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return source_results, target_results
    
    def run_experiment(self) -> Dict[str, Any]:
        """ì „ì²´ multi-domain ì‹¤í—˜ ì‹¤í–‰"""
        print(f"\n{'='*80}")
        print(f"ğŸ§ª Multi-Domain {self.model_type.upper()} ì‹¤í—˜ ì‹œì‘: {self.experiment_name}")
        print(f"ğŸŒ Source Domain: {self.source_domain}")
        print(f"ğŸ¯ Target Domains: {self.target_domains}")
        print(f"{'='*80}")
        
        self.logger.info(f"ğŸ§ª Multi-Domain {self.model_type.upper()} ì‹¤í—˜ ì‹œì‘: {self.experiment_name}")
        self.logger.info(f"ì‹¤í—˜ ì„¤ì •: {self.config}")
        
        try:
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            cleanup_gpu_memory()
            
            # ì‹¤í—˜ ë””ë ‰í„°ë¦¬ ìƒì„±
            self.experiment_dir.mkdir(parents=True, exist_ok=True)
            
            # ëª¨ë¸ ìƒì„±
            model = self.create_model()
            print(f"âœ… {self.model_type.upper()} ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            
            # DataModule ìƒì„±
            datamodule = self.create_datamodule()
            print(f"âœ… Multi-Domain DataModule ìƒì„± ì™„ë£Œ")
            print(f"   ğŸŒ Source: {self.source_domain}")
            print(f"   ğŸ¯ Targets: {self.target_domains}")
            
            # ëª¨ë¸ í›ˆë ¨
            model, engine, best_checkpoint = self.train_model(model, datamodule)
            
            # Multi-domain í‰ê°€
            source_results, target_results = self.run_multi_domain_evaluation(
                model, engine, datamodule, best_checkpoint
            )
            
            # í›ˆë ¨ ì •ë³´ ì¶”ì¶œ
            training_info = extract_training_info(engine)
            
            # ê²°ê³¼ ë¶„ì„
            analysis = analyze_experiment_results(
                source_results=source_results,
                target_results=target_results,
                training_info=training_info,
                condition={"name": self.experiment_name, "config": self.config},
                model_type=self.model_type.upper()
            )
            
            # ì‹¤í—˜ ê²°ê³¼ ì •ë¦¬
            experiment_result = create_common_experiment_result(
                condition={"name": self.experiment_name, "config": self.config},
                status="success",
                experiment_path=str(self.experiment_dir),
                source_results=source_results,
                target_results=target_results,
                training_info=training_info,
                best_checkpoint=best_checkpoint
            )
            
            # ê²°ê³¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_filename = f"result_{timestamp}.json"
            
            # TensorBoard ë¡œê·¸ ê²½ë¡œ í™•ì¸ í›„ ì €ì¥
            try:
                if hasattr(engine.trainer, 'logger') and hasattr(engine.trainer.logger, 'log_dir'):
                    log_dir = Path(engine.trainer.logger.log_dir)
                else:
                    log_dir = self.experiment_dir / "tensorboard_logs"
            except:
                log_dir = self.experiment_dir / "tensorboard_logs"
            
            save_experiment_results(
                result=experiment_result,
                result_filename=result_filename,
                log_dir=log_dir,
                logger=self.logger,
                model_type=self.model_type.upper()
            )
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            cleanup_gpu_memory()
            
            print(f"\nâœ… Multi-Domain ì‹¤í—˜ ì™„ë£Œ: {self.experiment_name}")
            self.logger.info(f"âœ… Multi-Domain ì‹¤í—˜ ì™„ë£Œ: {self.experiment_name}")
            
            return experiment_result
            
        except Exception as e:
            error_msg = f"Multi-Domain ì‹¤í—˜ ì‹¤íŒ¨: {e}"
            print(f"\nâŒ {error_msg}")
            self.logger.error(f"âŒ {error_msg}")
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (ì‹¤íŒ¨ ì‹œì—ë„)
            cleanup_gpu_memory()
            
            return create_common_experiment_result(
                condition={"name": self.experiment_name, "config": self.config},
                status="failed",
                error=str(e)
            )