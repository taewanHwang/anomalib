# π“‹ MultiDomain HDMAP λ¨λΈλ³„ ν•™μµ μ½”λ“ κµ¬ν„ ν…ν”λ¦Ώ κ°€μ΄λ“λΌμΈ

## π“– κ°μ”

μ΄ λ¬Έμ„λ” HDMAP λ°μ΄ν„°μ…‹μ—μ„ λ‹¤μ–‘ν• Vision Anomaly Detection λ¨λΈλ“¤μ„ μ„ν• **ν†µμΌλ ν•™μµ μ½”λ“ κµ¬ν„ ν…ν”λ¦Ώ**μ„ μ κ³µν•©λ‹λ‹¤. 

κΈ°μ΅΄ DRAEMκ³Ό DRAEM-SevNet κµ¬ν„μ„ κΈ°λ°μΌλ΅ ν•μ—¬, μƒλ΅μ΄ λ¨λΈλ“¤λ„ λ™μΌν• μ‹¤ν— νλ¦„κ³Ό ν‰κ°€ μ²΄κ³„λ¥Ό λ”°λ¥Ό μ μλ„λ΅ μ„¤κ³„λμ—μµλ‹λ‹¤.

---

## π—οΈ κΈ°λ³Έ μ½”λ“ κµ¬μ΅° ν…ν”λ¦Ώ

### π“ νμΌ λ…λ… κ·μΉ™
```
multi_domain_hdmap_{λ¨λΈλ…}-training.py
multi_domain_hdmap_{λ¨λΈλ…}-exp_condition.json
```

**μμ‹:**
- `multi_domain_hdmap_patchcore-training.py`
- `multi_domain_hdmap_padim-training.py`
- `multi_domain_hdmap_reverse_distillation-training.py`

### π“ νμΌ ν—¤λ” ν…ν”λ¦Ώ
```python
#!/usr/bin/env python3
"""MultiDomain HDMAP {λ¨λΈλ…} λ„λ©”μΈ μ „μ΄ ν•™μµ μμ‹.

{λ¨λΈλ…} λ¨λΈκ³Ό MultiDomainHDMAPDataModuleμ„ ν™μ©ν• ν¨μ¨μ μΈ λ„λ©”μΈ μ „μ΄ ν•™μµ μ‹¤ν— μ¤ν¬λ¦½νΈμ…λ‹λ‹¤.

{λ¨λΈλ…} νΉμ§•:
- [λ¨λΈλ³„ ν•µμ‹¬ νΉμ§• 1]
- [λ¨λΈλ³„ ν•µμ‹¬ νΉμ§• 2]
- [λ¨λΈλ³„ ν•µμ‹¬ νΉμ§• 3]
- [λ¨λΈλ³„ νΉν™” κΈ°λ¥λ“¤]

μ‹¤ν— κµ¬μ΅°:
1. MultiDomainHDMAPDataModule μ„¤μ • (e.g. source: domain_A, targets: domain_B,C,D)
2. Source Domainμ—μ„ {λ¨λΈλ…} λ¨λΈ ν›λ ¨ (train λ°μ΄ν„°)
3. Source Domainμ—μ„ μ„±λ¥ ν‰κ°€ (validationμΌλ΅ μ‚¬μ©λ  test λ°μ΄ν„°)
4. Target Domainsμ—μ„ λ™μ‹ μ„±λ¥ ν‰κ°€ (κ° λ„λ©”μΈλ³„ test λ°μ΄ν„°)
5. λ„λ©”μΈ μ „μ΄ ν¨κ³Ό μΆ…ν•© λ¶„μ„

μ£Όμ” κ°μ„ μ  ({λ¨λΈλ…} vs κΈ°μ¤€ λ¨λΈ):
- [μ„±λ¥ κ°μ„ μ  1]
- [μ„±λ¥ κ°μ„ μ  2]

NOTE:
- μ‹¤ν— μ΅°κ±΄λ“¤μ€ multi_domain_hdmap_{λ¨λΈλ…}_exp_condition.json νμΌμ—μ„ κ΄€λ¦¬λ©λ‹λ‹¤.
- μ½”λ“ μ μ§€λ³΄μμ„±μ„ μ„ν•΄ μ‹¤ν— μ„¤μ •κ³Ό μ‹¤ν–‰ λ΅μ§μ„ λ¶„λ¦¬ν–μµλ‹λ‹¤.
"""
```

---

## π”§ ν•„μ Import λΈ”λ΅ ν…ν”λ¦Ώ

```python
import os
import json
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict, Any
import logging
import warnings
import argparse

# MultiDomain HDMAP import
from anomalib.data.datamodules.image.multi_domain_hdmap import MultiDomainHDMAPDataModule
from anomalib.models.image.{λ¨λΈλ…} import {λ¨λΈν΄λμ¤λ…}  # λ¨λΈλ³„ μμ •
from anomalib.engine import Engine
from pytorch_lightning.loggers import TensorBoardLogger

# Early Stopping import (λ¨λΈμ΄ ν•™μµμ„ μ”κµ¬ν•λ” κ²½μ°λ§)
from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint

# κ³µν†µ μ ν‹Έλ¦¬ν‹° ν•¨μλ“¤ import
from experiment_utils import (
    cleanup_gpu_memory,
    setup_warnings_filter,
    setup_experiment_logging,
    extract_training_info,
    organize_source_domain_results,
    evaluate_target_domains,
    save_experiment_results,
    create_experiment_visualization,
    create_multi_domain_datamodule,
    evaluate_source_domain,
    load_experiment_conditions,
    analyze_experiment_results,
    extract_target_domains_from_config
)
```

---

## π“ λ¨λΈ ν›λ ¨ ν•¨μ ν…ν”λ¦Ώ

### π― κΈ°λ³Έ ν…ν”λ¦Ώ κµ¬μ΅°

```python
def train_{λ¨λΈλ…}_model_multi_domain(
    datamodule: MultiDomainHDMAPDataModule, 
    config: Dict[str, Any],
    results_base_dir: str,
    logger: logging.Logger
) -> tuple[{λ¨λΈν΄λμ¤λ…}, Engine, str]:
    """
    {λ¨λΈλ…} λ¨λΈ ν›λ ¨ μν–‰.
    
    Args:
        datamodule: μ„¤μ •λ MultiDomainHDMAPDataModule
        config: ν›λ ¨ μ„¤μ • λ”•μ…”λ„λ¦¬
        results_base_dir: κ²°κ³Ό μ €μ¥ κΈ°λ³Έ κ²½λ΅
        logger: λ΅κ±° κ°μ²΄
        
    Returns:
        tuple: (ν›λ ¨λ λ¨λΈ, Engine κ°μ²΄, μ²΄ν¬ν¬μΈνΈ κ²½λ΅)
        
    Note:
        {λ¨λΈλ…} νΉμ§•:
        - [λ¨λΈλ³„ ν•µμ‹¬ νΉμ§•λ“¤ λ‚μ—΄]
    """
    
    print(f"\nπ€ {λ¨λΈλ…} λ¨λΈ ν›λ ¨ μ‹μ‘")
    logger.info("π€ {λ¨λΈλ…} λ¨λΈ ν›λ ¨ μ‹μ‘")
    
    # π― λ¨λΈλ³„ νΉν™” μ„¤μ • μ¶λ ¥
    print(f"   π”§ Config μ„¤μ •:")
    # [λ¨λΈλ³„ μ¤‘μ”ν• config νλΌλ―Έν„°λ“¤ μ¶λ ¥]
    
    logger.info("β… {λ¨λΈλ…} λ¨λΈ μƒμ„± μ™„λ£")
    logger.info(f"π”§ Config μ„¤μ •: [μ£Όμ” μ„¤μ •λ“¤]")
    
    # π― λ¨λΈ μƒμ„± (λ¨λΈλ³„ νΉν™”)
    model = {λ¨λΈν΄λμ¤λ…}(
        # [λ¨λΈλ³„ ν•„μ/μ„ νƒ νλΌλ―Έν„°λ“¤]
    )
    
    # π― μ½λ°± μ„¤μ • (λ¨λΈλ³„ μ΅°κ±΄λ¶€)
    callbacks = []
    
    # [ν•™μµμ΄ ν•„μ”ν• λ¨λΈμ κ²½μ°]
    if {λ¨λΈμ΄_ν•™μµμ„_μ”κµ¬ν•λ”κ°€}:
        early_stopping = EarlyStopping(
            monitor="val_image_AUROC",
            patience=config["early_stopping_patience"],
            mode="max",
            verbose=True
        )
        
        checkpoint_callback = ModelCheckpoint(
            filename=f"{λ¨λΈλ…}_multi_domain_{datamodule.source_domain}_" + "{epoch:02d}_{val_image_AUROC:.4f}",
            monitor="val_image_AUROC",
            mode="max",
            save_top_k=1,
            verbose=True
        )
        
        callbacks.extend([early_stopping, checkpoint_callback])
    
    # π― TensorBoard λ΅κ±° μ„¤μ •
    tb_logger = TensorBoardLogger(
        save_dir=results_base_dir,
        name="tensorboard_logs",
        version=""
    )
    
    # π― Engine μ„¤μ •
    engine_kwargs = {
        "accelerator": "gpu" if torch.cuda.is_available() else "cpu",
        "devices": [0] if torch.cuda.is_available() else 1,
        "logger": tb_logger,
        "callbacks": callbacks,
        "enable_checkpointing": len(callbacks) > 0,
        "log_every_n_steps": 10,
        "enable_model_summary": True,
        "default_root_dir": results_base_dir
    }
    
    # [ν•™μµμ΄ ν•„μ”ν• λ¨λΈμ κ²½μ°λ§]
    if {λ¨λΈμ΄_ν•™μµμ„_μ”κµ¬ν•λ”κ°€}:
        engine_kwargs.update({
            "max_epochs": config["max_epochs"],
            "check_val_every_n_epoch": 1,
            "num_sanity_val_steps": 0
        })
    
    engine = Engine(**engine_kwargs)
    
    print(f"   π”§ Engine μ„¤μ • μ™„λ£")
    print(f"   π“ κ²°κ³Ό μ €μ¥ κ²½λ΅: {results_base_dir}")
    logger.info(f"π”§ Engine μ„¤μ • μ™„λ£")
    logger.info(f"π“ κ²°κ³Ό μ €μ¥ κ²½λ΅: {results_base_dir}")
    
    # π― λ¨λΈ ν›λ ¨/ν”Όν… (λ¨λΈλ³„ λ¶„κΈ°)
    if {λ¨λΈμ΄_ν•™μµμ„_μ”κµ¬ν•λ”κ°€}:
        print(f"   π― λ¨λΈ ν›λ ¨ μ‹μ‘...")
        logger.info("π― λ¨λΈ ν›λ ¨ μ‹μ‘...")
        
        engine.fit(
            model=model,
            datamodule=datamodule
        )
        
        best_checkpoint = checkpoint_callback.best_model_path
        print(f"   π† Best Checkpoint: {best_checkpoint}")
        logger.info(f"π† Best Checkpoint: {best_checkpoint}")
    else:
        print(f"   π― λ¨λΈ ν”Όν… μ‹μ‘... (ν•™μµ λ¶ν•„μ”)")
        logger.info("π― λ¨λΈ ν”Όν… μ‹μ‘... (ν•™μµ λ¶ν•„μ”)")
        
        engine.fit(
            model=model,
            datamodule=datamodule
        )
        
        best_checkpoint = None  # ν•™μµμ΄ μ—†λ” λ¨λΈμ€ μ²΄ν¬ν¬μΈνΈ μ—†μ
        print(f"   β… λ¨λΈ ν”Όν… μ™„λ£!")
        logger.info("β… λ¨λΈ ν”Όν… μ™„λ£!")
    
    print(f"   β… λ¨λΈ ν›λ ¨/ν”Όν… μ™„λ£!")
    logger.info("β… λ¨λΈ ν›λ ¨/ν”Όν… μ™„λ£!")
    
    return model, engine, best_checkpoint
```

---

## π§ μ‹¤ν— μ‹¤ν–‰ ν•¨μ ν…ν”λ¦Ώ

```python
def run_single_{λ¨λΈλ…}_experiment(
    condition: dict,
    log_dir: str = None
) -> dict:
    """λ‹¨μΌ {λ¨λΈλ…} μ‹¤ν— μ΅°κ±΄μ— λ€ν• μ‹¤ν— μν–‰."""
    
    # configμ—μ„ λ„λ©”μΈ μ„¤μ • κ°€μ Έμ¤κΈ°
    config = condition["config"]
    source_domain = config["source_domain"]
    target_domains = extract_target_domains_from_config(config)
    
    # μ‹¤ν— κ²½λ΅ μ„¤μ • (κΈ°μ΅΄ ν¨ν„΄ μ μ§€)
    from datetime import datetime
    if log_dir:
        base_timestamp_dir = log_dir
        timestamp_for_folder = datetime.now().strftime("%Y%m%d_%H%M%S")
        experiment_folder = f"{condition['name']}_{timestamp_for_folder}"
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_timestamp_dir = f"results/{λ¨λΈλ…}/{timestamp}"
        experiment_folder = f"{condition['name']}_{timestamp}"
    
    results_base_dir = f"{base_timestamp_dir}/MultiDomainHDMAP/{λ¨λΈλ…}/{experiment_folder}"
    
    # μ‹¤ν— μ΄λ¦„ μƒμ„±
    experiment_name = f"{source_domain}"
    
    print(f"\n{'='*80}")
    print(f"π”¬ {λ¨λΈλ…} μ‹¤ν— μ΅°κ±΄: {condition['name']}")
    print(f"π“ μ„¤λ…: {condition['description']}")
    print(f"{'='*80}")
    
    try:
        # GPU λ©”λ¨λ¦¬ μ •λ¦¬
        cleanup_gpu_memory()
        
        # DataModule μƒμ„±
        multi_datamodule = create_multi_domain_datamodule(
            datamodule_class=MultiDomainHDMAPDataModule,
            source_domain=source_domain,
            target_domains=target_domains,
            batch_size=config["batch_size"],
            image_size=config["image_size"]
        )
        
        # λ¨λΈ ν›λ ¨
        trained_model, engine, best_checkpoint = train_{λ¨λΈλ…}_model_multi_domain(
            datamodule=multi_datamodule,
            config=condition["config"],
            results_base_dir=results_base_dir,
            logger=logging.getLogger(__name__)
        )
        
        # [λ‚λ¨Έμ§€ ν‰κ°€ λ° μ €μ¥ λ΅μ§μ€ κΈ°μ΅΄ ν¨ν„΄κ³Ό λ™μΌ]
        # ...
        
    except Exception as e:
        # [μ—λ¬ μ²λ¦¬ λ΅μ§]
        # ...
```

---

## π“‹ λ¨λΈλ³„ νΉν™” κµ¬ν„ κ°€μ΄λ“

### π― Step 1: λ¨λΈ νΉμ„± νμ•…

κ° λ¨λΈμ„ κµ¬ν„ν•κΈ° μ „μ— λ‹¤μ μ‚¬ν•­λ“¤μ„ λ°λ“μ‹ ν™•μΈν•μ„Έμ”:

#### A. ν•™μµ μ”κµ¬μ‚¬ν•­
```python
# ν™•μΈν•΄μ•Ό ν•  μ‚¬ν•­λ“¤:
ν•™μµμ΄_ν•„μ”ν•κ°€ = True/False  # μ: DRAEM(True), PatchCore(False)
early_stopping_ν•„μ” = True/False
gradient_clipping_ν•„μ” = True/False
νΉλ³„ν•_trainer_arguments = {...}
```

#### B. λ¨λΈ μ΄κΈ°ν™” νλΌλ―Έν„°
```python
# κ° λ¨λΈμ __init__ νλΌλ―Έν„°λ“¤μ„ ν™•μΈν•κ³  configμ—μ„ μ κ³µν•΄μ•Ό ν•  κ²ƒλ“¤:
ν•„μ_νλΌλ―Έν„° = [...]
μ„ νƒ_νλΌλ―Έν„° = [...]
κΈ°λ³Έκ°’_μ‚¬μ©_νλΌλ―Έν„° = [...]
```

#### C. λ¨λΈλ³„ νΉν™” μ„¤μ •
```python
# μμ‹:
# PatchCore: coreset_sampling_ratio, num_neighbors, backbone, layers
# Padim: backbone, layers, pre_trained
# ReverseDistillation: backbone, layers, lr, momentum
```

### π― Step 2: JSON μ„¤μ • νμΌ μƒμ„±

```json
{
  "condition_1": {
    "name": "{λ¨λΈλ…}_baseline",
    "description": "{λ¨λΈλ…} κΈ°λ³Έ μ„¤μ •μΌλ΅ μ‹¤ν—",
    "config": {
      "source_domain": "domain_A",
      "target_domains": ["domain_B", "domain_C", "domain_D"],
      "batch_size": 32,
      "image_size": [256, 256],
      
      // λ¨λΈλ³„ νΉν™” νλΌλ―Έν„°λ“¤
      "{λ¨λΈλ³„_νλΌλ―Έν„°1}": "κ°’1",
      "{λ¨λΈλ³„_νλΌλ―Έν„°2}": "κ°’2",
      
      // ν•™μµμ΄ ν•„μ”ν• λ¨λΈμ κ²½μ°
      "max_epochs": 50,
      "early_stopping_patience": 10,
      "learning_rate": 0.001,
      "optimizer": "adamw",
      "weight_decay": 0.0001
    }
  }
}
```

### π― Step 3: λ¨λΈλ³„ μμ • ν¬μΈνΈ

#### A. Import κµ¬λ¬Έ μμ •
```python
from anomalib.models.image.{λ¨λΈλ…} import {λ¨λΈν΄λμ¤λ…}
```

#### B. λ¨λΈ μƒμ„± μ½”λ“ μμ •
```python
# μμ‹ - PatchCore
model = Patchcore(
    backbone=config["backbone"],
    layers=config["layers"],
    coreset_sampling_ratio=config["coreset_sampling_ratio"],
    num_neighbors=config["num_neighbors"]
)

# μμ‹ - Padim
model = Padim(
    backbone=config["backbone"],
    layers=config["layers"],
    pre_trained=config["pre_trained"]
)
```

#### C. ν•™μµ/ν”Όν… λ΅μ§ λ¶„κΈ°
```python
if λ¨λΈμ΄_ν•™μµμ„_μ”κµ¬ν•λ”κ°€:
    # ν•™μµ κΈ°λ° λ¨λΈ (DRAEM, ReverseDistillation λ“±)
    engine.fit(model=model, datamodule=datamodule)
    best_checkpoint = checkpoint_callback.best_model_path
else:
    # ν”Όμ² κΈ°λ° λ¨λΈ (PatchCore, Padim λ“±)
    engine.fit(model=model, datamodule=datamodule)
    best_checkpoint = None
```

---

## β οΈ μ£Όμμ‚¬ν•­ λ° μ²΄ν¬λ¦¬μ¤νΈ

### π” κµ¬ν„ μ „ μ²΄ν¬λ¦¬μ¤νΈ

- [ ] **λ¨λΈ λ¬Έμ„ ν™•μΈ**: Anomalib κ³µμ‹ λ¬Έμ„μ—μ„ λ¨λΈ μ΄κΈ°ν™” νλΌλ―Έν„° ν™•μΈ
- [ ] **ν•™μµ μ”κµ¬μ‚¬ν•­ νμ•…**: λ¨λΈμ΄ ν•™μµμ„ ν•„μ”λ΅ ν•λ”μ§€ ν™•μΈ
- [ ] **νΉν™” μ„¤μ • μ΅°μ‚¬**: λ¨λΈλ³„ κ³ μ ν• μ„¤μ •μ΄λ‚ μ μ•½μ‚¬ν•­ νμ•…
- [ ] **λ©”λ¨λ¦¬ μ”κµ¬μ‚¬ν•­**: GPU λ©”λ¨λ¦¬ μ‚¬μ©λ‰μ΄ ν° λ¨λΈμΈμ§€ ν™•μΈ

### π› οΈ κµ¬ν„ μ¤‘ μ²΄ν¬λ¦¬μ¤νΈ

- [ ] **Import κ²½λ΅ μ •ν™•μ„±**: λ¨λΈ ν΄λμ¤ importκ°€ μ¬λ°”λ¥Έμ§€ ν™•μΈ
- [ ] **Config νλΌλ―Έν„° λ§¤ν•‘**: JSON μ„¤μ •μ΄ λ¨λΈ μ΄κΈ°ν™” νλΌλ―Έν„°μ™€ μΌμΉν•λ”μ§€ ν™•μΈ
- [ ] **μ½λ°± μ„¤μ •**: ν•™μµμ΄ ν•„μ”μ—†λ” λ¨λΈμ—μ„ EarlyStopping/ModelCheckpoint μ κ±°
- [ ] **λ΅κΉ… λ©”μ‹μ§€**: λ¨λΈλ…μ΄ λ΅κ·Έ λ©”μ‹μ§€μ— μ •ν™•ν λ°μλμ—λ”μ§€ ν™•μΈ

### π§ ν…μ¤νΈ μ²΄ν¬λ¦¬μ¤νΈ

- [ ] **λ‹¨μΌ μ‹¤ν— μ‹¤ν–‰**: ν•λ‚μ μ‹¤ν— μ΅°κ±΄μΌλ΅ μ •μƒ λ™μ‘ ν™•μΈ
- [ ] **GPU λ©”λ¨λ¦¬ μ •λ¦¬**: μ‹¤ν— μ™„λ£ ν›„ λ©”λ¨λ¦¬ λ„μ μ—†λ”μ§€ ν™•μΈ
- [ ] **κ²°κ³Ό νμΌ μƒμ„±**: JSON κ²°κ³Ό νμΌκ³Ό μ‹κ°ν™” νμΌμ΄ μ •μƒ μƒμ„±λλ”μ§€ ν™•μΈ
- [ ] **λ΅κ·Έ ν™•μΈ**: μ½μ†” μ¶λ ¥κ³Ό λ΅κ·Έ νμΌμ— μ¤λ¥κ°€ μ—†λ”μ§€ ν™•μΈ

---

## π“ λ¨λΈλ³„ νΉν™” κ°€μ΄λ“

### π― PatchCore νΉν™”μ‚¬ν•­

```python
# νΉμ§•: ν•™μµ λ¶ν•„μ”, λ©”λ¨λ¦¬ λ±…ν¬ κΈ°λ°
ν•™μµμ΄_ν•„μ”ν•κ°€ = False
μ£Όμ”_νλΌλ―Έν„° = ["backbone", "layers", "coreset_sampling_ratio", "num_neighbors"]
κΈ°λ³Έ_backbone = "wide_resnet50_2"
κΈ°λ³Έ_layers = ["layer2", "layer3"]
```

### π― Padim νΉν™”μ‚¬ν•­

```python
# νΉμ§•: ν•™μµ λ¶ν•„μ”, ν™•λ¥ μ  μ„λ² λ”©
ν•™μµμ΄_ν•„μ”ν•κ°€ = False
μ£Όμ”_νλΌλ―Έν„° = ["backbone", "layers", "pre_trained"]
κΈ°λ³Έ_backbone = "resnet18"
κΈ°λ³Έ_layers = ["layer1", "layer2", "layer3"]
```

### π― ReverseDistillation νΉν™”μ‚¬ν•­

```python
# νΉμ§•: ν•™μµ ν•„μ”, μ§€μ‹ μ¦λ¥
ν•™μµμ΄_ν•„μ”ν•κ°€ = True
μ£Όμ”_νλΌλ―Έν„° = ["backbone", "layers", "anomaly_map_mode"]
νΉλ³„ν•_μ„¤μ • = "teacher-student κµ¬μ΅°"
```

---

## π–¥οΈ λ©€ν‹° GPU λ³‘λ ¬ μ‹¤ν— μ‹¤ν–‰ κ°€μ΄λ“

κ° λ¨λΈλ³„λ΅ **3κ°μ κµ¬μ„± μ”μ†**λ¥Ό κµ¬ν„ν•΄μ•Ό ν•©λ‹λ‹¤:

### π“‹ ν•„μ κµ¬ν„ νμΌλ“¤

```
1. multi_domain_hdmap_{λ¨λΈλ…}-training.py    # λ©”μΈ ν›λ ¨ μ¤ν¬λ¦½νΈ
2. multi_domain_hdmap_{λ¨λΈλ…}-exp_condition.json  # μ‹¤ν— μ΅°κ±΄ μ„¤μ •
3. multi_domain_hdmap_{λ¨λΈλ…}-run.sh          # λ©€ν‹° GPU μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
```

### π― Step 1: JSON μ‹¤ν— μ΅°κ±΄ νμΌ κµ¬μ΅°

```json
{
  "condition_1": {
    "name": "{λ¨λΈλ…}_baseline",
    "description": "{λ¨λΈλ…} κΈ°λ³Έ μ„¤μ •μΌλ΅ μ‹¤ν—",
    "config": {
      "source_domain": "domain_A",
      "target_domains": ["domain_B", "domain_C", "domain_D"],
      "batch_size": 32,
      "image_size": [256, 256],
      
      // λ¨λΈλ³„ ν•µμ‹¬ νλΌλ―Έν„°λ“¤
      "{λ¨λΈλ³„_νλΌλ―Έν„°1}": "κ°’1",
      "{λ¨λΈλ³„_νλΌλ―Έν„°2}": "κ°’2",
      
      // ν•™μµμ΄ ν•„μ”ν• λ¨λΈμ κ²½μ°
      "max_epochs": 50,
      "early_stopping_patience": 10,
      "learning_rate": 0.001,
      "optimizer": "adamw",
      "weight_decay": 0.0001
    }
  },
  "condition_2": {
    "name": "{λ¨λΈλ…}_optimized",
    "description": "{λ¨λΈλ…} μµμ ν™” μ„¤μ •μΌλ΅ μ‹¤ν—",
    "config": {
      // ... λ‹¤λ¥Έ νλΌλ―Έν„° μ΅°ν•©
    }
  }
}
```

### π― Step 2: λ©€ν‹° GPU μ‹¤ν–‰ μ¤ν¬λ¦½νΈ ν…ν”λ¦Ώ

**νμΌλ…**: `multi_domain_hdmap_{λ¨λΈλ…}-run.sh`

```bash
#!/bin/bash
# nohup ./examples/hdmap/multi_domain_hdmap_{λ¨λΈλ…}-run.sh > /dev/null 2>&1 &
# pkill -f "multi_domain_hdmap_{λ¨λΈλ…}-run.sh"
# pkill -f "examples/hdmap/multi_domain_hdmap_{λ¨λΈλ…}-training.py"

# {λ¨λΈλ…} λ³‘λ ¬ μ‹¤ν— μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
# λ©€ν‹° GPUλ¥Ό ν™μ©ν•μ—¬ μ‹¤ν— μ΅°κ±΄μ„ λ³‘λ ¬λ΅ μ‹¤ν–‰

AVAILABLE_GPUS=(0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15)
EXPERIMENT_CONDITIONS=(
    "{λ¨λΈλ…}_baseline"
    "{λ¨λΈλ…}_optimized"
    "{λ¨λΈλ…}_condition_3"
    # ν•„μ”ν• λ§νΌ μ¶”κ°€...
)
NUM_EXPERIMENTS=${#EXPERIMENT_CONDITIONS[@]}

# λ΅κ·Έ λ””λ ‰ν† λ¦¬ μƒμ„± 
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_DIR="results/{λ¨λΈλ…}/${TIMESTAMP}"
mkdir -p "${LOG_DIR}"

SCRIPT_PATH="examples/hdmap/multi_domain_hdmap_{λ¨λΈλ…}-training.py"

echo "=================================="
echo "π€ {λ¨λΈλ…} λ³‘λ ¬ μ‹¤ν— μ‹μ‘"
echo "=================================="
echo "π“ λ΅κ·Έ λ””λ ‰ν† λ¦¬: ${LOG_DIR}"
echo "π–¥οΈ  μ‚¬μ© GPU: ${AVAILABLE_GPUS[*]}"
echo "π§ μ‹¤ν— μ΅°κ±΄: ${NUM_EXPERIMENTS}κ°"
echo ""

# μ‹¤ν— ν• λ‹Ή λ° μ‹¤ν–‰
echo "π“‹ μ‹¤ν— ν• λ‹Ή:"
for i in $(seq 0 $((NUM_EXPERIMENTS-1))); do
    GPU_ID=${AVAILABLE_GPUS[$((i % ${#AVAILABLE_GPUS[@]}))]}
    EXP_NAME=${EXPERIMENT_CONDITIONS[$i]}
    echo "   GPU ${GPU_ID}: μ‹¤ν— ${i} - ${EXP_NAME}"
done
echo ""

echo "π€ λ³‘λ ¬ μ‹¤ν— μ‹μ‘..."

# λ°±κ·ΈλΌμ΄λ“λ΅ λ¨λ“  μ‹¤ν— μ‹μ‘
pids=()
for i in $(seq 0 $((NUM_EXPERIMENTS-1))); do
    GPU_ID=${AVAILABLE_GPUS[$((i % ${#AVAILABLE_GPUS[@]}))]}
    EXP_NAME=${EXPERIMENT_CONDITIONS[$i]}
    
    echo "π― GPU ${GPU_ID}μ—μ„ μ‹¤ν— ${i} (${EXP_NAME}) μ‹μ‘..."
    
    # κ° μ‹¤ν—μ„ λ°±κ·ΈλΌμ΄λ“λ΅ μ‹¤ν–‰
    nohup python ${SCRIPT_PATH} \
        --gpu-id ${GPU_ID} \
        --experiment-id ${i} \
        --log-dir "${LOG_DIR}" \
        > "${LOG_DIR}/output_exp_${i}_gpu${GPU_ID}.log" 2>&1 &
    
    # PID μ €μ¥
    pids+=($!)
    
    # GPUκ°„ μ‹μ‘ κ°„κ²© (GPU μ΄κΈ°ν™” μ¶©λ λ°©μ§€)
    sleep 5
done

echo ""
echo "β… λ¨λ“  μ‹¤ν—μ΄ λ°±κ·ΈλΌμ΄λ“μ—μ„ μ‹μ‘λμ—μµλ‹λ‹¤!"
echo "π“ μ‹¤μ‹κ°„ λ¨λ‹ν„°λ§:"
echo "   watch -n 10 'nvidia-smi'"
echo ""
echo "π“„ κ°λ³„ λ΅κ·Έ ν™•μΈ:"
for i in $(seq 0 $((NUM_EXPERIMENTS-1))); do
    GPU_ID=${AVAILABLE_GPUS[$((i % ${#AVAILABLE_GPUS[@]}))]}
    echo "   tail -f ${LOG_DIR}/output_exp_${i}_gpu${GPU_ID}.log"
done
echo ""

# λ¨λ“  λ°±κ·ΈλΌμ΄λ“ μ‘μ—… μ™„λ£ λ€κΈ°
echo "β³ λ¨λ“  μ‹¤ν— μ™„λ£ λ€κΈ° μ¤‘..."
for pid in ${pids[*]}; do
    wait $pid
    echo "β… μ‹¤ν— μ™„λ£: PID $pid"
done

echo ""
echo "π‰ λ¨λ“  μ‹¤ν—μ΄ μ™„λ£λμ—μµλ‹λ‹¤!"
echo "π“ κ²°κ³Ό μ„μΉ: ${LOG_DIR}"
echo ""

# μµμΆ… κ²°κ³Ό μ”μ•½
echo "π“ μ‹¤ν— κ²°κ³Ό μ”μ•½:"
for i in $(seq 0 $((NUM_EXPERIMENTS-1))); do
    EXP_NAME=${EXPERIMENT_CONDITIONS[$i]}
    RESULT_FILE="${LOG_DIR}/result_exp_$(printf "%02d" $i)_${EXP_NAME}_gpu*.json"
    if ls ${RESULT_FILE} 1> /dev/null 2>&1; then
        echo "   β… ${EXP_NAME}: μ„±κ³µ"
    else
        echo "   β ${EXP_NAME}: μ‹¤ν¨ λλ” λ―Έμ™„λ£"
    fi
done
```

### π― Step 3: μλ™ μ‹¤ν— λ¬λ„ ν™μ©

κΈ°μ΅΄ `auto_experiment_runner.sh`λ¥Ό ν™μ©ν•μ—¬ GPU λ¨λ‹ν„°λ§ κΈ°λ° μλ™ μ‹¤ν–‰:

```bash
# {λ¨λΈλ…} μ‹¤ν—μ„ μλ™μΌλ΅ μ‹¤ν–‰ (GPU μ ν΄μ‹ μ‹μ‘)
nohup examples/hdmap/auto_experiment_runner.sh \
    -s examples/hdmap/multi_domain_hdmap_{λ¨λΈλ…}-run.sh \
    10 > auto_experiment_$(date +%Y%m%d_%H%M%S).log 2>&1 &
```

### π― Step 4: μ‹¤ν— λ¨λ‹ν„°λ§ λ…λ Ήμ–΄

```bash
# GPU μ‚¬μ©λ¥  μ‹¤μ‹κ°„ λ¨λ‹ν„°λ§
watch -n 10 'nvidia-smi'

# νΉμ • μ‹¤ν— λ΅κ·Έ ν™•μΈ
tail -f results/{λ¨λΈλ…}/{timestamp}/output_exp_0_gpu0.log

# μ‹¤ν— μ§„ν–‰ μƒν™© ν™•μΈ
ps aux | grep "multi_domain_hdmap_{λ¨λΈλ…}-training.py"

# μ‹¤ν— μ¤‘λ‹¨ (ν•„μ”μ‹)
pkill -f "multi_domain_hdmap_{λ¨λΈλ…}-training.py"
```

### π― Step 5: κ²°κ³Ό λ¶„μ„

κ° μ‹¤ν— μ™„λ£ ν›„ μλ™ μƒμ„±λλ” νμΌλ“¤:

```
results/{λ¨λΈλ…}/{timestamp}/
β”β”€β”€ output_exp_0_gpu0.log           # μ‹¤ν— 0 λ΅κ·Έ
β”β”€β”€ output_exp_1_gpu1.log           # μ‹¤ν— 1 λ΅κ·Έ
β”β”€β”€ result_exp_00_{μ΅°κ±΄λ…}_gpu0.json  # μ‹¤ν— 0 κ²°κ³Ό
β”β”€β”€ result_exp_01_{μ΅°κ±΄λ…}_gpu1.json  # μ‹¤ν— 1 κ²°κ³Ό
β””β”€β”€ tensorboard_logs/               # TensorBoard λ΅κ·Έλ“¤
```

---

## π”„ μ—…λ°μ΄νΈ κ°€μ΄λ“

μƒλ΅μ΄ λ¨λΈμ„ μ¶”κ°€ν•  λ•λ§λ‹¤ μ΄ ν…ν”λ¦Ώμ„ μ°Έκ³ ν•μ—¬:

1. **μΌκ΄€λ μ½”λ“ κµ¬μ΅°** μ μ§€
2. **λ™μΌν• μ‹¤ν— νλ¦„** λ³΄μ¥  
3. **νΈν™ κ°€λ¥ν• κ²°κ³Ό ν•μ‹** μƒμ„±
4. **μ μ§€λ³΄μ μ©μ΄μ„±** ν™•λ³΄
5. **λ©€ν‹° GPU λ³‘λ ¬ μ‹¤ν–‰** μ§€μ›

μ΄λ¥Ό ν†µν•΄ λ¨λ“  λ¨λΈλ“¤μ΄ **λ™μΌν• λΉ„κµ κΈ°μ¤€**μΌλ΅ ν‰κ°€λ  μ μμµλ‹λ‹¤.

---

## π“ λ¬Έμμ‚¬ν•­

κµ¬ν„ μ¤‘ λ¬Έμ κ°€ λ°μƒν•κ±°λ‚ λ¨λΈλ³„ νΉν™” μ”κµ¬μ‚¬ν•­μ΄ λ°κ²¬λλ©΄, μ΄ ν…ν”λ¦Ώ λ¬Έμ„λ¥Ό μ—…λ°μ΄νΈν•μ—¬ ν–¥ν›„ κµ¬ν„μλ“¤μ΄ μ°Έκ³ ν•  μ μλ„λ΅ ν•©λ‹λ‹¤.
