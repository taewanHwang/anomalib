#!/usr/bin/env python3
"""Anomaly Detection ì‹¤í—˜ì„ ìœ„í•œ ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤.

ì´ ëª¨ë“ˆì€ DRAEM, PaDiM ë“± ë‹¤ì–‘í•œ Anomaly Detection ëª¨ë¸ ì‹¤í—˜ì—ì„œ 
ì¬ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê³µí†µ í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- GPU ë©”ëª¨ë¦¬ ê´€ë¦¬
- ì‹¤í—˜ ë¡œê¹… ì„¤ì •
- ê²°ê³¼ ì´ë¯¸ì§€ ì •ë¦¬ ë° ì‹œê°í™”
- Target domain í‰ê°€
- ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ë° ì €ì¥
"""

import os
import gc
import json
import shutil
import warnings
import logging
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional, Union, Tuple
from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint

# Anomalib imports
from anomalib.engine import Engine
from anomalib.data.datamodules.image.multi_domain_hdmap import MultiDomainHDMAPDataModule
from anomalib.data.datamodules.image.all_domains_hdmap import AllDomainsHDMAPDataModule


def load_experiment_conditions(json_filename: str) -> List[Dict[str, Any]]:
    """
    JSON íŒŒì¼ì—ì„œ ì‹¤í—˜ ì¡°ê±´ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        json_filename: ë¡œë“œí•  JSON íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
        
    Returns:
        ì‹¤í—˜ ì¡°ê±´ ë¦¬ìŠ¤íŠ¸
        
    Raises:
        FileNotFoundError: JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        json.JSONDecodeError: JSON íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°
    """
    # caller ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ JSON íŒŒì¼ ê²½ë¡œ ìƒì„±
    import inspect
    caller_frame = inspect.stack()[1]
    caller_dir = os.path.dirname(os.path.abspath(caller_frame.filename))
    json_path = os.path.join(caller_dir, json_filename)
    
    if not os.path.exists(json_path):
        raise FileNotFoundError(f"ì‹¤í—˜ ì¡°ê±´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path}")
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        raise json.JSONDecodeError(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
    
    # JSONì—ì„œ ë¡œë“œí•œ ë°ì´í„°ì˜ ìœ íš¨ì„± ê²€ì‚¬
    if 'experiment_conditions' not in data:
        raise ValueError("JSON íŒŒì¼ì— 'experiment_conditions' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    experiment_conditions = data['experiment_conditions']
    
    # JSONì—ì„œëŠ” tupleì´ listë¡œ ì €ì¥ë˜ë¯€ë¡œ, í•„ìš”í•œ í•„ë“œë“¤ì„ ë‹¤ì‹œ tupleë¡œ ë³€í™˜
    for condition in experiment_conditions:
        if 'config' not in condition:
            continue
            
        config = condition['config']
        
        # range íƒ€ì…ì˜ í•„ë“œë“¤ì„ tupleë¡œ ë³€í™˜
        range_fields = ['patch_width_range', 'patch_ratio_range']
        for field in range_fields:
            if field in config and isinstance(config[field], list):
                config[field] = tuple(config[field])
    
    return experiment_conditions
    
    return experiment_conditions


def load_all_domains_experiment_conditions(json_filename: str) -> List[Dict[str, Any]]:
    """
    AllDomains ì‹¤í—˜ì„ ìœ„í•œ JSON íŒŒì¼ì—ì„œ ì‹¤í—˜ ì¡°ê±´ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        json_filename: ë¡œë“œí•  JSON íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
        
    Returns:
        ì‹¤í—˜ ì¡°ê±´ ë¦¬ìŠ¤íŠ¸
        
    Raises:
        FileNotFoundError: JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        json.JSONDecodeError: JSON íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°
    """
    # caller ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ JSON íŒŒì¼ ê²½ë¡œ ìƒì„±
    import inspect
    caller_frame = inspect.stack()[1]
    caller_dir = os.path.dirname(os.path.abspath(caller_frame.filename))
    json_path = os.path.join(caller_dir, json_filename)
    
    if not os.path.exists(json_path):
        raise FileNotFoundError(f"ì‹¤í—˜ ì¡°ê±´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path}")
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        raise json.JSONDecodeError(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
    
    # AllDomains JSONì€ ì§ì ‘ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ
    if isinstance(data, list):
        return data
    else:
        raise ValueError("AllDomains JSON íŒŒì¼ì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.")


def get_experiment_by_name(experiment_conditions: List[Dict[str, Any]], 
                          experiment_name: str) -> Dict[str, Any]:
    """
    ì‹¤í—˜ ì´ë¦„ìœ¼ë¡œ íŠ¹ì • ì‹¤í—˜ ì¡°ê±´ì„ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        experiment_conditions: ì „ì²´ ì‹¤í—˜ ì¡°ê±´ ë¦¬ìŠ¤íŠ¸
        experiment_name: ì°¾ì„ ì‹¤í—˜ ì´ë¦„
        
    Returns:
        í•´ë‹¹ ì‹¤í—˜ ì¡°ê±´ ë”•ì…”ë„ˆë¦¬
        
    Raises:
        ValueError: í•´ë‹¹ ì´ë¦„ì˜ ì‹¤í—˜ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
    """
    for condition in experiment_conditions:
        if condition.get('name') == experiment_name:
            return condition
    
    available_names = [c.get('name', 'Unknown') for c in experiment_conditions]
    raise ValueError(f"ì‹¤í—˜ '{experiment_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                    f"ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í—˜: {available_names}")


def validate_experiment_config(config: Dict[str, Any]) -> bool:
    """
    ì‹¤í—˜ ì„¤ì •ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.
    
    Args:
        config: ê²€ì‚¬í•  ì‹¤í—˜ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ì„¤ì •ì´ ìœ íš¨í•˜ë©´ True, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ False
    """
    required_fields = [
        'max_epochs', 'learning_rate', 'batch_size', 'image_size',
        'source_domain', 'target_domains'
    ]
    
    for field in required_fields:
        if field not in config:
            print(f"í•„ìˆ˜ ì„¤ì • '{field}'ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return False
    
    # ê°’ì˜ ìœ íš¨ì„± ê²€ì‚¬
    if config['max_epochs'] <= 0:
        print("max_epochsëŠ” 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
        return False
        
    if config['learning_rate'] <= 0:
        print("learning_rateëŠ” 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
        return False
        
    if config['batch_size'] <= 0:
        print("batch_sizeëŠ” 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
        return False
    
    return True


def print_experiment_summary(experiment_conditions: List[Dict[str, Any]]) -> None:
    """
    ì‹¤í—˜ ì¡°ê±´ë“¤ì˜ ìš”ì•½ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    
    Args:
        experiment_conditions: ì‹¤í—˜ ì¡°ê±´ ë¦¬ìŠ¤íŠ¸
    """
    print(f"\n=== ì‹¤í—˜ ì¡°ê±´ ìš”ì•½ (ì´ {len(experiment_conditions)}ê°œ) ===")
    
    for i, condition in enumerate(experiment_conditions, 1):
        name = condition.get('name', 'Unknown')
        description = condition.get('description', 'No description')
        config = condition.get('config', {})
        
        epochs = config.get('max_epochs', 'Unknown')
        lr = config.get('learning_rate', 'Unknown')
        
        print(f"{i:2d}. {name}")
        print(f"    ì„¤ëª…: {description}")
        print(f"    ì—í¬í¬: {epochs}, í•™ìŠµë¥ : {lr}")
        
        if 'patch_width_range' in config and 'patch_ratio_range' in config:
            width_range = config['patch_width_range']
            ratio_range = config['patch_ratio_range']
            print(f"    íŒ¨ì¹˜ í¬ê¸°: {width_range}, ë¹„ìœ¨: {ratio_range}")
        
        print()


def extract_target_domains_from_config(config: Dict[str, Any]) -> List[str]:
    """
    ì‹¤í—˜ ì„¤ì •ì—ì„œ target domainsë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        config: ì‹¤í—˜ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Returns:
        List[str]: target domain ë¦¬ìŠ¤íŠ¸
    """
    target_domains = config['target_domains']
    
    if target_domains == 'auto':
        # ê¸°ë³¸ HDMAP ë„ë©”ì¸ (source_domain ì œì™¸)
        source_domain = config['source_domain']
        all_domains = ['domain_A', 'domain_B', 'domain_C', 'domain_D']
        target_domains = [d for d in all_domains if d != source_domain]
    elif isinstance(target_domains, str):
        target_domains = [target_domains]
    elif not isinstance(target_domains, list):
        target_domains = ['domain_B', 'domain_C', 'domain_D']
    
    return target_domains


def analyze_experiment_results(
    source_results: Dict[str, Any],
    target_results: Dict[str, Dict[str, Any]],
    training_info: Dict[str, Any],
    condition: Dict[str, Any],
    model_type: str = "Model"
) -> Dict[str, Any]:
    """
    ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤ (ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µ ì‚¬ìš© ê°€ëŠ¥).
    
    Args:
        source_results: ì†ŒìŠ¤ ë„ë©”ì¸ í‰ê°€ ê²°ê³¼
        target_results: íƒ€ê²Ÿ ë„ë©”ì¸ í‰ê°€ ê²°ê³¼
        training_info: í›ˆë ¨ ì •ë³´
        condition: ì‹¤í—˜ ì¡°ê±´
        model_type: ëª¨ë¸ íƒ€ì… (ì¶œë ¥ìš©)
        
    Returns:
        Dict[str, Any]: ë¶„ì„ëœ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print(f"\nğŸ“Š {model_type} ì‹¤í—˜ ê²°ê³¼ ë¶„ì„")
    
    # íƒ€ê²Ÿ ë„ë©”ì¸ í‰ê·  AUROC ê³„ì‚°
    target_aurocs = []
    for domain, result in target_results.items():
        if isinstance(result.get('image_AUROC'), (int, float)):
            target_aurocs.append(result['image_AUROC'])
    
    avg_target_auroc = sum(target_aurocs) / len(target_aurocs) if target_aurocs else 0.0
    
    # ì†ŒìŠ¤ ë„ë©”ì¸ AUROC
    source_auroc = source_results.get('image_AUROC', 0.0) if source_results else 0.0
    
    # ë„ë©”ì¸ ì „ì´ íš¨ê³¼ ê³„ì‚°
    transfer_ratio = avg_target_auroc / source_auroc if source_auroc > 0 else 0.0
    
    # ì„±ëŠ¥ í‰ê°€
    if transfer_ratio > 0.9:
        transfer_grade = "ìš°ìˆ˜"
    elif transfer_ratio > 0.8:
        transfer_grade = "ì–‘í˜¸"
    elif transfer_ratio > 0.7:
        transfer_grade = "ë³´í†µ"
    else:
        transfer_grade = "ê°œì„ í•„ìš”"
    
    # ê²°ê³¼ ìš”ì•½
    analysis = {
        "experiment_name": condition["name"],
        "source_auroc": source_auroc,
        "avg_target_auroc": avg_target_auroc,
        "transfer_ratio": transfer_ratio,
        "transfer_grade": transfer_grade,
        "target_domain_count": len(target_results),
        "training_epochs": training_info.get("last_trained_epoch", 0),
        "early_stopped": training_info.get("early_stopped", False),
        "best_val_auroc": training_info.get("best_val_auroc", 0.0)
    }
    
    # ë„ë©”ì¸ë³„ ìƒì„¸ ì„±ëŠ¥
    domain_performances = {}
    for domain, result in target_results.items():
        domain_performances[domain] = {
            "auroc": result.get('image_AUROC', 0.0),
            "f1_score": result.get('image_F1Score', 0.0)
        }
    
    analysis["domain_performances"] = domain_performances
    
    # ë¡œê¹…
    print(f"   ğŸ“ˆ Source AUROC: {source_auroc:.4f}")
    print(f"   ğŸ¯ Target í‰ê·  AUROC: {avg_target_auroc:.4f}")
    print(f"   ğŸ”„ ì „ì´ ë¹„ìœ¨: {transfer_ratio:.3f} ({transfer_grade})")
    print(f"   ğŸ“š í›ˆë ¨ ì—í¬í¬: {analysis['training_epochs']}")
    
    for domain, perf in domain_performances.items():
        print(f"   â””â”€ {domain}: AUROC={perf['auroc']:.4f}")
    
    return analysis


def create_common_experiment_result(
    condition: Dict[str, Any],
    status: str = "success",
    experiment_path: str = None,
    source_results: Dict[str, Any] = None,
    target_results: Dict[str, Dict[str, Any]] = None,
    training_info: Dict[str, Any] = None,
    best_checkpoint: str = None,
    error: str = None
) -> Dict[str, Any]:
    """
    ê³µí†µ ì‹¤í—˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        condition: ì‹¤í—˜ ì¡°ê±´
        status: ì‹¤í—˜ ìƒíƒœ ("success" ë˜ëŠ” "failed")
        experiment_path: ì‹¤í—˜ ê²½ë¡œ
        source_results: ì†ŒìŠ¤ ë„ë©”ì¸ ê²°ê³¼
        target_results: íƒ€ê²Ÿ ë„ë©”ì¸ ê²°ê³¼ë“¤
        training_info: í›ˆë ¨ ì •ë³´
        best_checkpoint: ìµœê³  ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
        error: ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
        
    Returns:
        Dict[str, Any]: ì‹¤í—˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    result = {
        "condition": condition,
        "status": status,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "experiment_path": experiment_path,
        "source_results": source_results or {},
        "target_results": target_results or {},
        "training_info": training_info or {},
        "best_checkpoint": best_checkpoint,
    }
    
    if status == "failed":
        result["error"] = error
    else:
        # Target domain í‰ê·  AUROC ê³„ì‚°
        if target_results:
            target_aurocs = []
            for domain, domain_result in target_results.items():
                auroc = domain_result.get('image_AUROC')
                if isinstance(auroc, (int, float)):
                    target_aurocs.append(auroc)
            
            if target_aurocs:
                result["avg_target_auroc"] = sum(target_aurocs) / len(target_aurocs)
            else:
                result["avg_target_auroc"] = 0.0
        else:
            result["avg_target_auroc"] = 0.0
    
    return result


def create_experiment_visualization(
    experiment_name: str,
    model_type: str,
    results_base_dir: str,
    source_domain: str = None,
    target_domains: list = None,
    source_results: Dict[str, Any] = None,
    target_results: Dict[str, Dict[str, Any]] = None,
    single_domain: bool = False
) -> str:
    """ì‹¤í—˜ ê²°ê³¼ ì‹œê°í™” í´ë” êµ¬ì¡° ìƒì„± ë° ì‹¤í—˜ ì •ë³´ ì €ì¥.
    
    Args:
        experiment_name: ì‹¤í—˜ ì´ë¦„
        model_type: ëª¨ë¸ íƒ€ì… (ì˜ˆ: "DRAEM-SevNet", "PaDiM")
        results_base_dir: ê¸°ë³¸ ê²°ê³¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        source_domain: ì†ŒìŠ¤ ë„ë©”ì¸ ì´ë¦„ (single_domain=Trueì¼ ë•ŒëŠ” None ê°€ëŠ¥)
        target_domains: íƒ€ê²Ÿ ë„ë©”ì¸ ë¦¬ìŠ¤íŠ¸
        source_results: ì†ŒìŠ¤ ë„ë©”ì¸ í‰ê°€ ê²°ê³¼
        target_results: íƒ€ê²Ÿ ë„ë©”ì¸ë“¤ í‰ê°€ ê²°ê³¼
        single_domain: ë‹¨ì¼ ë„ë©”ì¸ ì‹¤í—˜ ì—¬ë¶€
        
    Returns:
        str: ìƒì„±ëœ visualize ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    print(f"\nğŸ¨ {model_type} Visualization ìƒì„±")
    
    # ê¸°ë³¸ ê²½ë¡œë¥¼ ì‚¬ìš© (ì´ë¯¸ ì‹¤í—˜ë³„ ê³ ìœ  ê²½ë¡œì„)
    base_path = Path(results_base_dir)
    
    # ë¨¼ì € v* íŒ¨í„´ì˜ ë²„ì „ í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸
    version_dirs = [d for d in base_path.glob("v*") if d.is_dir() and d.name.startswith('v') and d.name[1:].isdigit()]
    if version_dirs:
        # v0, v1 ë“±ì˜ íŒ¨í„´ì´ ìˆìœ¼ë©´ ìµœì‹  ë²„ì „ ì‚¬ìš©
        latest_version_path = max(version_dirs, key=lambda x: int(x.name[1:]))
    else:
        # ë²„ì „ í´ë”ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
        latest_version_path = base_path
    
    # visualize í´ë” ìƒì„±
    viz_path = latest_version_path / "visualize"
    viz_path.mkdir(exist_ok=True)
    
    # í´ë” êµ¬ì¡° ìƒì„± (single_domain ì‹¤í—˜ì—ì„œëŠ” target_domains í´ë” ìƒì„±í•˜ì§€ ì•ŠìŒ)
    if single_domain:
        folders_to_create = ["results"]
    else:
        folders_to_create = [
            "source_domain",
            "target_domains"
        ]
    
    for folder in folders_to_create:
        (viz_path / folder).mkdir(exist_ok=True)
    
    # íƒ€ê²Ÿ ë„ë©”ì¸ë³„ í•˜ìœ„ í´ë” ìƒì„± (multi-domain ì‹¤í—˜ì—ë§Œ ì ìš©)
    if not single_domain and target_domains:
        for domain in target_domains:
            (viz_path / "target_domains" / domain).mkdir(exist_ok=True)
    
    # ì‹¤í—˜ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    experiment_info = {
        "experiment_name": experiment_name,
        "model_type": model_type,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "results_path": str(latest_version_path),
        "source_domain": source_domain,
        "target_domains": target_domains or [],
        "results_summary": {
            "source_results": source_results or {},
            "target_results": target_results or {}
        }
    }
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    info_file = viz_path / "experiment_info.json"
    with open(info_file, 'w', encoding='utf-8') as f:
        json.dump(experiment_info, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… {model_type} í´ë” êµ¬ì¡° ìƒì„± ì™„ë£Œ: {viz_path}")
    
    return str(viz_path)


def create_multi_domain_datamodule(
    datamodule_class,
    source_domain: str = "domain_A",
    target_domains: Union[str, List[str]] = "auto",
    batch_size: int = 16,
    image_size: str = "224x224",
    dataset_root: str = None,
    validation_strategy: str = "source_test",
    num_workers: int = 16
):
    """ì¼ë°˜í™”ëœ MultiDomain DataModule ìƒì„±.
    
    Args:
        datamodule_class: DataModule í´ë˜ìŠ¤ (ì˜ˆ: MultiDomainHDMAPDataModule)
        source_domain: ì†ŒìŠ¤ ë„ë©”ì¸ ì´ë¦„
        target_domains: íƒ€ê²Ÿ ë„ë©”ì¸ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” "auto"
        batch_size: ë°°ì¹˜ í¬ê¸°
        image_size: ì´ë¯¸ì§€ í¬ê¸°
        dataset_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
        validation_strategy: ê²€ì¦ ì „ëµ
        num_workers: ì›Œì»¤ ìˆ˜
        
    Returns:
        ìƒì„±ëœ datamodule ì¸ìŠ¤í„´ìŠ¤
    """
    print(f"\nğŸ“¦ {datamodule_class.__name__} ìƒì„± ì¤‘...")
    print(f"   Source Domain: {source_domain}")
    print(f"   Target Domains: {target_domains}")
    
    # ê¸°ë³¸ dataset_root ì„¤ì •
    if dataset_root is None:
        dataset_root = f"./datasets/HDMAP/1000_8bit_resize_{image_size}"
    
    datamodule = datamodule_class(
        root=dataset_root,
        source_domain=source_domain,
        target_domains=target_domains,
        validation_strategy=validation_strategy,
        train_batch_size=batch_size,
        eval_batch_size=batch_size,
        num_workers=num_workers,
    )
    
    # ë°ì´í„° ì¤€ë¹„ ë° ì„¤ì •
    datamodule.prepare_data()
    datamodule.setup()
    
    print(f"âœ… {datamodule_class.__name__} ì„¤ì • ì™„ë£Œ")
    print(f"   ì‹¤ì œ Target Domains: {datamodule.target_domains}")
    print(f"   í›ˆë ¨ ë°ì´í„°: {len(datamodule.train_data)} ìƒ˜í”Œ (source: {datamodule.source_domain})")
    print(f"   ê²€ì¦ ë°ì´í„°: {len(datamodule.val_data)} ìƒ˜í”Œ (source test)")
    
    total_test_samples = sum(len(test_data) for test_data in datamodule.test_data)
    print(f"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {total_test_samples} ìƒ˜í”Œ (targets)")
    
    for i, target_domain in enumerate(datamodule.target_domains):
        print(f"     â””â”€ {target_domain}: {len(datamodule.test_data[i])} ìƒ˜í”Œ")
    
    return datamodule


def create_all_domains_datamodule(
    datamodule_class,
    batch_size: int,
    image_size: str,
    domains: list[str] = None,
    val_split_ratio: float = 0.2,
    dataset_root: str = None,
    num_workers: int = 8
) -> AllDomainsHDMAPDataModule:
    """AllDomainsHDMAPDataModule ìƒì„± ë° ì„¤ì •.
    
    Args:
        datamodule_class: AllDomainsHDMAPDataModule í´ë˜ìŠ¤ (ì¼ê´€ì„±ì„ ìœ„í•´ ì¶”ê°€, ì‹¤ì œë¡œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        batch_size: ë°°ì¹˜ í¬ê¸°
        image_size: ì´ë¯¸ì§€ í¬ê¸° (ì˜ˆ: "392x392")
        domains: ì‚¬ìš©í•  ë„ë©”ì¸ ë¦¬ìŠ¤íŠ¸. Noneì´ë©´ ëª¨ë“  ë„ë©”ì¸ ì‚¬ìš©
        val_split_ratio: ê²€ì¦ ë°ì´í„° ë¶„í•  ë¹„ìœ¨
        dataset_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        num_workers: ì›Œì»¤ ìˆ˜
        
    Returns:
        ì„¤ì •ëœ AllDomainsHDMAPDataModule
    """
    print(f"\nğŸ“¦ AllDomainsHDMAPDataModule ìƒì„± ì¤‘...")
    
    # ì´ë¯¸ì§€ í¬ê¸° íŒŒì‹±
    try:
        width, height = map(int, image_size.split('x'))
        image_size_tuple = (width, height)
    except ValueError:
        # ê¸°ë³¸ê°’ ì‚¬ìš©
        image_size_tuple = (392, 392)
        print(f"   âš ï¸ ì´ë¯¸ì§€ í¬ê¸° íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {image_size_tuple}")
    
    # ë„ë©”ì¸ ì •ë³´ ì¶œë ¥
    domains_info = f"ì „ì²´ ë„ë©”ì¸ (A~D)" if not domains else f"{domains}"
    print(f"   ğŸŒ ë„ë©”ì¸: {domains_info}")
    print(f"   ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {image_size_tuple}")
    print(f"   ğŸ“Š ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"   ğŸ”„ Val ë¶„í•  ë¹„ìœ¨: {val_split_ratio}")
    
    # ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¥¸ ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
    if dataset_root is None:
        # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì ˆëŒ€ ê²½ë¡œ ìƒì„±
        import os
        current_dir = os.getcwd()
        dataset_root = os.path.join(current_dir, "datasets", "HDMAP", f"1000_8bit_resize_{image_size}")
    
    # AllDomainsHDMAPDataModule ìƒì„±
    datamodule = AllDomainsHDMAPDataModule(
        root=dataset_root,
        domains=domains,  # Noneì´ë©´ ëª¨ë“  ë„ë©”ì¸ ì‚¬ìš©
        train_batch_size=batch_size,
        eval_batch_size=batch_size,
        num_workers=num_workers,
        val_split_ratio=val_split_ratio,  # trainì—ì„œ validation ë¶„í• 
        seed=42
    )
    
    # ë°ì´í„° ì„¤ì •
    print(f"   âš™ï¸  DataModule ì„¤ì • ì¤‘...")
    datamodule.setup()
    
    # ë°ì´í„° í†µê³„ ì¶œë ¥
    print(f"   âœ… DataModule ì„¤ì • ì™„ë£Œ!")
    print(f"      â€¢ Train ìƒ˜í”Œ: {len(datamodule.train_data):,}ê°œ (ëª¨ë“  ë„ë©”ì¸ ì •ìƒ ë°ì´í„°)")
    print(f"      â€¢ Val ìƒ˜í”Œ: {len(datamodule.val_data):,}ê°œ (trainì—ì„œ ë¶„í• )")
    print(f"      â€¢ Test ìƒ˜í”Œ: {len(datamodule.test_data):,}ê°œ (ëª¨ë“  ë„ë©”ì¸ ì •ìƒ+ê²°í•¨)")
    
    return datamodule


def evaluate_source_domain(
    model: Any, 
    engine: Any, 
    datamodule: Any,
    checkpoint_path: str = None
) -> Dict[str, Any]:
    """ì¼ë°˜í™”ëœ Source Domain ì„±ëŠ¥ í‰ê°€.
    
    Args:
        model: í‰ê°€í•  ëª¨ë¸
        engine: Lightning Engine
        datamodule: ë°ì´í„° ëª¨ë“ˆ
        checkpoint_path: ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        
    Returns:
        Dict[str, Any]: í‰ê°€ ê²°ê³¼
    """
    print(f"\nğŸ“Š Source Domain ì„±ëŠ¥ í‰ê°€ - {datamodule.source_domain}")
    print("   ğŸ’¡ í‰ê°€ ë°ì´í„°: Source domain test (validationìœ¼ë¡œ ì‚¬ìš©ëœ ë°ì´í„°)")
    print("   ğŸ¯ ì¬í˜„ì„±ì„ ìœ„í•´ í›ˆë ¨ì— ì‚¬ìš©ëœ ë™ì¼í•œ DataModuleì˜ val_dataloader ì‚¬ìš©")
    print(f"   ğŸ“‹ ê²€ì¦ ë°ì´í„°ì…‹ í¬ê¸°: {len(datamodule.val_data)} ìƒ˜í”Œ")
    
    # í›ˆë ¨ì— ì‚¬ìš©ëœ ë™ì¼í•œ DataModuleì˜ validation DataLoader ì‚¬ìš©
    # ì´ë ‡ê²Œ í•˜ë©´ ì™„ì „íˆ ë™ì¼í•œ ë°ì´í„°ì…‹ ì¸ìŠ¤í„´ìŠ¤ì™€ ìˆœì„œë¥¼ ë³´ì¥
    val_dataloader = datamodule.val_dataloader()
    
    # Engineì˜ ê²½ë¡œ ì„¤ì • í™•ì¸ (fit() í›„ì—ë§Œ ì ‘ê·¼ ê°€ëŠ¥)
    try:
        if hasattr(engine, 'trainer') and engine.trainer is not None and hasattr(engine.trainer, 'default_root_dir'):
            print(f"   ğŸ”§ Source domain í‰ê°€ ì‹œ Engine default_root_dir: {engine.trainer.default_root_dir}")
    except Exception as e:
        print(f"   âš ï¸ Warning: Engine ê²½ë¡œ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    if checkpoint_path:
        results = engine.test(
            model=model,
            dataloaders=val_dataloader,
            ckpt_path=checkpoint_path
        )
    else:
        results = engine.test(
            model=model,
            dataloaders=val_dataloader
        )
    
    if results and len(results) > 0:
        source_metrics = results[0]
        
        # test_image_AUROC -> image_AUROC í‚¤ ë³€í™˜ (í‘œì¤€í™”)
        if 'test_image_AUROC' in source_metrics:
            source_metrics['image_AUROC'] = source_metrics['test_image_AUROC']
        if 'test_image_F1Score' in source_metrics:
            source_metrics['image_F1Score'] = source_metrics['test_image_F1Score']
        
        print(f"   âœ… Source Domain í‰ê°€ ì™„ë£Œ:")
        print(f"   ğŸ“ ì£¼ìš” ë©”íŠ¸ë¦­ (Validationê³¼ ë™ì¼í•´ì•¼ í•¨):")
        
        # ì£¼ìš” ë©”íŠ¸ë¦­ ì¶œë ¥
        for key, value in source_metrics.items():
            if isinstance(value, (int, float)):
                if 'AUROC' in key or 'F1Score' in key:
                    print(f"     â””â”€ {key}: {value:.4f}")
                else:
                    print(f"     â””â”€ {key}: {value}")
        
        return source_metrics
    else:
        print(f"   âŒ Source Domain í‰ê°€ ì‹¤íŒ¨")
        return {}


def cleanup_gpu_memory():
    """GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µ ì‚¬ìš© ê°€ëŠ¥)."""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()


def setup_warnings_filter():
    """ì‹¤í—˜ ì‹œ ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§ (ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µ ì‚¬ìš© ê°€ëŠ¥)."""
    warnings.filterwarnings("ignore", category=FutureWarning)
    warnings.filterwarnings("ignore", category=DeprecationWarning)
    warnings.filterwarnings("ignore", category=UserWarning)


def setup_experiment_logging(log_file_path: str, experiment_name: str) -> logging.Logger:
    """ì‹¤í—˜ ë¡œê¹… ì„¤ì • (ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µ ì‚¬ìš© ê°€ëŠ¥).
    
    Args:
        log_file_path: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        experiment_name: ì‹¤í—˜ ì´ë¦„
        
    Returns:
        logging.Logger: ì„¤ì •ëœ ë¡œê±°
    """
    # ë¡œê±° ì„¤ì •
    logger = logging.getLogger(experiment_name)
    logger.setLevel(logging.INFO)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€
    file_handler = logging.FileHandler(log_file_path, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    
    # í¬ë§·í„° ì„¤ì •
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    
    return logger


def extract_training_info(engine: Engine) -> Dict[str, Any]:
    """PyTorch Lightning Engineì—ì„œ í•™ìŠµ ì •ë³´ ì¶”ì¶œ (ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µ ì‚¬ìš© ê°€ëŠ¥).
    
    Args:
        engine: Anomalib Engine ê°ì²´
        
    Returns:
        Dict[str, Any]: í•™ìŠµ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    import torch
    
    trainer = engine.trainer
    
    # Early Stopping ì½œë°± ì°¾ê¸°
    early_stopping_callback = None
    for callback in trainer.callbacks:
        if isinstance(callback, EarlyStopping):
            early_stopping_callback = callback
            break
    
    # ì‹¤ì œ í•™ìŠµ ì™„ë£Œ ì—í­ ê³„ì‚°
    if early_stopping_callback and hasattr(early_stopping_callback, 'stopped_epoch') and early_stopping_callback.stopped_epoch > 0:
        # Early stoppingì´ ë°œìƒí•œ ê²½ìš°: stopped_epochì´ ë§ˆì§€ë§‰ í•™ìŠµ ì—í­
        last_trained_epoch = early_stopping_callback.stopped_epoch + 1  # 0-based â†’ 1-based
        early_stopped = True
    else:
        # ì •ìƒ ì™„ë£Œ ë˜ëŠ” early stopping ì—†ìŒ
        last_trained_epoch = trainer.current_epoch + 1  # 0-based â†’ 1-based
        early_stopped = False
    
    # ê¸°ë³¸ ì •ë³´
    training_info = {
        "max_epochs_configured": trainer.max_epochs,
        "last_trained_epoch": last_trained_epoch,  # ì‹¤ì œ ë§ˆì§€ë§‰ìœ¼ë¡œ í•™ìŠµí•œ ì—í­ (1-based)
        "total_steps": trainer.global_step,
        "early_stopped": early_stopped,
        "early_stop_reason": None,
        "best_val_auroc": None,  # ìµœê³  validation AUROC
        "f1_threshold_issue": "F1ScoreëŠ” ê¸°ë³¸ thresholdë¡œ ê³„ì‚°ë¨. AUROC ëŒ€ë¹„ ë‚®ì„ ìˆ˜ ìˆìŒ."
    }
    
    # Early stopping ì„¸ë¶€ ì •ë³´ ì¶”ê°€
    if early_stopping_callback:
        if training_info["early_stopped"]:
            training_info["early_stop_reason"] = f"No improvement for {early_stopping_callback.patience} epochs"
        
        # ìµœê³  ì„±ëŠ¥ ê¸°ë¡
        if hasattr(early_stopping_callback, 'best_score') and early_stopping_callback.best_score is not None:
            best_score = early_stopping_callback.best_score
            if hasattr(best_score, 'cpu'):
                training_info["best_val_auroc"] = float(best_score.cpu())
            else:
                training_info["best_val_auroc"] = float(best_score)
    
    # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì •ë³´ì—ì„œë„ ìµœê³  ì„±ëŠ¥ ì¶”ì¶œ
    checkpoint_callback = None
    for callback in trainer.callbacks:
        if hasattr(callback, 'best_model_score'):
            checkpoint_callback = callback
            break
    
    if checkpoint_callback and hasattr(checkpoint_callback, 'best_model_score') and checkpoint_callback.best_model_score is not None:
        best_score = checkpoint_callback.best_model_score
        if hasattr(best_score, 'cpu'):
            training_info["best_val_auroc"] = float(best_score.cpu())
        else:
            training_info["best_val_auroc"] = float(best_score)
    
    # í•™ìŠµ ì™„ë£Œ ë°©ì‹ ê²°ì •
    if training_info["early_stopped"]:
        completion_type = "early_stopping"
        completion_description = f"ì—í­ {training_info['last_trained_epoch']}ì—ì„œ early stoppingìœ¼ë¡œ ì¤‘ë‹¨"
    elif training_info["last_trained_epoch"] >= training_info["max_epochs_configured"]:
        completion_type = "max_epochs_reached"
        completion_description = f"ìµœëŒ€ ì—í­ {training_info['max_epochs_configured']} ì™„ë£Œ"
    else:
        completion_type = "interrupted"
        completion_description = f"ì—í­ {training_info['last_trained_epoch']}ì—ì„œ ì¤‘ë‹¨ë¨"
    
    training_info["completion_type"] = completion_type
    training_info["completion_description"] = completion_description
    
    return training_info


def find_anomalib_image_paths(base_search_path: Path) -> Optional[Path]:
    """Anomalibì´ ìƒì„±í•œ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ìë™ìœ¼ë¡œ íƒìƒ‰ (ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µ ì‚¬ìš© ê°€ëŠ¥).
    
    Args:
        base_search_path: íƒìƒ‰í•  ê¸°ë³¸ ê²½ë¡œ
        
    Returns:
        Optional[Path]: ë°œê²¬ëœ ì´ë¯¸ì§€ ê²½ë¡œì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬ (images í´ë”ì˜ ë¶€ëª¨)
    """
    # ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬ì¡°ì— ëŒ€ì‘í•˜ëŠ” íŒ¨í„´ë“¤
    search_patterns = [
        "**/DraemSevNet/MultiDomainHDMAPDataModule/**/images",  # DRAEM ê³„ì—´
        "**/Padim/MultiDomainHDMAPDataModule/**/images",        # PaDiM ê³„ì—´
        "**/*/MultiDomainHDMAPDataModule/**/images",            # ì¼ë°˜ì ì¸ íŒ¨í„´
        "**/images"                                              # ê°€ì¥ ì¼ë°˜ì ì¸ íŒ¨í„´
    ]
    
    anomalib_image_paths = []
    
    for pattern in search_patterns:
        found_paths = list(base_search_path.glob(pattern))
        anomalib_image_paths.extend(found_paths)
    
    if anomalib_image_paths:
        # ê²½ë¡œ ìƒì„± ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹  ì„ íƒ
        latest_image_path = max(anomalib_image_paths, key=lambda p: p.stat().st_mtime if p.exists() else 0)
        anomalib_results_path = latest_image_path.parent  # images í´ë”ì˜ ë¶€ëª¨
        print(f"   âœ… ì‹¤ì œ Anomalib ê²°ê³¼ ê²½ë¡œ: {anomalib_results_path}")
        return anomalib_results_path
    
    return None


def organize_source_domain_results(
    sevnet_viz_path: str,
    results_base_dir: str,
    source_domain: str,
    specific_version_path: str = None
) -> bool:
    """Source Domain í‰ê°€ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ì •ë¦¬ëœ í´ë”ë¡œ ë³µì‚¬ (ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µ ì‚¬ìš© ê°€ëŠ¥).
    
    ëª©ì : engine.test()ë¡œ ìƒì„±ëœ Source Domain ì‹œê°í™” ê²°ê³¼ë¥¼ source_domain/ í´ë”ë¡œ ì¬ë°°ì¹˜í•˜ì—¬
          ë‚˜ì¤‘ì— ë¶„ì„í•  ë•Œ ìš©ì´í•˜ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•¨
    
    Source Domainì€ ë³´í†µ fault/, good/ í´ë” êµ¬ì¡°ë¡œ êµ¬ì„±ë¨:
    - fault/: ì‹¤ì œ anomalyê°€ ìˆëŠ” ì´ë¯¸ì§€ë“¤ì˜ ì‹œê°í™” ê²°ê³¼
    - good/: ì •ìƒ ì´ë¯¸ì§€ë“¤ì˜ ì‹œê°í™” ê²°ê³¼
    
    ê° ì´ë¯¸ì§€ëŠ” ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨:
    - Original Image: ì›ë³¸ ì´ë¯¸ì§€
    - Reconstructed: ì¬êµ¬ì„±ëœ ì´ë¯¸ì§€ (reconstruction quality í™•ì¸)
    - Anomaly Map: Heat map í˜•íƒœì˜ anomaly ì ìˆ˜ ë¶„í¬
    - Image + Pred Mask: Threshold ê¸°ë°˜ binary mask (ë¹¨ê°„ìƒ‰ ì˜ì—­ë§Œ í‘œì‹œ)
    - Severity Score: SeverityHeadì˜ ì‹¬ê°ë„ ì˜ˆì¸¡ê°’ (0.0~1.0)
      * DRAEM-SevNetì€ mask + severity ê²°í•©ìœ¼ë¡œ ë” ì •êµí•œ anomaly detection ì œê³µ
    
    Args:
        sevnet_viz_path: visualize í´ë” ê²½ë¡œ
        results_base_dir: ê¸°ë³¸ ê²°ê³¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        source_domain: ì†ŒìŠ¤ ë„ë©”ì¸ ì´ë¦„
        specific_version_path: íŠ¹ì • ë²„ì „ ê²½ë¡œ (ì„ íƒì )
        
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        # Source í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        if specific_version_path:
            source_path = Path(specific_version_path)
        else:
            source_path = Path(results_base_dir)
        
        # images í´ë” ì°¾ê¸°
        images_folder = None
        for images_path in source_path.rglob("images"):
            if images_path.is_dir():
                images_folder = images_path
                break
        
        if not images_folder or not images_folder.exists():
            print(f"   âš ï¸ Warning: {source_domain} images í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source_path}")
            return False
        
        # íƒ€ê²Ÿ ê²½ë¡œ (visualize/source_domain/)
        sevnet_viz_path_obj = Path(sevnet_viz_path)
        target_source_path = sevnet_viz_path_obj / "source_domain"
        target_source_path.mkdir(parents=True, exist_ok=True)
        
        print(f"   ğŸ“‚ Source Domain ì´ë¯¸ì§€ ë³µì‚¬: {images_folder} â†’ {target_source_path}")
        
        # fault/, good/ í´ë” ë³µì‚¬
        copied_folders = []
        for subfolder in ["fault", "good"]:
            source_subfolder = images_folder / subfolder
            target_subfolder = target_source_path / subfolder
            
            if source_subfolder.exists():
                if target_subfolder.exists():
                    shutil.rmtree(target_subfolder)
                shutil.copytree(source_subfolder, target_subfolder)
                
                image_count = len(list(target_subfolder.glob("*.png")))
                copied_folders.append(f"{subfolder}({image_count})")
                print(f"     âœ… {subfolder}: {image_count} ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ")
        
        if copied_folders:
            print(f"   âœ… Source Domain ë³µì‚¬ ì™„ë£Œ: {', '.join(copied_folders)}")
            return True
        else:
            print(f"   âš ï¸ Warning: ë³µì‚¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
            
    except Exception as e:
        print(f"   âŒ Error: Source Domain ì´ë¯¸ì§€ ë³µì‚¬ ì‹¤íŒ¨: {e}")
        return False


def copy_target_domain_results(
    domain: str,
    results_base_dir: str = None,
    specific_version_path: str = None,
    visualization_base_path: str = None
) -> bool:
    """Target Domain í‰ê°€ ê²°ê³¼ ì „ì²´ ë³µì‚¬ ë° ë³´ì¡´ (ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µ ì‚¬ìš© ê°€ëŠ¥).
    
    ê° Target Domain í‰ê°€ê°€ ì™„ë£Œë˜ë©´ images/ í´ë”ì˜ ëª¨ë“  ê²°ê³¼ë¥¼ 
    visualize/target_domains/{domain}/ í´ë”ë¡œ ì™„ì „íˆ ë³µì‚¬í•˜ì—¬ ë³´ì¡´í•©ë‹ˆë‹¤.
    
    ëª©ì : engine.test()ë¡œ ìƒì„±ëœ ì‹œê°í™” ê²°ê³¼ë¥¼ ë„ë©”ì¸ë³„ë¡œ ì¬ë°°ì¹˜í•˜ì—¬ 
          ë‚˜ì¤‘ì— ë¶„ì„í•  ë•Œ ìš©ì´í•˜ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•¨
    
    Args:
        domain: íƒ€ê²Ÿ ë„ë©”ì¸ ì´ë¦„
        results_base_dir: ê¸°ë³¸ ê²°ê³¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì„ íƒì )
        specific_version_path: íŠ¹ì • ë²„ì „ ê²½ë¡œ (ì„ íƒì )
        visualization_base_path: ì‹œê°í™” ì €ì¥ ê¸°ë³¸ ê²½ë¡œ (ì„ íƒì )
        
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ê²½ë¡œ ê²°ì • (specific_version_path ìš°ì„ , ê·¸ ë‹¤ìŒ results_base_dir)
        if specific_version_path:
            base_path = Path(specific_version_path)
        elif results_base_dir:
            base_path = Path(results_base_dir)
        else:
            print(f"         âŒ Error: ê²½ë¡œê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
        
        # ì‹œê°í™” ê²½ë¡œ ê²°ì •
        if visualization_base_path:
            viz_base_path = Path(visualization_base_path)
        else:
            viz_base_path = base_path / "visualize"
        
        # íƒ€ê²Ÿ ê²½ë¡œ (visualize/target_domains/{domain}/)
        target_domain_path = viz_base_path / "target_domains" / domain
        target_domain_path.mkdir(parents=True, exist_ok=True)
        
        # Sourceì—ì„œ images í´ë” ì°¾ê¸°
        all_images_paths = list(base_path.rglob("images"))
        
        # ë§Œì•½ ì°¾ì§€ ëª»í–ˆë‹¤ë©´, ë¶€ëª¨ ê²½ë¡œì—ì„œë„ íƒìƒ‰ (ì‹¤ì œ Anomalib ê²°ê³¼ ê²½ë¡œ í¬í•¨)
        if not all_images_paths and base_path.name == "tensorboard_logs":
            parent_path = base_path.parent
            all_images_paths = list(parent_path.rglob("images"))
        
        images_folder = None
        for images_path in all_images_paths:
            if images_path.is_dir():
                images_folder = images_path
                break
        
        if not images_folder or not images_folder.exists():
            print(f"         âš ï¸ Warning: {domain} images í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # images í´ë” ì „ì²´ ë³µì‚¬
        copied_count = 0
        for item in images_folder.iterdir():
            if item.is_file() and item.suffix.lower() in ['.png', '.jpg', '.jpeg']:
                target_file = target_domain_path / item.name
                shutil.copy2(item, target_file)
                copied_count += 1
            elif item.is_dir():
                target_subfolder = target_domain_path / item.name
                if target_subfolder.exists():
                    shutil.rmtree(target_subfolder)
                shutil.copytree(item, target_subfolder)
                subfolder_count = len(list(target_subfolder.rglob("*.png")))
                copied_count += subfolder_count
        
        if copied_count > 0:
            print(f"         âœ… {domain}: {copied_count} ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ")
            return True
        else:
            print(f"         âš ï¸ Warning: {domain}ì— ë³µì‚¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
            
    except Exception as e:
        print(f"         âŒ Error: {domain} ì´ë¯¸ì§€ ë³µì‚¬ ì‹¤íŒ¨: {e}")
        return False


def evaluate_target_domains(
    model: Any,
    engine: Engine,
    datamodule: Any,
    checkpoint_path: str,
    results_base_dir: str,
    target_domains: List[str] = None,
    datamodule_class = None,
    save_samples: bool = True,
    current_version_path: str = None
) -> Dict[str, Dict[str, Any]]:
    """Target domainsì— ëŒ€í•œ ì„±ëŠ¥ í‰ê°€ ìˆ˜í–‰ (ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µ ì‚¬ìš© ê°€ëŠ¥).
    
    Args:
        model: í›ˆë ¨ëœ ëª¨ë¸
        engine: Anomalib Engine
        datamodule: Multi-domain ë°ì´í„°ëª¨ë“ˆ (sourceìš©)
        checkpoint_path: ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
        results_base_dir: ê²°ê³¼ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ
        target_domains: í‰ê°€í•  target domain ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ datamoduleì—ì„œ ì¶”ì¶œ)
        datamodule_class: DataModule í´ë˜ìŠ¤ (Noneì´ë©´ ìë™ ê°ì§€)
        save_samples: ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€
        current_version_path: í˜„ì¬ ë²„ì „ ê²½ë¡œ (ì‹œê°í™” ì €ì¥ìš©)
        
    Returns:
        Dict[str, Dict[str, Any]]: ê° target domainë³„ í‰ê°€ ê²°ê³¼
    """
    # DataModule í´ë˜ìŠ¤ ìë™ ê°ì§€
    if datamodule_class is None:
        datamodule_class = type(datamodule)
    
    # Target domains ìë™ ì¶”ì¶œ
    if target_domains is None:
        if hasattr(datamodule, 'target_domains'):
            target_domains = datamodule.target_domains
        else:
            # ê¸°ë³¸ê°’ìœ¼ë¡œ HDMAP ë„ë©”ì¸ ì‚¬ìš©
            target_domains = ["domain_B", "domain_C", "domain_D"]
            print(f"   âš ï¸ Warning: target_domainsë¥¼ ìë™ ê°ì§€í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {target_domains}")
    
    print(f"   ğŸ¯ í‰ê°€í•  Target Domains: {target_domains}")
    
    target_results = {}
    
    for domain in target_domains:
        print(f"      ğŸ¯ Target Domain í‰ê°€: {domain}")
        
        try:
            # ê°œë³„ Target Domainìš© DataModule ìƒì„± (ë™ì  í´ë˜ìŠ¤ ì‚¬ìš©)
            target_datamodule = datamodule_class(
                root=datamodule.root,
                source_domain=getattr(datamodule, 'source_domain', "domain_A"),  # ì›ë˜ source domain ìœ ì§€
                target_domains=[domain],   # í‰ê°€í•  domainì„ targetìœ¼ë¡œ ì„¤ì •
                validation_strategy=getattr(datamodule, 'validation_strategy', "source_test"),
                train_batch_size=getattr(datamodule, 'train_batch_size', 16),
                eval_batch_size=getattr(datamodule, 'eval_batch_size', 16),
                num_workers=getattr(datamodule, 'num_workers', 16)
            )
            
            # Test ë‹¨ê³„ ì„¤ì •
            target_datamodule.setup(stage="test")
            
            # ëª¨ë¸ í‰ê°€
            print(f"         ğŸ“Š {domain} DataModule ì„¤ì • ì™„ë£Œ, test ì‹œì‘...")
            
            # Note: Engineì˜ default_root_dirì€ í›ˆë ¨ í›„ ë³€ê²½ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ì¬ì„¤ì •í•˜ì§€ ì•ŠìŒ
            # ê²°ê³¼ëŠ” ê° ì‹¤í—˜ì˜ tensorboard_logs í´ë”ì— ì •ìƒì ìœ¼ë¡œ ì €ì¥ë¨
            
            result = engine.test(
                model=model, 
                datamodule=target_datamodule,
                ckpt_path=checkpoint_path
            )
            
            print(f"         ğŸ” {domain} í‰ê°€ ê²°ê³¼ íƒ€ì…: {type(result)}")
            print(f"         ğŸ” {domain} í‰ê°€ ê²°ê³¼ ë‚´ìš©: {result}")
            
            # ê²°ê³¼ ì €ì¥
            if result:
                domain_result = result[0] if isinstance(result, list) else result
                
                # test_image_AUROC -> image_AUROC í‚¤ ë³€í™˜ (í‘œì¤€í™”)
                if 'test_image_AUROC' in domain_result:
                    domain_result['image_AUROC'] = domain_result['test_image_AUROC']
                if 'test_image_F1Score' in domain_result:
                    domain_result['image_F1Score'] = domain_result['test_image_F1Score']
                
                target_results[domain] = domain_result
                print(f"         âœ… {domain} í‰ê°€ ì™„ë£Œ - AUROC: {target_results[domain].get('image_AUROC', 'N/A')}")
                if isinstance(target_results[domain].get('image_AUROC'), (int, float)):
                    print(f"         ğŸ“Š {domain} ìƒì„¸ ì„±ëŠ¥: AUROC={target_results[domain].get('image_AUROC'):.4f}, F1={target_results[domain].get('image_F1Score', 'N/A')}")
            else:
                print(f"         âš ï¸ Warning: {domain} í‰ê°€ ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤")
                target_results[domain] = {"image_AUROC": 0.0, "image_F1Score": 0.0}
            
            # ì´ë¯¸ì§€ ë³µì‚¬ (ì„ íƒì )
            if save_samples and current_version_path:
                copy_success = copy_target_domain_results(
                    domain=domain,
                    results_base_dir=results_base_dir,
                    specific_version_path=current_version_path
                )
                if not copy_success:
                    print(f"         âš ï¸ Warning: {domain} ì´ë¯¸ì§€ ë³µì‚¬ ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"         âŒ Error: {domain} í‰ê°€ ì‹¤íŒ¨: {e}")
            target_results[domain] = {"image_AUROC": 0.0, "image_F1Score": 0.0, "error": str(e)}
    
    return target_results


def save_experiment_results(
    result: Dict[str, Any], 
    result_filename: str, 
    log_dir: Path, 
    logger: logging.Logger,
    model_type: str = "Model"
) -> Path:
    """ì‹¤í—˜ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ (ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µ ì‚¬ìš© ê°€ëŠ¥).
    
    Args:
        result: ì‹¤í—˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        result_filename: ì €ì¥í•  íŒŒì¼ëª…
        log_dir: ë¡œê·¸ ë””ë ‰í† ë¦¬ (ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
        logger: ë¡œê±° ê°ì²´
        model_type: ëª¨ë¸ íƒ€ì… (ë¡œê¹…ìš©)
        
    Returns:
        Path: ì‹¤ì œ ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    # ì‹¤í—˜ë³„ ê²½ë¡œì— ì €ì¥í•˜ê±°ë‚˜, ì‹¤íŒ¨ ì‹œ log_dirì— ì €ì¥
    if result.get("experiment_path") and Path(result["experiment_path"]).exists():
        result_path = Path(result["experiment_path"]) / result_filename
        print(f"   ğŸ“ ê²°ê³¼ íŒŒì¼ì„ ì‹¤í—˜ í´ë”ì— ì €ì¥: {result_path}")
    else:
        result_path = log_dir / result_filename
        print(f"   ğŸ“ ê²°ê³¼ íŒŒì¼ì„ ë¡œê·¸ í´ë”ì— ì €ì¥: {result_path}")
    
    # ê²°ê³¼ JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ ì²˜ë¦¬
    serializable_result = json.loads(json.dumps(result, default=str))
    
    with open(result_path, 'w', encoding='utf-8') as f:
        json.dump(serializable_result, f, indent=2, ensure_ascii=False)
    
    # ê²°ê³¼ ìš”ì•½ ë¡œê¹…
    if result["status"] == "success":
        logger.info("âœ… ì‹¤í—˜ ì„±ê³µ!")
        
        # AUROC ì •ë³´ ë¡œê¹… (multi-domain ë˜ëŠ” all-domainsì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬)
        if 'source_results' in result:
            # Multi-domain ì‹¤í—˜ì˜ ê²½ìš°
            source_auroc = result['source_results'].get('image_AUROC', None)
            if isinstance(source_auroc, (int, float)):
                logger.info(f"   Source Domain AUROC: {source_auroc:.4f}")
            else:
                logger.info(f"   Source Domain AUROC: {source_auroc or 'N/A'}")
            
            # Target Domains Avg AUROC ì•ˆì „í•œ í¬ë§·íŒ…
            avg_target_auroc = result.get('avg_target_auroc', None)
            if isinstance(avg_target_auroc, (int, float)):
                logger.info(f"   Target Domains Avg AUROC: {avg_target_auroc:.4f}")
            else:
                logger.info(f"   Target Domains Avg AUROC: {avg_target_auroc or 'N/A'}")
                
        elif 'all_domains_results' in result:
            # All-domains ì‹¤í—˜ì˜ ê²½ìš°
            all_domains_auroc = result['all_domains_results'].get('test_image_AUROC', None)
            if isinstance(all_domains_auroc, (int, float)):
                logger.info(f"   All Domains AUROC: {all_domains_auroc:.4f}")
            else:
                logger.info(f"   All Domains AUROC: {all_domains_auroc or 'N/A'}")
        else:
            logger.info("   AUROC ì •ë³´ ì—†ìŒ")
        
        logger.info(f"   ì²´í¬í¬ì¸íŠ¸: {result.get('best_checkpoint', 'N/A')}")
        
        # í•™ìŠµ ê³¼ì • ì •ë³´ ë¡œê¹…
        training_info = result.get('training_info', {})
        if training_info:
            logger.info("ğŸ“Š í•™ìŠµ ê³¼ì • ì •ë³´:")
            logger.info(f"   ì„¤ì •ëœ ìµœëŒ€ ì—í¬í¬: {training_info.get('max_epochs_configured', 'N/A')}")
            logger.info(f"   ì‹¤ì œ í•™ìŠµ ì—í¬í¬: {training_info.get('last_trained_epoch', 'N/A')}")
            logger.info(f"   ì´ í•™ìŠµ ìŠ¤í…: {training_info.get('total_steps', 'N/A')}")
            logger.info(f"   Early Stopping ì ìš©: {training_info.get('early_stopped', 'N/A')}")
            if training_info.get('early_stopped'):
                logger.info(f"   Early Stopping ì‚¬ìœ : {training_info.get('early_stop_reason', 'N/A')}")
            # ìµœê³  Validation AUROC ì•ˆì „í•œ í¬ë§·íŒ…
            best_val_auroc = training_info.get('best_val_auroc', None)
            if isinstance(best_val_auroc, (int, float)):
                logger.info(f"   ìµœê³  Validation AUROC: {best_val_auroc:.4f}")
            else:
                logger.info(f"   ìµœê³  Validation AUROC: {best_val_auroc or 'N/A'}")
            logger.info(f"   í•™ìŠµ ì™„ë£Œ ë°©ì‹: {training_info.get('completion_description', 'N/A')}")
        
        # Target Domainë³„ ìƒì„¸ ì„±ëŠ¥ ë¡œê¹…
        target_results = result.get('target_results', {})
        if target_results:
            logger.info("ğŸ¯ Target Domainë³„ ì„±ëŠ¥:")
            for domain, domain_result in target_results.items():
                domain_auroc = domain_result.get('image_AUROC', 'N/A')
                if isinstance(domain_auroc, (int, float)):
                    logger.info(f"   {domain}: {domain_auroc:.4f}")
                else:
                    logger.info(f"   {domain}: {domain_auroc}")
    else:
        logger.info("âŒ ì‹¤í—˜ ì‹¤íŒ¨!")
        logger.info(f"   ì˜¤ë¥˜: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
    
    logger.info(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {result_path}")
    
    # ì‹¤í—˜ë³„ ê²½ë¡œì— ì €ì¥ëœ ê²½ìš° ì¶”ê°€ ì •ë³´ ë¡œê¹…
    if result.get("experiment_path"):
        logger.info(f"ğŸ“‚ ì‹¤í—˜ í´ë”: {result['experiment_path']}")
    
    return result_path


def analyze_multi_experiment_results(all_results: list, source_domain: str):
    """ë‹¤ì¤‘ ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ë° ë¹„êµ (ëª¨ë“  ëª¨ë¸ì—ì„œ ê³µí†µ ì‚¬ìš© ê°€ëŠ¥).
    
    Args:
        all_results: ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        source_domain: ì†ŒìŠ¤ ë„ë©”ì¸ ì´ë¦„
    """
    print(f"\n{'='*80}")
    print(f"ğŸ“ˆ ë‹¤ì¤‘ ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ë° ë¹„êµ")
    print(f"Source Domain: {source_domain}")
    print(f"{'='*80}")
    
    successful_results = [r for r in all_results if r["status"] == "success"]
    failed_results = [r for r in all_results if r["status"] == "failed"]
    
    print(f"\nğŸ“Š ì‹¤í—˜ ìš”ì•½:")
    print(f"   ì„±ê³µ: {len(successful_results)}/{len(all_results)} ê°œ")
    print(f"   ì‹¤íŒ¨: {len(failed_results)}/{len(all_results)} ê°œ")
    
    if failed_results:
        print(f"\nâŒ ì‹¤íŒ¨í•œ ì‹¤í—˜ë“¤:")
        for result in failed_results:
            print(f"   - {result['condition']['name']}: {result['error']}")
    
    if successful_results:
        print(f"\nğŸ† ì‹¤í—˜ ê²°ê³¼ ìˆœìœ„ (Target Domain í‰ê·  AUROC ê¸°ì¤€):")
        # Target Domain í‰ê·  AUROC ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_results = sorted(successful_results, 
                              key=lambda x: x.get("avg_target_auroc", 0), 
                              reverse=True)
        
        print(f"{'ìˆœìœ„':<4} {'ì‹¤í—˜ ì¡°ê±´':<30} {'Source AUROC':<12} {'Target Avg':<12} {'ë„ë©”ì¸ ì „ì´':<10}")
        print("-" * 80)
        
        for idx, result in enumerate(sorted_results, 1):
            condition_name = result["condition"]["name"]
            source_auroc = result["source_results"].get("image_AUROC", 0)
            avg_target_auroc = result.get("avg_target_auroc", 0)
            
            # ë„ë©”ì¸ ì „ì´ íš¨ê³¼ ê³„ì‚°
            if source_auroc > 0:
                transfer_effect = avg_target_auroc / source_auroc
                transfer_desc = "ìš°ìˆ˜" if transfer_effect > 0.9 else "ì–‘í˜¸" if transfer_effect > 0.8 else "ê°œì„ í•„ìš”"
            else:
                transfer_desc = "N/A"
            
            print(f"{idx:<4} {condition_name:<30} {source_auroc:<12.3f} {avg_target_auroc:<12.3f} {transfer_desc:<10}")
        
        # ìµœê³  ì„±ëŠ¥ ì‹¤í—˜ ì„¸ë¶€ ë¶„ì„
        best_result = sorted_results[0]
        print(f"\nğŸ¥‡ ìµœê³  ì„±ëŠ¥ ì‹¤í—˜: {best_result['condition']['name']}")
        print(f"   ğŸ“Š Target Domainë³„ ì„¸ë¶€ ì„±ëŠ¥:")
        
        target_performances = []
        for domain, result in best_result["target_results"].items():
            domain_auroc = result.get("image_AUROC", 0)
            if isinstance(domain_auroc, (int, float)):
                print(f"   {domain:<12} {domain_auroc:<12.3f}")
                target_performances.append((domain, domain_auroc))
        
        # ë„ë©”ì¸ë³„ ì„±ëŠ¥ ë¶„ì„
        if target_performances:
            best_domain = max(target_performances, key=lambda x: x[1])
            worst_domain = min(target_performances, key=lambda x: x[1])
            print(f"\n   ğŸ¯ ìµœê³  ì„±ëŠ¥ ë„ë©”ì¸: {best_domain[0]} (AUROC: {best_domain[1]:.3f})")
            print(f"   âš ï¸  ìµœì € ì„±ëŠ¥ ë„ë©”ì¸: {worst_domain[0]} (AUROC: {worst_domain[1]:.3f})")


def create_single_domain_datamodule(
    domain: str,
    batch_size: int = 16,
    image_size: str = "224x224",
    dataset_root: str = None,
    val_split_ratio: float = 0.2,
    num_workers: int = 4,
    seed: int = 42
):
    """Single Domainìš© HDMAPDataModule ìƒì„± ë° ì„¤ì •.
    
    Args:
        domain: ë‹¨ì¼ ë„ë©”ì¸ ì´ë¦„ (ì˜ˆ: "domain_A")
        batch_size: ë°°ì¹˜ í¬ê¸°
        image_size: ì´ë¯¸ì§€ í¬ê¸° (ì˜ˆ: "224x224")
        dataset_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        val_split_ratio: trainì—ì„œ validation ë¶„í•  ë¹„ìœ¨
        num_workers: ì›Œì»¤ ìˆ˜
        seed: ëœë¤ ì‹œë“œ
        
    Returns:
        ì„¤ì •ëœ HDMAPDataModule
    """
    from anomalib.data.datamodules.image.hdmap import HDMAPDataModule
    from anomalib.data.utils import ValSplitMode
    
    print(f"\nğŸ“¦ Single Domain HDMAPDataModule ìƒì„± ì¤‘...")
    print(f"   ğŸ¯ ë„ë©”ì¸: {domain}")
    print(f"   ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {image_size}")
    print(f"   ğŸ“Š ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"   ğŸ”„ Val ë¶„í•  ë¹„ìœ¨: {val_split_ratio}")
    
    # ê¸°ë³¸ dataset_root ì„¤ì •
    if dataset_root is None:
        import os
        current_dir = os.getcwd()
        # working directoryê°€ examples/hdmap/single_domainì¼ ë•Œë¥¼ ê³ ë ¤
        if current_dir.endswith('single_domain'):
            dataset_root = os.path.join(current_dir, "..", "..", "..", "datasets", "HDMAP", f"1000_8bit_resize_{image_size}")
        else:
            dataset_root = os.path.join(current_dir, "datasets", "HDMAP", f"1000_8bit_resize_{image_size}")
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        dataset_root = os.path.abspath(dataset_root)
    
    print(f"   ğŸ“ ë°ì´í„°ì…‹ ê²½ë¡œ: {dataset_root}")
    
    # HDMAPDataModule ìƒì„±
    datamodule = HDMAPDataModule(
        root=dataset_root,
        domain=domain,
        train_batch_size=batch_size,
        eval_batch_size=batch_size,
        num_workers=num_workers,
        val_split_mode=ValSplitMode.FROM_TRAIN,  # trainì—ì„œ validation ë¶„í• 
        val_split_ratio=val_split_ratio,
        seed=seed
    )
    
    # ë°ì´í„° ì¤€ë¹„ ë° ì„¤ì •
    print(f"   âš™ï¸  DataModule ì„¤ì • ì¤‘...")
    datamodule.prepare_data()
    datamodule.setup()
    
    # ë°ì´í„° í†µê³„ ì¶œë ¥
    print(f"âœ… {domain} ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"   í›ˆë ¨ ìƒ˜í”Œ: {len(datamodule.train_data)}ê°œ")
    print(f"   ê²€ì¦ ìƒ˜í”Œ: {len(datamodule.val_data) if datamodule.val_data else 0}ê°œ")
    print(f"   í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(datamodule.test_data)}ê°œ")
    
    return datamodule
