#!/usr/bin/env python3
"""
BaseAnomalyTrainer - í†µí•© Anomaly Detection ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ ë² ì´ìŠ¤ í´ë˜ìŠ¤

ì´ ëª¨ë“ˆì€ ëª¨ë“  anomaly detection ëª¨ë¸ì˜ í›ˆë ¨ì„ í†µí•© ê´€ë¦¬í•©ë‹ˆë‹¤.

ì§€ì› ëª¨ë¸:
- DRAEM: Reconstruction + Anomaly Detection
- Dinomaly: Vision Transformer ê¸°ë°˜ anomaly detection with DINOv2
- PatchCore: Memory bank ê¸°ë°˜ few-shot anomaly detection  
- DRAEM-SevNet: Selective feature reconstruction
"""

import os
import json
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Tuple
import logging

# ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ import
from experiment_utils import (
    cleanup_gpu_memory,
    setup_experiment_logging,
    extract_training_info,
    save_experiment_results,
    create_experiment_visualization,
    create_single_domain_datamodule
)

# ëª¨ë¸ë³„ imports
from anomalib.models.image.draem import Draem
from anomalib.models.image.draem_sevnet import DraemSevNet
from anomalib.models.image import Dinomaly, Patchcore
from anomalib.engine import Engine
from pytorch_lightning.loggers import TensorBoardLogger
from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, Callback
from anomalib.metrics import AUROC, Evaluator



class BaseAnomalyTrainer:
    """í†µí•© Anomaly Detection ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, config: Dict[str, Any], experiment_name: str, session_timestamp: str, experiment_dir: str = None):
        """
        Args:
            config: ì‹¤í—˜ ì„¤ì • ë”•ì…”ë„ˆë¦¬ (model_type í¬í•¨)
            experiment_name: ì‹¤í—˜ ì´ë¦„
            session_timestamp: ì „ì²´ ì„¸ì…˜ì˜ timestamp
            experiment_dir: ì™¸ë¶€ì—ì„œ ì§€ì •í•œ ì‹¤í—˜ ë””ë ‰í„°ë¦¬ (ì„ íƒì )
        """
        self.config = config
        self.experiment_name = experiment_name
        self.session_timestamp = session_timestamp
        self.model_type = config.get("model_type", "").lower()
        self.external_experiment_dir = experiment_dir
        self.setup_paths()
        
    def setup_paths(self):
        """ì‹¤í—˜ ê²½ë¡œ ì„¤ì •"""
        if self.external_experiment_dir:
            # bash ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì „ë‹¬ë°›ì€ ë””ë ‰í„°ë¦¬ ì‚¬ìš©
            self.experiment_dir = Path(self.external_experiment_dir)
            self.results_dir = self.experiment_dir.parent
        else:
            # í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ë³¸ ë°©ì‹ (ë‹¨ë… ì‹¤í–‰ ì‹œ)
            self.results_dir = Path("results") / self.session_timestamp
            self.experiment_dir = self.results_dir / f"{self.experiment_name}_{self.session_timestamp}"
            self.experiment_dir.mkdir(parents=True, exist_ok=True)
        
    def create_model(self):
        """Factory patternìœ¼ë¡œ ëª¨ë¸ ìƒì„±"""
        if self.model_type == "draem":
            return self._create_draem_model()
        elif self.model_type == "dinomaly":
            return self._create_dinomaly_model()
        elif self.model_type == "patchcore":
            return self._create_patchcore_model()
        elif self.model_type == "draem_sevnet":
            return self._create_draem_sevnet_model()
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {self.model_type}")
    
    def _create_draem_model(self):
        """DRAEM ëª¨ë¸ ìƒì„±"""
        # ëª…ì‹œì ìœ¼ë¡œ test_image_AUROC ë©”íŠ¸ë¦­ ì„¤ì •
        val_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="val_image_")
        test_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="test_image_")
        evaluator = Evaluator(val_metrics=[val_auroc], test_metrics=[test_auroc])
        
        return Draem(evaluator=evaluator)
    
    def _create_dinomaly_model(self):
        """Dinomaly ëª¨ë¸ ìƒì„±"""
        # DinomalyëŠ” ê¸°ë³¸ evaluatorë¥¼ ì‚¬ìš©í•˜ì—¬ trainable íŒŒë¼ë¯¸í„° ì„¤ì • ë¬¸ì œ íšŒí”¼
        return Dinomaly(
            encoder_name=self.config["encoder_name"],
            target_layers=self.config["target_layers"],
            bottleneck_dropout=self.config["bottleneck_dropout"],
            decoder_depth=self.config["decoder_depth"],
            remove_class_token=self.config["remove_class_token"],
            evaluator=True  # ê¸°ë³¸ evaluator ì‚¬ìš©
        )
    
    def _create_patchcore_model(self):
        """Patchcore ëª¨ë¸ ìƒì„±"""
        return Patchcore(
            backbone=self.config["backbone"],
            layers=self.config["layers"],
            pre_trained=self.config["pre_trained"],
            coreset_sampling_ratio=self.config["coreset_sampling_ratio"],
            num_neighbors=self.config["num_neighbors"]
        )
    
    def _create_draem_sevnet_model(self):
        """DRAEM-SevNet ëª¨ë¸ ìƒì„±"""
        # ëª…ì‹œì ìœ¼ë¡œ test_image_AUROC ë©”íŠ¸ë¦­ ì„¤ì •
        val_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="val_image_")
        test_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="test_image_")
        evaluator = Evaluator(val_metrics=[val_auroc], test_metrics=[test_auroc])
        
        return DraemSevNet(
            severity_head_mode=self.config["severity_head_mode"],
            severity_head_hidden_dim=self.config["severity_head_hidden_dim"],
            score_combination=self.config["score_combination"],
            severity_weight_for_combination=self.config["severity_weight_for_combination"],
            severity_head_pooling_type=self.config["severity_head_pooling_type"],
            severity_head_spatial_size=self.config["severity_head_spatial_size"],
            severity_head_use_spatial_attention=self.config["severity_head_use_spatial_attention"],
            patch_ratio_range=self.config["patch_ratio_range"],
            patch_width_range=self.config["patch_width_range"],
            patch_count=self.config["patch_count"],
            anomaly_probability=self.config["anomaly_probability"],
            severity_weight=self.config["severity_weight"],
            severity_loss_type=self.config["severity_loss_type"],
            severity_max=self.config["severity_max"],
            evaluator=evaluator
        )
    
    def create_datamodule(self):
        """ëª¨ë“  ëª¨ë¸ì— ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•  ë°ì´í„° ëª¨ë“ˆ ìƒì„±"""
        # ë„ë©”ì¸ ì„¤ì • - ëª¨ë¸ë³„ë¡œ ë‹¤ë¥¸ í•„ë“œëª… ì²˜ë¦¬
        domain = self.config.get("source_domain") or self.config.get("domain")
        if not domain:
            raise ValueError("configì—ì„œ 'source_domain' ë˜ëŠ” 'domain' í•„ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
        return create_single_domain_datamodule(
            domain=domain,
            batch_size=self.config["batch_size"],
            image_size=self.config["image_size"],
            val_split_ratio=self.config["val_split_ratio"],
            num_workers=self.config["num_workers"],
            seed=self.config["seed"]
        )
    
    def create_callbacks(self):
        """ì½œë°± ì„¤ì • - ëª¨ë¸ë³„ ì ì ˆí•œ early stopping ë©”íŠ¸ë¦­ ì‚¬ìš©"""
        callbacks = []
        
        # ëª¨ë¸ë³„ EarlyStopping ì„¤ì •
        if self.model_type == "patchcore":
            # PatchCoreëŠ” ë‹¨ì¼ epoch í›ˆë ¨ì´ë¯€ë¡œ EarlyStoppingê³¼ ModelCheckpoint ëª¨ë‘ ë¶ˆí•„ìš”
            # Engineì—ì„œ ìë™ìœ¼ë¡œ ModelCheckpointë¥¼ ì¶”ê°€í•˜ë¯€ë¡œ ë³„ë„ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
            print("   â„¹ï¸ PatchCore: EarlyStopping ë° ModelCheckpoint ë¹„í™œì„±í™” (ë‹¨ì¼ epoch í›ˆë ¨)")
            return []  # ë¹ˆ ì½œë°± ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            
        else:
            # DRAEM, DRAEM-SevNet, Dinomaly: val_loss ê¸°ë°˜ EarlyStopping
            early_stopping = EarlyStopping(
                monitor="val_loss",
                patience=self.config["early_stopping_patience"],
                mode="min",
                verbose=True
            )
            callbacks.append(early_stopping)
            
            # Model Checkpoint
            domain = self.config.get("source_domain") or self.config.get("domain")
            checkpoint = ModelCheckpoint(
                filename=f"{self.model_type}_single_domain_{domain}_" + "{epoch:02d}_{val_loss:.4f}",
                monitor="val_loss", 
                mode="min",
                save_top_k=1,
                verbose=True
            )
            callbacks.append(checkpoint)
            
            print(f"   â„¹ï¸ {self.model_type.upper()}: EarlyStopping í™œì„±í™” (val_loss ëª¨ë‹ˆí„°ë§)")
        
        return callbacks
    
    def configure_optimizer(self, model):
        """ì˜µí‹°ë§ˆì´ì € ì„¤ì • - ëª¨ë“  ëª¨ë¸ ê³µí†µ"""
        # PatchCoreëŠ” ì˜µí‹°ë§ˆì´ì €ê°€ í•„ìš”í•˜ì§€ ì•ŠìŒ
        if self.model_type == "patchcore":
            return
            
        # DRAEMê³¼ DRAEM-SevNetì€ ì´ë¯¸ ìì²´ configure_optimizersë¥¼ ê°€ì§€ê³  ìˆìŒ
        # Dinomalyë§Œ ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©
        # ë”°ë¼ì„œ ì—¬ê¸°ì„œëŠ” ë³„ë„ ì²˜ë¦¬ ë¶ˆí•„ìš”
    
    def train_model(self, model, datamodule, logger) -> Tuple[Any, Engine, str]:
        """ëª¨ë¸ í›ˆë ¨ ìˆ˜í–‰"""
        print(f"\nğŸš€ {self.model_type.upper()} ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        logger.info(f"ğŸš€ {self.model_type.upper()} ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        
        # Config ì„¤ì • ì¶œë ¥
        print(f"   ğŸ”§ Config ì„¤ì •:")
        print(f"      Model Type: {self.model_type}")
        if self.model_type != "patchcore":
            print(f"      Max Epochs: {self.config['max_epochs']}")
            print(f"      Learning Rate: {self.config['learning_rate']}")
            print(f"      Early Stopping Patience: {self.config['early_stopping_patience']}")
        print(f"      Batch Size: {self.config['batch_size']}")
        
        # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
        self.configure_optimizer(model)
        
        # ì½œë°± ì„¤ì •
        callbacks = self.create_callbacks()
        
        # TensorBoard ë¡œê±° ì„¤ì •
        tb_logger = TensorBoardLogger(
            save_dir=str(self.experiment_dir),
            name="tensorboard_logs",
            version=""
        )
        
        # Engine ì„¤ì •
        # PatchCoreì˜ ê²½ìš° max_epochsë¥¼ 1ë¡œ ê°•ì œ ì„¤ì •
        max_epochs = 1 if self.model_type == "patchcore" else self.config["max_epochs"]
        
        engine_kwargs = {
            "accelerator": "gpu" if torch.cuda.is_available() else "cpu",
            "devices": [0] if torch.cuda.is_available() else 1,
            "logger": tb_logger,
            "callbacks": callbacks,
            "enable_checkpointing": True,
            "log_every_n_steps": 10,
            "enable_model_summary": True,
            "default_root_dir": str(self.experiment_dir),
            "max_epochs": max_epochs,
            "check_val_every_n_epoch": 1,
            "num_sanity_val_steps": 0
        }
        
        if self.model_type == "patchcore":
            print(f"   â„¹ï¸ PatchCore: max_epochs ê°•ì œ ì„¤ì • (1 epoch)")
        else:
            print(f"   â„¹ï¸ {self.model_type.upper()}: max_epochs = {max_epochs}")
        
        engine = Engine(**engine_kwargs)
        
        print(f"   ğŸ”§ Engine ì„¤ì • ì™„ë£Œ")
        print(f"   ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {self.experiment_dir}")
        logger.info(f"ğŸ”§ Engine ì„¤ì • ì™„ë£Œ")
        logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {self.experiment_dir}")
        
        # ëª¨ë¸ í›ˆë ¨
        print(f"   ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        logger.info("ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        engine.fit(model=model, datamodule=datamodule)
        
        # ìµœê³  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
        best_checkpoint = ""
        for callback in callbacks:
            if isinstance(callback, ModelCheckpoint) and hasattr(callback, 'best_model_path'):
                best_checkpoint = callback.best_model_path
                break
        
        print(f"   ğŸ† Best Checkpoint: {best_checkpoint}")
        logger.info(f"ğŸ† Best Checkpoint: {best_checkpoint}")
        
        print(f"   âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        logger.info("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        
        return model, engine, best_checkpoint
    
    def evaluate_model(self, model, engine, datamodule, logger) -> Dict[str, Any]:
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        domain = self.config.get("source_domain") or self.config.get("domain")
        
        print(f"\nğŸ“Š {domain} ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘")
        logger.info(f"ğŸ“Š {domain} ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘")
        
        # í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
        test_results = engine.test(model=model, datamodule=datamodule)
        
        # ê²°ê³¼ ì •ë¦¬ - test_image_AUROC ìš°ì„  ì‚¬ìš©
        if test_results and len(test_results) > 0:
            test_metrics = test_results[0]
            
            # ë©”íŠ¸ë¦­ í‚¤ ìš°ì„ ìˆœìœ„: test_image_AUROC > image_AUROC
            image_auroc = test_metrics.get("test_image_AUROC", test_metrics.get("image_AUROC", 0.0))
            
            results = {
                "domain": domain,
                "image_AUROC": float(image_auroc),
                "image_F1Score": test_metrics.get("test_image_F1Score", test_metrics.get("image_F1Score", 0.0)),
                "training_samples": len(datamodule.train_data),
                "test_samples": len(datamodule.test_data),
                "val_samples": len(datamodule.val_data) if datamodule.val_data else 0
            }
            
            # ë””ë²„ê¹…: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ë©”íŠ¸ë¦­ ì¶œë ¥
            print(f"   ğŸ” Available test metrics: {list(test_metrics.keys())}")
            logger.info(f"Available test metrics: {list(test_metrics.keys())}")
            
            print(f"   âœ… {domain} í‰ê°€ ì™„ë£Œ:")
            print(f"      Image AUROC: {results['image_AUROC']:.4f}")
            print(f"      Image F1: {results['image_F1Score']:.4f}")
            
            logger.info(f"âœ… {domain} í‰ê°€ ì™„ë£Œ: Image AUROC={results['image_AUROC']:.4f}")
        else:
            results = {"domain": domain, "error": "No test results available"}
            logger.error(f"âŒ {domain} í‰ê°€ ì‹¤íŒ¨")
        
        return results
    
    def save_results(self, results, training_info, best_checkpoint, logger):
        """ì‹¤í—˜ ê²°ê³¼ ì €ì¥"""
        domain = self.config.get("source_domain") or self.config.get("domain")
        
        experiment_results = {
            "experiment_name": self.experiment_name,
            "description": f"{domain} - {self.model_type.upper()} single domain training",
            "domain": domain,
            "config": self.config,
            "results": results,
            "training_info": training_info,
            "timestamp": datetime.now().isoformat(),
            "checkpoint_path": best_checkpoint,
            "status": "success",
            "condition": {
                "name": self.experiment_name,
                "description": f"{domain} - {self.model_type.upper()} single domain training",
                "config": {
                    "source_domain": domain,
                    **self.config
                }
            },
            "source_results": {
                "test_image_AUROC": results.get("image_AUROC", 0.0),
                "test_image_F1Score": results.get("image_F1Score", 0.0),
                "domain": domain
            },
            "target_results": {}  # Single domainì´ë¯€ë¡œ ë¹„ì›Œë‘ 
        }
        
        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # ì‹¤í—˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— ì§ì ‘ ì €ì¥ (multi-domainê³¼ ë™ì¼)
        result_filename = f"result_{timestamp}.json"
        
        results_file = save_experiment_results(
            result=experiment_results,
            result_filename=result_filename,
            log_dir=Path(self.experiment_dir),  # ì‹¤í—˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
            logger=logger,
            model_type=self.model_type.upper()
        )
        print(f"ğŸ“„ ì‹¤í—˜ ê²°ê³¼ ì €ì¥ë¨: {results_file}")
        
        return experiment_results
    
    def run_experiment(self) -> dict:
        """ì „ì²´ ì‹¤í—˜ ì‹¤í–‰"""
        domain = self.config.get("source_domain") or self.config.get("domain")
        
        print(f"\n{'='*80}")
        print(f"ğŸ”¬ {self.model_type.upper()} Single Domain ì‹¤í—˜: {self.experiment_name}")
        print(f"ğŸ¯ ë„ë©”ì¸: {domain}")
        print(f"{'='*80}")
        
        try:
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            cleanup_gpu_memory()
            
            # ë¡œê¹… ì„¤ì •
            log_file_path = self.experiment_dir / f"{domain}_single.log"
            logger = setup_experiment_logging(str(log_file_path), self.experiment_name)
            logger.info(f"ğŸš€ {self.model_type.upper()} Single Domain ì‹¤í—˜ ì‹œì‘")
            
            # ëª¨ë¸ ìƒì„±
            model = self.create_model()
            
            # DataModule ìƒì„±
            datamodule = self.create_datamodule()
            
            # ëª¨ë¸ í›ˆë ¨
            trained_model, engine, best_checkpoint = self.train_model(model, datamodule, logger)
            
            # ì„±ëŠ¥ í‰ê°€
            results = self.evaluate_model(trained_model, engine, datamodule, logger)
            
            # í›ˆë ¨ ì •ë³´ ì¶”ì¶œ
            training_info = extract_training_info(engine)
            
            # ê²°ê³¼ ì €ì¥
            experiment_results = self.save_results(results, training_info, best_checkpoint, logger)
            
            # ì‹œê°í™” ìƒì„±
            try:
                create_experiment_visualization(
                    experiment_name=self.experiment_name,
                    model_type=f"{self.model_type.upper()}_single_domain_{domain}",
                    results_base_dir=str(self.experiment_dir),
                    source_domain=domain,
                    source_results=experiment_results.get('results', {}),
                    single_domain=True
                )
                print(f"ğŸ“Š ê²°ê³¼ ì‹œê°í™” ìƒì„± ì™„ë£Œ")
            except Exception as viz_error:
                print(f"âš ï¸ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {viz_error}")
                logger.warning(f"ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {viz_error}")
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            cleanup_gpu_memory()
            
            print(f"âœ… ì‹¤í—˜ ì™„ë£Œ: {self.experiment_name}")
            logger.info(f"âœ… ì‹¤í—˜ ì™„ë£Œ: {self.experiment_name}")
            
            return experiment_results
            
        except Exception as e:
            error_msg = f"âŒ ì‹¤í—˜ ì‹¤íŒ¨: {self.experiment_name} - {str(e)}"
            print(error_msg)
            if 'logger' in locals():
                logger.error(error_msg)
            
            cleanup_gpu_memory()
            
            return {
                "experiment_name": self.experiment_name,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "status": "failed"
            }