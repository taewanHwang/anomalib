#!/usr/bin/env python3
"""SingleDomain HDMAP DRAEM í•™ìŠµ ì˜ˆì‹œ.

DRAEM ëª¨ë¸ê³¼ HDMAPDataModuleì„ í™œìš©í•œ ë‹¨ì¼ ë„ë©”ì¸ ì´ìƒ íƒì§€ í•™ìŠµ ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

DRAEM íŠ¹ì§•:
- Reconstruction + Anomaly Detection: ì •ìƒ ì´ë¯¸ì§€ ë³µì›ê³¼ ì´ìƒ íƒì§€ë¥¼ ë™ì‹œ ìˆ˜í–‰
- í•™ìŠµ í•„ìš”: Encoder-Decoder êµ¬ì¡°ë¡œ í›ˆë ¨ ê³¼ì • í•„ìš”
- Anomaly Generation: ì¸ìœ„ì ìœ¼ë¡œ ì´ìƒ íŒ¨í„´ì„ ìƒì„±í•˜ì—¬ ì§€ë„ í•™ìŠµ ìˆ˜í–‰
- Multi-scale Features: ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ì˜ íŠ¹ì§•ì„ í™œìš©í•œ ì´ìƒ íƒì§€
- End-to-End Training: ë³µì›ê³¼ ë¶„í• ì„ ë™ì‹œì— ìµœì í™”

ì‹¤í—˜ êµ¬ì¡°:
1. HDMAPDataModule ì„¤ì • (ë‹¨ì¼ ë„ë©”ì¸, validationì„ trainì—ì„œ ë¶„í• )
2. ë‹¨ì¼ ë„ë©”ì¸ì—ì„œ DRAEM ëª¨ë¸ í›ˆë ¨ (train ë°ì´í„°)
3. ê°™ì€ ë„ë©”ì¸ì—ì„œ ì„±ëŠ¥ í‰ê°€ (validationìœ¼ë¡œ ì‚¬ìš©í•  train ë¶„í•  + test ë°ì´í„°)
4. í•™ìŠµ ê³¡ì„  ë° ì„±ëŠ¥ ë¶„ì„

ì£¼ìš” ê°œì„ ì  (DRAEM vs ê¸°ì¡´ feature ê¸°ë°˜ ëª¨ë¸):
- í•™ìŠµ ê°€ëŠ¥í•œ ì´ìƒ íƒì§€: ë„ë©”ì¸ë³„ íŠ¹ì„±ì— ë§ëŠ” í•™ìŠµ ìˆ˜í–‰
- í”½ì…€ ë‹¨ìœ„ ì •ë°€ë„: ì´ìƒ ì˜ì—­ì˜ ì •í™•í•œ localization
- ì•ˆì •ì  ì„±ëŠ¥: ì¶©ë¶„í•œ ì •ìƒ ë°ì´í„°ë¡œ robustí•œ ë³µì› ëª¨ë¸ êµ¬ì¶•

NOTE:
- ì‹¤í—˜ ì¡°ê±´ë“¤ì€ single_domain_hdmap_draem-exp_condition.json íŒŒì¼ì—ì„œ ê´€ë¦¬ë©ë‹ˆë‹¤.
- validationì€ train ë°ì´í„°ì—ì„œ ë¶„í• í•˜ë¯€ë¡œ ëª¨ë‘ ì •ìƒ ë°ì´í„°ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
"""

import os
import json
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict, Any
import logging
import warnings
import argparse

# HDMAP import  
from anomalib.models.image.draem import Draem
from anomalib.engine import Engine
from pytorch_lightning.loggers import TensorBoardLogger

# Early Stopping import (í•™ìŠµì´ í•„ìš”í•œ ëª¨ë¸)
from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, Callback
import torch.nn.functional as F

# ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ import
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), ".."))
from experiment_utils import (
    cleanup_gpu_memory,
    setup_warnings_filter,
    setup_experiment_logging,
    extract_training_info,
    save_experiment_results,
    create_experiment_visualization,
    load_experiment_conditions,
    analyze_experiment_results,
    create_single_domain_datamodule
)

# ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™”
setup_warnings_filter()
logging.getLogger("anomalib.visualization.image.item_visualizer").setLevel(logging.ERROR)
logging.getLogger("anomalib.visualization").setLevel(logging.ERROR)
logging.getLogger("anomalib.callbacks").setLevel(logging.ERROR)


class ValidationLossCallback(Callback):
    """Validation Lossë¥¼ ê³„ì‚°í•˜ê³  ë¡œê¹…í•˜ëŠ” ì»¤ìŠ¤í…€ ì½œë°±."""
    
    def on_validation_epoch_end(self, trainer, pl_module):
        """Validation epoch ì¢…ë£Œ ì‹œ validation lossë¥¼ ìˆ˜ë™ìœ¼ë¡œ ê³„ì‚°í•˜ê³  ë¡œê¹…."""
        if hasattr(pl_module, 'loss') and trainer.state.stage == 'validation':
            # Validation dataloaderì—ì„œ ë°°ì¹˜ë¥¼ ê°€ì ¸ì™€ loss ê³„ì‚°
            val_dataloader = trainer.val_dataloaders
            if val_dataloader and len(val_dataloader) > 0:
                total_loss = 0.0
                num_batches = 0
                
                pl_module.eval()
                with torch.no_grad():
                    for batch in val_dataloader:
                        # Forward pass
                        outputs = pl_module(batch)
                        
                        # Loss ê³„ì‚° (DRAEMì˜ loss í•¨ìˆ˜ ì‚¬ìš©)
                        loss = pl_module.loss(outputs)
                        total_loss += loss.item()
                        num_batches += 1
                
                # í‰ê·  validation loss ê³„ì‚°
                avg_val_loss = total_loss / num_batches if num_batches > 0 else 0.0
                
                # ë¡œê·¸ì— ê¸°ë¡
                pl_module.log("val_loss", avg_val_loss, on_epoch=True, prog_bar=True, logger=True)


def train_draem_model_single_domain(
    datamodule, 
    config: Dict[str, Any],
    results_base_dir: str,
    logger: logging.Logger
) -> tuple[Draem, Engine, str]:
    """
    DRAEM ëª¨ë¸ í›ˆë ¨ ìˆ˜í–‰.
    
    Args:
        datamodule: ì„¤ì •ëœ HDMAPDataModule
        config: í›ˆë ¨ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        results_base_dir: ê²°ê³¼ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ
        logger: ë¡œê±° ê°ì²´
        
    Returns:
        tuple: (í›ˆë ¨ëœ ëª¨ë¸, Engine ê°ì²´, ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ)
        
    Note:
        DRAEM íŠ¹ì§•:
        - í•™ìŠµ ê¸°ë°˜ ëª¨ë¸ë¡œ Early Stopping ë° ì²´í¬í¬ì¸íŠ¸ í•„ìš”
        - Reconstructionê³¼ Anomaly Detection ë™ì‹œ ìˆ˜í–‰
        - Multi-scale featureë¥¼ í™œìš©í•œ ì •ë°€í•œ ì´ìƒ íƒì§€
    """
    
    print(f"\nğŸš€ DRAEM ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    logger.info("ğŸš€ DRAEM ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    
    # Config ì„¤ì • ì¶œë ¥
    print(f"   ğŸ”§ Config ì„¤ì •:")
    print(f"      Max Epochs: {config['max_epochs']}")
    print(f"      Learning Rate: {config['learning_rate']}")
    print(f"      Batch Size: {config['batch_size']}")
    print(f"      Optimizer: {config.get('optimizer', 'adamw')}")
    print(f"      Early Stopping Patience: {config['early_stopping_patience']}")
    
    logger.info("âœ… DRAEM ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    logger.info(f"ğŸ”§ Config ì„¤ì •: max_epochs={config['max_epochs']}, lr={config['learning_rate']}")
    
    # DRAEM ëª¨ë¸ ìƒì„±
    model = Draem()
    
    # ValidationLoss ì½œë°± ì¶”ê°€
    val_loss_callback = ValidationLossCallback()
    
    # Early Stopping ì½œë°± ì„¤ì • (validation loss ì‚¬ìš©)
    early_stopping = EarlyStopping(
        monitor="val_loss",
        patience=config["early_stopping_patience"],
        mode="min",  # lossëŠ” ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ
        verbose=True
    )
    
    checkpoint_callback = ModelCheckpoint(
        filename=f"draem_single_domain_{datamodule.domain}_" + "{epoch:02d}_{val_loss:.4f}",
        monitor="val_loss",
        mode="min",  # lossëŠ” ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ
        save_top_k=1,
        verbose=True
    )
    
    callbacks = [val_loss_callback, early_stopping, checkpoint_callback]
    
    # TensorBoard ë¡œê±° ì„¤ì •
    tb_logger = TensorBoardLogger(
        save_dir=results_base_dir,
        name="tensorboard_logs",
        version=""
    )
    
    # Engine ì„¤ì • (í•™ìŠµ ê¸°ë°˜ ëª¨ë¸)
    engine_kwargs = {
        "accelerator": "gpu" if torch.cuda.is_available() else "cpu",
        "devices": [0] if torch.cuda.is_available() else 1,
        "logger": tb_logger,
        "callbacks": callbacks,
        "enable_checkpointing": True,
        "log_every_n_steps": 10,
        "enable_model_summary": True,
        "default_root_dir": results_base_dir,
        "max_epochs": config["max_epochs"],
        "check_val_every_n_epoch": 1,
        "num_sanity_val_steps": 0
    }
    
    engine = Engine(**engine_kwargs)
    
    print(f"   ğŸ”§ Engine ì„¤ì • ì™„ë£Œ")
    print(f"   ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {results_base_dir}")
    logger.info(f"ğŸ”§ Engine ì„¤ì • ì™„ë£Œ")
    logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {results_base_dir}")
    
    # ëª¨ë¸ í›ˆë ¨
    print(f"   ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    logger.info("ğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    
    engine.fit(
        model=model,
        datamodule=datamodule
    )
    
    best_checkpoint = checkpoint_callback.best_model_path
    print(f"   ğŸ† Best Checkpoint: {best_checkpoint}")
    logger.info(f"ğŸ† Best Checkpoint: {best_checkpoint}")
    
    print(f"   âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    logger.info("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    
    return model, engine, best_checkpoint


def evaluate_single_domain(
    model: Draem, 
    engine: Engine, 
    datamodule, 
    logger: logging.Logger
) -> Dict[str, Any]:
    """ë‹¨ì¼ ë„ë©”ì¸ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€."""
    
    print(f"\nğŸ“Š {datamodule.domain} ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘")
    logger.info(f"ğŸ“Š {datamodule.domain} ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    test_results = engine.test(model=model, datamodule=datamodule)
    
    # ê²°ê³¼ ì •ë¦¬
    if test_results and len(test_results) > 0:
        test_metrics = test_results[0]
        
        results = {
            "domain": datamodule.domain,
            "image_AUROC": test_metrics.get("test_image_AUROC", 0.0),
            "pixel_AUROC": test_metrics.get("test_pixel_AUROC", 0.0),
            "image_F1Score": test_metrics.get("test_image_F1Score", 0.0),
            "pixel_F1Score": test_metrics.get("test_pixel_F1Score", 0.0),
            "training_samples": len(datamodule.train_data),
            "test_samples": len(datamodule.test_data),
            "val_samples": len(datamodule.val_data) if datamodule.val_data else 0
        }
        
        print(f"   âœ… {datamodule.domain} í‰ê°€ ì™„ë£Œ:")
        print(f"      Image AUROC: {results['image_AUROC']:.4f}")
        print(f"      Pixel AUROC: {results['pixel_AUROC']:.4f}")
        print(f"      Image F1: {results['image_F1Score']:.4f}")
        print(f"      Pixel F1: {results['pixel_F1Score']:.4f}")
        
        logger.info(f"âœ… {datamodule.domain} í‰ê°€ ì™„ë£Œ: Image AUROC={results['image_AUROC']:.4f}")
    else:
        results = {"domain": datamodule.domain, "error": "No test results available"}
        logger.error(f"âŒ {datamodule.domain} í‰ê°€ ì‹¤íŒ¨")
    
    return results


def run_single_draem_experiment(
    condition: dict,
    log_dir: str = None
) -> dict:
    """ë‹¨ì¼ DRAEM ì‹¤í—˜ ì¡°ê±´ì— ëŒ€í•œ ì‹¤í—˜ ìˆ˜í–‰."""
    
    # configì—ì„œ ë„ë©”ì¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    config = condition["config"]
    domain = config["domain"]
    
    # ì‹¤í—˜ ê²½ë¡œ ì„¤ì •
    if log_dir:
        base_timestamp_dir = log_dir
        timestamp_for_folder = datetime.now().strftime("%Y%m%d_%H%M%S")
        experiment_folder = f"{condition['name']}_{timestamp_for_folder}"
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_timestamp_dir = f"results/draem_single/{timestamp}"
        experiment_folder = f"{condition['name']}_{timestamp}"
    
    results_base_dir = f"{base_timestamp_dir}/MultiDomainHDMAP/DRAEM/{experiment_folder}"
    
    # ì‹¤í—˜ ì´ë¦„ ìƒì„±
    experiment_name = f"{domain}_single"
    
    print(f"\n{'='*80}")
    print(f"ğŸ”¬ DRAEM Single Domain ì‹¤í—˜ ì¡°ê±´: {condition['name']}")
    print(f"ğŸ“ ì„¤ëª…: {condition['description']}")
    print(f"ğŸ¯ ë„ë©”ì¸: {domain}")
    print(f"{'='*80}")
    
    try:
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        cleanup_gpu_memory()
        
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(results_base_dir, exist_ok=True)
        
        # ì‹¤í—˜ ë¡œê¹… ì„¤ì •
        log_file_path = os.path.join(results_base_dir, f"{experiment_name}.log")
        logger = setup_experiment_logging(log_file_path, experiment_name)
        logger.info("ğŸš€ DRAEM Single Domain ì‹¤í—˜ ì‹œì‘")
        
        # DataModule ìƒì„± (ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©)
        datamodule = create_single_domain_datamodule(
            domain=domain,
            batch_size=config["batch_size"],
            image_size="224x224",
            val_split_ratio=0.1,
            num_workers=4,
            seed=42
        )
        
        # ëª¨ë¸ í›ˆë ¨
        trained_model, engine, best_checkpoint = train_draem_model_single_domain(
            datamodule=datamodule,
            config=config,
            results_base_dir=results_base_dir,
            logger=logger
        )
        
        # ì„±ëŠ¥ í‰ê°€
        results = evaluate_single_domain(trained_model, engine, datamodule, logger)
        
        # í›ˆë ¨ ì •ë³´ ì¶”ì¶œ
        training_info = extract_training_info(engine)
        
        # ì‹¤í—˜ ê²°ê³¼ ì •ë¦¬ (Multi Domain í˜¸í™˜ í˜•ì‹)
        experiment_results = {
            "experiment_name": condition["name"],
            "description": condition["description"],
            "domain": domain,
            "config": config,
            "results": results,
            "training_info": training_info,
            "timestamp": datetime.now().isoformat(),
            "checkpoint_path": best_checkpoint,
            "status": "success",
            # Multi Domain ë¶„ì„ í˜¸í™˜ì„ ìœ„í•œ êµ¬ì¡°
            "condition": {
                "name": condition["name"],
                "description": condition["description"],
                "config": {
                    "source_domain": domain,  # Single domainì„ sourceë¡œ ì·¨ê¸‰
                    **config
                }
            },
            "source_results": {
                "test_image_AUROC": results.get("image_AUROC", 0.0),
                "test_pixel_AUROC": results.get("pixel_AUROC", 0.0),
                "test_image_F1Score": results.get("image_F1Score", 0.0),
                "test_pixel_F1Score": results.get("pixel_F1Score", 0.0),
                "domain": domain
            },
            "target_results": {}  # Single domainì´ë¯€ë¡œ target ì—†ìŒ
        }
        
        # ê²°ê³¼ ì €ì¥ (Multi Domain í˜¸í™˜ í˜•ì‹)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # tensorboard_logs ë””ë ‰í† ë¦¬ ìƒì„±
        tensorboard_logs_dir = Path(results_base_dir) / "tensorboard_logs"
        tensorboard_logs_dir.mkdir(parents=True, exist_ok=True)
        
        # Multi Domain í˜¸í™˜ ê²°ê³¼ íŒŒì¼ëª…
        result_filename = f"result_{timestamp}.json"
        
        results_file = save_experiment_results(
            result=experiment_results,
            result_filename=result_filename,
            log_dir=tensorboard_logs_dir,
            logger=logger,
            model_type="DRAEM"
        )
        print(f"ğŸ“„ ì‹¤í—˜ ê²°ê³¼ ì €ì¥ë¨: {results_file}")
        
        # ì‹œê°í™” ìƒì„±
        try:
            create_experiment_visualization(
                experiment_results, 
                results_base_dir, 
                f"DRAEM_single_domain_{domain}",
                single_domain=True
            )
            print(f"ğŸ“Š ê²°ê³¼ ì‹œê°í™” ìƒì„± ì™„ë£Œ")
        except Exception as viz_error:
            print(f"âš ï¸ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {viz_error}")
            logger.warning(f"ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {viz_error}")
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        cleanup_gpu_memory()
        
        print(f"âœ… ì‹¤í—˜ ì™„ë£Œ: {condition['name']}")
        logger.info(f"âœ… ì‹¤í—˜ ì™„ë£Œ: {condition['name']}")
        
        return experiment_results
        
    except Exception as e:
        error_msg = f"âŒ ì‹¤í—˜ ì‹¤íŒ¨: {condition['name']} - {str(e)}"
        print(error_msg)
        if 'logger' in locals():
            logger.error(error_msg)
        
        cleanup_gpu_memory()
        
        return {
            "experiment_name": condition["name"],
            "error": str(e),
            "timestamp": datetime.now().isoformat(),
            "status": "failed"
        }


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(description="DRAEM Single Domain ì‹¤í—˜")
    parser.add_argument("--gpu-id", type=int, default=0, help="ì‚¬ìš©í•  GPU ID")
    parser.add_argument("--experiment-id", type=int, default=0, help="ì‹¤í—˜ ì¡°ê±´ ì¸ë±ìŠ¤")
    parser.add_argument("--log-dir", type=str, default=None, help="ë¡œê·¸ ì €ì¥ ë””ë ‰í† ë¦¬")
    
    args = parser.parse_args()
    
    # GPU ì„¤ì •
    if torch.cuda.is_available():
        os.environ["CUDA_VISIBLE_DEVICES"] = str(args.gpu_id)
        print(f"ğŸ–¥ï¸ GPU {args.gpu_id} ì‚¬ìš©")
    
    # ê²½ê³  í•„í„° ì„¤ì •
    setup_warnings_filter()
    
    # ì‹¤í—˜ ì¡°ê±´ ë¡œë“œ
    conditions = load_experiment_conditions("draem-exp_condition.json")
    
    if args.experiment_id >= len(conditions):
        print(f"âŒ ì˜ëª»ëœ ì‹¤í—˜ ID: {args.experiment_id} (ìµœëŒ€: {len(conditions)-1})")
        return
    
    condition = conditions[args.experiment_id]
    
    # ì‹¤í—˜ ì‹¤í–‰
    result = run_single_draem_experiment(condition, args.log_dir)
    
    if "error" not in result:
        print(f"\nğŸ‰ ì‹¤í—˜ ì„±ê³µ!")
        if "results" in result and isinstance(result["results"], dict):
            print(f"   ğŸ“Š ìµœì¢… ì„±ê³¼:")
            print(f"      Image AUROC: {result['results'].get('image_AUROC', 0):.4f}")
            print(f"      Pixel AUROC: {result['results'].get('pixel_AUROC', 0):.4f}")
    else:
        print(f"\nğŸ’¥ ì‹¤í—˜ ì‹¤íŒ¨: {result['error']}")


if __name__ == "__main__":
    main()