{
  "experiment_conditions": [
    {
      "name": "domainA_baseline",
      "description": "Domain A - 기본 ViT-Base 설정 (단일 도메인 최적화)",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0001,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    },
    {
      "name": "domainA_large_model",
      "description": "Domain A - ViT-Large 모델 사용",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0001,
        "batch_size": 4,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_large_14",
        "target_layers": [4, 6, 8, 10, 12, 14, 16, 18],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    },
    {
      "name": "domainA_high_lr",
      "description": "Domain A - 높은 학습률과 더 많은 warmup",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0003,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 200
      }
    },
    {
      "name": "domainA_deep_decoder",
      "description": "Domain A - 더 깊은 decoder와 낮은 dropout",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0001,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.1,
        "decoder_depth": 12,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    },
    {
      "name": "domainA_shallow_features",
      "description": "Domain A - 얕은 특징만 사용 (더 세부적인 패턴)",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0001,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [1, 2, 3, 4, 5, 6],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    },
    {
      "name": "domainA_deep_features",
      "description": "Domain A - 깊은 특징만 사용 (더 추상적인 패턴)",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0001,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [6, 7, 8, 9, 10, 11],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    },
    {
      "name": "domainA_no_class_token",
      "description": "Domain A - Class token 제거 (patch feature만 사용)",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0001,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": true,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    },
    {
      "name": "domainA_high_dropout",
      "description": "Domain A - 높은 dropout으로 overfitting 방지",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0001,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.4,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    },
    {
      "name": "domainA_large_batch",
      "description": "Domain A - 큰 배치 사이즈로 안정적인 학습",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0002,
        "batch_size": 16,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 150
      }
    },
    {
      "name": "domainA_small_batch",
      "description": "Domain A - 작은 배치 사이즈로 세밀한 학습",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.00005,
        "batch_size": 4,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 50
      }
    },
    {
      "name": "domainA_adam_optimizer",
      "description": "Domain A - Adam 옵티마이저 사용",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0001,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adam",
        "weight_decay": 0.0,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    },
    {
      "name": "domainA_extended_training",
      "description": "Domain A - 더 긴 훈련 시간",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 100,
        "early_stopping_patience": 15,
        "learning_rate": 0.0001,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    },
    {
      "name": "domainA_minimal_decoder",
      "description": "Domain A - 최소한의 decoder (빠른 추론)",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0001,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 4,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    },
    {
      "name": "domainA_cosine_schedule",
      "description": "Domain A - Cosine annealing 스케줄러 사용",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0002,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100,
        "scheduler": "cosine"
      }
    },
    {
      "name": "domainA_balanced_features",
      "description": "Domain A - 중간 레이어 특징 집중 사용",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.0001,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [3, 4, 5, 6, 7, 8],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    },
    {
      "name": "domainA_stable_adamw",
      "description": "Domain A - StableAdamW 옵티마이저로 안정적인 학습",
      "config": {
        "source_domain": "domain_A",
        "max_epochs": 50,
        "early_stopping_patience": 10,
        "learning_rate": 0.002,
        "batch_size": 8,
        "image_size": "224x224",
        "encoder_name": "dinov2reg_vit_base_14",
        "target_layers": [2, 3, 4, 5, 6, 7, 8, 9],
        "bottleneck_dropout": 0.2,
        "decoder_depth": 8,
        "remove_class_token": false,
        "optimizer": "stable_adamw",
        "weight_decay": 0.0001,
        "gradient_clip_val": 0.1,
        "warmup_steps": 100
      }
    }
  ]
}