#!/usr/bin/env python3
"""
Single Domain ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Single-Domain ì‹¤í—˜ì˜ metrics_report.json íŒŒì¼ì„ ë¶„ì„í•˜ì—¬
ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ í…Œì´ë¸” í˜•íƒœë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.

==============================================================================
ğŸš€ ì‚¬ìš©ë²•:
==============================================================================

.venv/bin/python examples/hdmap/analyze_experiment_results_single.py --results_dir results_100k_train

==============================================================================
ğŸ“ ëŒ€ìƒ í´ë” êµ¬ì¡°:
==============================================================================

results_100k_train/
â””â”€â”€ 20251011_054347/
    â”œâ”€â”€ exp-71.A_20251011_054347/
    â”‚   â””â”€â”€ analysis/
    â”‚       â””â”€â”€ metrics_report.json
    â”œâ”€â”€ exp-71.B_20251011_054347/
    â”‚   â””â”€â”€ analysis/
    â”‚       â””â”€â”€ metrics_report.json
    â””â”€â”€ ...

==============================================================================
ğŸ“Š ì¶œë ¥ ë‚´ìš©:
==============================================================================

ì‹¤í—˜ë³„ ìƒì„¸ ì„±ëŠ¥ í…Œì´ë¸”:
- ì‹¤í—˜ ì´ë¦„ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
- ë„ë©”ì¸ (A, B, C, D)
- AUROC
- Optimal Threshold
- Precision
- Recall
- F1 Score
- Accuracy (Confusion Matrix ê¸°ë°˜ ê³„ì‚°)

==============================================================================
ğŸ”§ Metrics JSON í˜•ì‹:
==============================================================================

{
  "auroc": 1.0,
  "optimal_threshold": 0.41473591327667236,
  "precision": 1.0,
  "recall": 0.9988888888888889,
  "f1_score": 0.9994441356309061,
  "confusion_matrix": [[900, 0], [1, 899]],
  "total_samples": 1800,
  "positive_samples": 900,
  "negative_samples": 900
}
"""

import argparse
import json
from pathlib import Path

import pandas as pd


def extract_experiment_info(exp_dir_name):
    """ì‹¤í—˜ ë””ë ‰í† ë¦¬ ì´ë¦„ì—ì„œ ì •ë³´ ì¶”ì¶œ

    ì˜ˆ: exp-71.A_20251011_054347
    -> experiment_name: exp-71.A
    -> domain: A
    -> timestamp: 20251011_054347
    """
    # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ (ë§ˆì§€ë§‰ ë‘ ë¶€ë¶„: YYYYMMDD_HHMMSS)
    parts = exp_dir_name.split('_')

    timestamp = None
    exp_name_with_domain = exp_dir_name

    # ë§ˆì§€ë§‰ ë‘ ë¶€ë¶„ì´ timestampì¸ì§€ í™•ì¸
    if len(parts) >= 3:
        if (parts[-2].isdigit() and len(parts[-2]) == 8 and
            parts[-1].isdigit() and len(parts[-1]) == 6):
            timestamp = f"{parts[-2]}_{parts[-1]}"
            exp_name_with_domain = '_'.join(parts[:-2])

    # ë„ë©”ì¸ ì¶”ì¶œ (exp-71.A -> A)
    domain = None
    experiment_name = exp_name_with_domain

    if '.' in exp_name_with_domain:
        exp_parts = exp_name_with_domain.split('.')
        if len(exp_parts) >= 2:
            domain = exp_parts[1]  # A, B, C, D ë“±
            # experiment_nameì€ ë„ë©”ì¸ í¬í•¨í•œ ì „ì²´ ì´ë¦„
            experiment_name = exp_name_with_domain

    return {
        'full_name': exp_dir_name,
        'experiment_name': experiment_name,
        'domain': domain,
        'timestamp': timestamp
    }


def calculate_accuracy(confusion_matrix):
    """Confusion Matrixë¡œë¶€í„° Accuracy ê³„ì‚°

    confusion_matrix: [[TN, FP], [FN, TP]]
    """
    if confusion_matrix and len(confusion_matrix) == 2 and len(confusion_matrix[0]) == 2:
        tn, fp = confusion_matrix[0][0], confusion_matrix[0][1]
        fn, tp = confusion_matrix[1][0], confusion_matrix[1][1]
        total = tp + tn + fp + fn
        if total > 0:
            return (tp + tn) / total
    return None


def analyze_single_domain_experiments(results_dir: str):
    """Single-Domain ì‹¤í—˜ ê²°ê³¼ ë¶„ì„"""
    results_path = Path(results_dir)

    print(f"ğŸ” Single-Domain ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ì‹œì‘...")
    print(f"ğŸ“ ê¸°ë³¸ ë””ë ‰í† ë¦¬: {results_path}")

    # timestamp ë””ë ‰í† ë¦¬ ì°¾ê¸°
    timestamp_dirs = [d for d in results_path.iterdir() if d.is_dir()]

    if not timestamp_dirs:
        print(f"âŒ {results_path}ì—ì„œ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ëª¨ë“  ì‹¤í—˜ ë””ë ‰í† ë¦¬ ìˆ˜ì§‘
    all_experiment_dirs = []
    for timestamp_dir in timestamp_dirs:
        experiment_dirs = [d for d in timestamp_dir.iterdir() if d.is_dir()]
        all_experiment_dirs.extend(experiment_dirs)

    if not all_experiment_dirs:
        print(f"âŒ ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“Š ë°œê²¬ëœ ì‹¤í—˜ ë””ë ‰í† ë¦¬: {len(all_experiment_dirs)}ê°œ")

    # ê° ì‹¤í—˜ì˜ metrics_report.json ìˆ˜ì§‘
    experiment_results = []

    for exp_dir in all_experiment_dirs:
        metrics_report_path = exp_dir / "analysis" / "metrics_report.json"

        if not metrics_report_path.exists():
            continue

        try:
            with open(metrics_report_path, 'r', encoding='utf-8') as f:
                metrics_data = json.load(f)

            # ì‹¤í—˜ ì •ë³´ ì¶”ì¶œ
            exp_info = extract_experiment_info(exp_dir.name)

            # Accuracy ê³„ì‚°
            accuracy = calculate_accuracy(metrics_data.get('confusion_matrix'))
            val_metrics = metrics_data.get('validation_metrics')
            val_accuracy = (
                calculate_accuracy(val_metrics.get('confusion_matrix'))
                if val_metrics and val_metrics.get('confusion_matrix')
                else None
            )

            # ê²°ê³¼ ì €ì¥
            experiment_results.append({
                'experiment_name': exp_info['experiment_name'],
                'domain': exp_info['domain'],
                'timestamp': exp_info['timestamp'],
                'auroc': metrics_data.get('auroc'),
                'optimal_threshold': metrics_data.get('optimal_threshold'),
                'precision': metrics_data.get('precision'),
                'recall': metrics_data.get('recall'),
                'f1_score': metrics_data.get('f1_score'),
                'accuracy': accuracy,
                'val_auroc': val_metrics.get('auroc') if val_metrics else None,
                'val_precision': val_metrics.get('precision') if val_metrics else None,
                'val_recall': val_metrics.get('recall') if val_metrics else None,
                'val_f1_score': val_metrics.get('f1_score') if val_metrics else None,
                'val_accuracy': val_accuracy,
                'full_dir_name': exp_info['full_name']
            })

        except Exception as e:
            print(f"   âš ï¸ {exp_dir.name} metrics_report.json ë¡œë“œ ì‹¤íŒ¨: {e}")

    if not experiment_results:
        print("âŒ ë¶„ì„í•  ìˆ˜ ìˆëŠ” metrics_report.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # DataFrame ìƒì„±
    df = pd.DataFrame(experiment_results)

    # ì •ë ¬: ì‹¤í—˜ëª… ì˜¤ë¦„ì°¨ìˆœ -> ë„ë©”ì¸ ì˜¤ë¦„ì°¨ìˆœ -> íƒ€ì„ìŠ¤íƒ¬í”„ ì˜¤ë¦„ì°¨ìˆœ
    df = df.sort_values(['experiment_name', 'domain', 'timestamp'], ascending=[True, True, True])

    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*120}")
    print(f"ğŸ¯ Single-Domain ì‹¤í—˜ ê²°ê³¼")
    print(f"{'='*120}")
    print(f"ì´ ì‹¤í—˜ ìˆ˜: {len(df)}")

    print(f"\nğŸ“Š ì‹¤í—˜ë³„ ìƒì„¸ ì„±ëŠ¥:")

    # ì¶œë ¥ìš© DataFrame ìƒì„±
    display_df = df.copy()
    display_df['ì‹¤í—˜ëª…'] = display_df['experiment_name']
    display_df['ë„ë©”ì¸'] = display_df['domain']
    display_df['íƒ€ì„ìŠ¤íƒ¬í”„'] = display_df['timestamp']
    display_df['AUROC'] = display_df['auroc'].apply(lambda x: f"{x:.6f}" if pd.notna(x) else 'N/A')
    display_df['Threshold'] = display_df['optimal_threshold'].apply(lambda x: f"{x:.6f}" if pd.notna(x) else 'N/A')
    display_df['Precision'] = display_df['precision'].apply(lambda x: f"{x:.6f}" if pd.notna(x) else 'N/A')
    display_df['Recall'] = display_df['recall'].apply(lambda x: f"{x:.6f}" if pd.notna(x) else 'N/A')
    display_df['F1 Score'] = display_df['f1_score'].apply(lambda x: f"{x:.6f}" if pd.notna(x) else 'N/A')
    display_df['Test Accuracy'] = display_df['accuracy'].apply(lambda x: f"{x:.6f}" if pd.notna(x) else 'N/A')
    display_df['Val AUROC'] = display_df['val_auroc'].apply(lambda x: f"{x:.6f}" if pd.notna(x) else 'N/A')
    display_df['Val Precision'] = display_df['val_precision'].apply(lambda x: f"{x:.6f}" if pd.notna(x) else 'N/A')
    display_df['Val Recall'] = display_df['val_recall'].apply(lambda x: f"{x:.6f}" if pd.notna(x) else 'N/A')
    display_df['Val F1 Score'] = display_df['val_f1_score'].apply(lambda x: f"{x:.6f}" if pd.notna(x) else 'N/A')
    display_df['Val Accuracy'] = display_df['val_accuracy'].apply(lambda x: f"{x:.6f}" if pd.notna(x) else 'N/A')

    # ì¶œë ¥í•  ì¹¼ëŸ¼ë§Œ ì„ íƒ
    output_columns = [
        'ì‹¤í—˜ëª…', 'ë„ë©”ì¸', 'íƒ€ì„ìŠ¤íƒ¬í”„',
        'AUROC', 'Threshold', 'Precision', 'Recall', 'F1 Score', 'Test Accuracy',
        'Val AUROC', 'Val Precision', 'Val Recall', 'Val F1 Score', 'Val Accuracy'
    ]
    display_df = display_df[output_columns]

    # CSV í˜•íƒœë¡œ ì¶œë ¥ (comma separated)
    print(display_df.to_csv(index=False, lineterminator='\n'))

    # CSV ì €ì¥
    output_path = results_path / "single_domain_analysis.csv"
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {output_path}")

    # ========================================================================
    # ë‘ ë²ˆì§¸ View: ì‹¤í—˜ë³„ ë„ë©”ì¸ ë°˜ë³µ íšŸìˆ˜
    # ========================================================================
    print(f"\n{'='*120}")
    print(f"ğŸ“Š ì‹¤í—˜ë³„ ë„ë©”ì¸ ë°˜ë³µ íšŸìˆ˜")
    print(f"{'='*120}")

    # ì‹¤í—˜ ë²ˆí˜¸ ì¶”ì¶œ (exp-71.A -> exp-71)
    def extract_experiment_number(exp_name):
        if '.' in exp_name and exp_name.startswith('exp-'):
            # exp-71.A -> exp-71
            return exp_name.split('.')[0]
        return exp_name

    df['experiment_number'] = df['experiment_name'].apply(extract_experiment_number)

    # ì‹¤í—˜ ë²ˆí˜¸ë³„, ë„ë©”ì¸ë³„ ë°˜ë³µ íšŸìˆ˜ ê³„ì‚°
    count_data = []

    for exp_num in sorted(df['experiment_number'].unique()):
        exp_data = df[df['experiment_number'] == exp_num]

        row_data = {'ì‹¤í—˜ëª…': exp_num}

        # ê° ë„ë©”ì¸ì— ëŒ€í•´ ë°˜ë³µ íšŸìˆ˜ ê³„ì‚°
        for domain in ['A', 'B', 'C', 'D']:
            domain_count = len(exp_data[exp_data['domain'] == domain])
            row_data[f'Domain_{domain}'] = domain_count

        count_data.append(row_data)

    # DataFrame ìƒì„±
    count_df = pd.DataFrame(count_data)

    # CSV í˜•íƒœë¡œ ì¶œë ¥
    print(count_df.to_csv(index=False, lineterminator='\n'))

    # CSV ì €ì¥
    count_output_path = results_path / "experiment_domain_count.csv"
    count_df.to_csv(count_output_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ì‹¤í—˜ë³„ ë„ë©”ì¸ ë°˜ë³µ íšŸìˆ˜ ì €ì¥ë¨: {count_output_path}")

    # ========================================================================
    # ì„¸ ë²ˆì§¸ View: ì‹¤í—˜ë³„ ë„ë©”ì¸ Accuracy í‰ê· /í‘œì¤€í¸ì°¨ ë§¤íŠ¸ë¦­ìŠ¤
    # ========================================================================
    print(f"\n{'='*120}")
    print(f"ğŸ“Š ì‹¤í—˜ë³„ ë„ë©”ì¸ Accuracy í‰ê· /í‘œì¤€í¸ì°¨")
    print(f"{'='*120}")

    # ì‹¤í—˜ ë²ˆí˜¸ ì¶”ì¶œ (exp-71.A -> exp-71)
    def extract_experiment_number(exp_name):
        if '.' in exp_name and exp_name.startswith('exp-'):
            # exp-71.A -> exp-71
            return exp_name.split('.')[0]
        return exp_name

    df['experiment_number'] = df['experiment_name'].apply(extract_experiment_number)

    summary_rows = []
    val_summary_rows = []
    for exp_num in sorted(df['experiment_number'].unique()):
        exp_data = df[df['experiment_number'] == exp_num]
        row = {'ì‹¤í—˜ëª…': exp_num}
        val_row = {'ì‹¤í—˜ëª…': exp_num}

        for domain in ['A', 'B', 'C', 'D']:
            test_data = exp_data[exp_data['domain'] == domain]['accuracy']
            if len(test_data) > 0:
                mean_test = test_data.mean()
                std_test = test_data.std() if len(test_data) > 1 else 0.0
                row[f'Domain_{domain}_Mean'] = f"{mean_test:.6f}"
                row[f'Domain_{domain}_Std'] = f"{std_test:.6f}"
            else:
                row[f'Domain_{domain}_Mean'] = 'N/A'
                row[f'Domain_{domain}_Std'] = 'N/A'

            val_data = exp_data[exp_data['domain'] == domain]['val_accuracy']
            if len(val_data) > 0:
                mean_val = val_data.mean()
                std_val = val_data.std() if len(val_data) > 1 else 0.0
                val_row[f'Val_Domain_{domain}_Mean'] = f"{mean_val:.6f}"
                val_row[f'Val_Domain_{domain}_Std'] = f"{std_val:.6f}"
            else:
                val_row[f'Val_Domain_{domain}_Mean'] = 'N/A'
                val_row[f'Val_Domain_{domain}_Std'] = 'N/A'

        summary_rows.append(row)
        val_summary_rows.append(val_row)

    summary_df = pd.DataFrame(summary_rows)
    summary_df['Overall_Mean'] = df.groupby('experiment_number')['accuracy'].mean().values
    summary_df['Overall_Std'] = df.groupby('experiment_number')['accuracy'].std().fillna(0).values
    print(summary_df.to_csv(index=False, lineterminator='\n'))
    summary_output_path = results_path / "experiment_domain_accuracy_summary.csv"
    summary_df.to_csv(summary_output_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ì‹¤í—˜ë³„ ë„ë©”ì¸ Test Accuracy ìš”ì•½ ì €ì¥ë¨: {summary_output_path}")

    val_summary_df = pd.DataFrame(val_summary_rows)
    val_summary_df['Val_Overall_Mean'] = df.groupby('experiment_number')['val_accuracy'].mean().values
    val_summary_df['Val_Overall_Std'] = df.groupby('experiment_number')['val_accuracy'].std().fillna(0).values
    print(val_summary_df.to_csv(index=False, lineterminator='\n'))
    val_summary_output_path = results_path / "experiment_domain_val_accuracy_summary.csv"
    val_summary_df.to_csv(val_summary_output_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ì‹¤í—˜ë³„ ë„ë©”ì¸ Validation Accuracy ìš”ì•½ ì €ì¥ë¨: {val_summary_output_path}")

    return df


def main():
    parser = argparse.ArgumentParser(description='Single-Domain ì‹¤í—˜ ê²°ê³¼ ë¶„ì„')
    parser.add_argument(
        '--results_dir',
        type=str,
        required=True,
        help='ì‹¤í—˜ ê²°ê³¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì˜ˆ: results_100k_train)'
    )

    args = parser.parse_args()

    # ë¶„ì„ ì‹¤í–‰
    analyze_single_domain_experiments(args.results_dir)


if __name__ == "__main__":
    main()
